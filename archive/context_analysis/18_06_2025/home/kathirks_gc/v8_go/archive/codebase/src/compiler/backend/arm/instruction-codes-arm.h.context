{
  "metadata": {
    "path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/arm/instruction-codes-arm.h",
    "file_name": "instruction-codes-arm.h",
    "language": "cpp",
    "purpose": "Defines ARM-specific opcodes and addressing modes for the V8 compiler backend."
  },
  "imports": {
    "metadata": {
      "language": "cpp",
      "purpose": "No explicit imports, but uses namespace v8, v8::internal, v8::internal::compiler"
    },
    "code": "// No explicit includes\n        namespace v8 { namespace internal { namespace compiler {\n        // ... content within namespaces ...\n        }}}"
  },
  "classes": [
    {
      "metadata": {
        "language": "cpp",
        "type": "namespace",
        "name": "v8::internal::compiler",
        "about": "Namespace containing compiler related classes and definitions.",
        "attributes": [],
        "dependencies": []
      },
      "code": "namespace v8 {\n      namespace internal {\n      namespace compiler {\n\n      // Content of the namespace follows\n\n      }}}"
    },
    {
      "metadata": {
        "language": "cpp",
        "type": "macro",
        "name": "TARGET_ARCH_OPCODE_LIST",
        "about": "Defines a list of ARM-specific opcodes using a macro.",
        "attributes": [],
        "dependencies": []
      },
      "code": "#define TARGET_ARCH_OPCODE_LIST(V) \\\n  V(ArmAdd)                        \\\n  V(ArmAnd)                        \\\n  V(ArmBic)                        \\\n  V(ArmClz)                        \\\n  V(ArmCmp)                        \\\n  V(ArmCmn)                        \\\n  V(ArmTst)                        \\\n  V(ArmTeq)                        \\\n  V(ArmOrr)                        \\\n  V(ArmEor)                        \\\n  V(ArmSub)                        \\\n  V(ArmRsb)                        \\\n  V(ArmMul)                        \\\n  V(ArmMla)                        \\\n  V(ArmMls)                        \\\n  V(ArmSmull)                      \\\n  V(ArmSmmul)                      \\\n  V(ArmSmmla)                      \\\n  V(ArmUmull)                      \\\n  V(ArmSdiv)                       \\\n  V(ArmUdiv)                       \\\n  V(ArmMov)                        \\\n  V(ArmMvn)                        \\\n  V(ArmBfc)                        \\\n  V(ArmUbfx)                       \\\n  V(ArmSbfx)                       \\\n  V(ArmSxtb)                       \\\n  V(ArmSxth)                       \\\n  V(ArmSxtab)                      \\\n  V(ArmSxtah)                      \\\n  V(ArmUxtb)                       \\\n  V(ArmUxth)                       \\\n  V(ArmUxtab)                      \\\n  V(ArmRbit)                       \\\n  V(ArmRev)                        \\\n  V(ArmUxtah)                      \\\n  V(ArmAddPair)                    \\\n  V(ArmSubPair)                    \\\n  V(ArmMulPair)                    \\\n  V(ArmLslPair)                    \\\n  V(ArmLsrPair)                    \\\n  V(ArmAsrPair)                    \\\n  V(ArmVcmpF32)                    \\\n  V(ArmVaddF32)                    \\\n  V(ArmVsubF32)                    \\\n  V(ArmVmulF32)                    \\\n  V(ArmVmlaF32)                    \\\n  V(ArmVmlsF32)                    \\\n  V(ArmVdivF32)                    \\\n  V(ArmVabsF32)                    \\\n  V(ArmVnegF32)                    \\\n  V(ArmVsqrtF32)                   \\\n  V(ArmVcmpF64)                    \\\n  V(ArmVaddF64)                    \\\n  V(ArmVsubF64)                    \\\n  V(ArmVmulF64)                    \\\n  V(ArmVmlaF64)                    \\\n  V(ArmVmlsF64)                    \\\n  V(ArmVdivF64)                    \\\n  V(ArmVmodF64)                    \\\n  V(ArmVabsF64)                    \\\n  V(ArmVnegF64)                    \\\n  V(ArmVsqrtF64)                   \\\n  V(ArmVmullLow)                   \\\n  V(ArmVmullHigh)                  \\\n  V(ArmVrintmF32)                  \\\n  V(ArmVrintmF64)                  \\\n  V(ArmVrintpF32)                  \\\n  V(ArmVrintpF64)                  \\\n  V(ArmVrintzF32)                  \\\n  V(ArmVrintzF64)                  \\\n  V(ArmVrintaF64)                  \\\n  V(ArmVrintnF32)                  \\\n  V(ArmVrintnF64)                  \\\n  V(ArmVcvtF32F64)                 \\\n  V(ArmVcvtF64F32)                 \\\n  V(ArmVcvtF32S32)                 \\\n  V(ArmVcvtF32U32)                 \\\n  V(ArmVcvtF64S32)                 \\\n  V(ArmVcvtF64U32)                 \\\n  V(ArmVcvtS32F32)                 \\\n  V(ArmVcvtU32F32)                 \\\n  V(ArmVcvtS32F64)                 \\\n  V(ArmVcvtU32F64)                 \\\n  V(ArmVmovU32F32)                 \\\n  V(ArmVmovF32U32)                 \\\n  V(ArmVmovLowU32F64)              \\\n  V(ArmVmovLowF64U32)              \\\n  V(ArmVmovHighU32F64)             \\\n  V(ArmVmovHighF64U32)             \\\n  V(ArmVmovF64U32U32)              \\\n  V(ArmVmovU32U32F64)              \\\n  V(ArmVldrF32)                    \\\n  V(ArmVstrF32)                    \\\n  V(ArmVldrF64)                    \\\n  V(ArmVld1F64)                    \\\n  V(ArmVstrF64)                    \\\n  V(ArmVst1F64)                    \\\n  V(ArmVld1S128)                   \\\n  V(ArmVst1S128)                   \\\n  V(ArmVcnt)                       \\\n  V(ArmVpadal)                     \\\n  V(ArmVpaddl)                     \\\n  V(ArmFloat32Max)                 \\\n  V(ArmFloat64Max)                 \\\n  V(ArmFloat32Min)                 \\\n  V(ArmFloat64Min)                 \\\n  V(ArmFloat64SilenceNaN)          \\\n  V(ArmLdrb)                       \\\n  V(ArmLdrsb)                      \\\n  V(ArmStrb)                       \\\n  V(ArmLdrh)                       \\\n  V(ArmLdrsh)                      \\\n  V(ArmStrh)                       \\\n  V(ArmLdr)                        \\\n  V(ArmStr)                        \\\n  V(ArmPush)                       \\\n  V(ArmPoke)                       \\\n  V(ArmPeek)                       \\\n  V(ArmDmbIsh)                     \\\n  V(ArmDsbIsb)                     \\\n  V(ArmF64x2Splat)                 \\\n  V(ArmF64x2ExtractLane)           \\\n  V(ArmF64x2ReplaceLane)           \\\n  V(ArmF64x2Abs)                   \\\n  V(ArmF64x2Neg)                   \\\n  V(ArmF64x2Sqrt)                  \\\n  V(ArmF64x2Add)                   \\\n  V(ArmF64x2Sub)                   \\\n  V(ArmF64x2Mul)                   \\\n  V(ArmF64x2Div)                   \\\n  V(ArmF64x2Min)                   \\\n  V(ArmF64x2Max)                   \\\n  V(ArmF64x2Eq)                    \\\n  V(ArmF64x2Ne)                    \\\n  V(ArmF64x2Lt)                    \\\n  V(ArmF64x2Le)                    \\\n  V(ArmF64x2Pmin)                  \\\n  V(ArmF64x2Pmax)                  \\\n  V(ArmF64x2Qfma)                  \\\n  V(ArmF64x2Qfms)                  \\\n  V(ArmF64x2Ceil)                  \\\n  V(ArmF64x2Floor)                 \\\n  V(ArmF64x2Trunc)                 \\\n  V(ArmF64x2NearestInt)            \\\n  V(ArmF64x2ConvertLowI32x4S)      \\\n  V(ArmF64x2ConvertLowI32x4U)      \\\n  V(ArmF64x2PromoteLowF32x4)       \\\n  V(ArmF32x4Splat)                 \\\n  V(ArmF32x4ExtractLane)           \\\n  V(ArmF32x4ReplaceLane)           \\\n  V(ArmF32x4SConvertI32x4)         \\\n  V(ArmF32x4UConvertI32x4)         \\\n  V(ArmF32x4Abs)                   \\\n  V(ArmF32x4Neg)                   \\\n  V(ArmF32x4Sqrt)                  \\\n  V(ArmF32x4Add)                   \\\n  V(ArmF32x4Sub)                   \\\n  V(ArmF32x4Mul)                   \\\n  V(ArmF32x4Div)                   \\\n  V(ArmF32x4Min)                   \\\n  V(ArmF32x4Max)                   \\\n  V(ArmF32x4Eq)                    \\\n  V(ArmF32x4Ne)                    \\\n  V(ArmF32x4Lt)                    \\\n  V(ArmF32x4Le)                    \\\n  V(ArmF32x4Pmin)                  \\\n  V(ArmF32x4Pmax)                  \\\n  V(ArmF32x4Qfma)                  \\\n  V(ArmF32x4Qfms)                  \\\n  V(ArmF32x4DemoteF64x2Zero)       \\\n  V(ArmI64x2SplatI32Pair)          \\\n  V(ArmI64x2ReplaceLaneI32Pair)    \\\n  V(ArmI64x2Abs)                   \\\n  V(ArmI64x2Neg)                   \\\n  V(ArmI64x2Shl)                   \\\n  V(ArmI64x2ShrS)                  \\\n  V(ArmI64x2Add)                   \\\n  V(ArmI64x2Sub)                   \\\n  V(ArmI64x2Mul)                   \\\n  V(ArmI64x2ShrU)                  \\\n  V(ArmI64x2BitMask)               \\\n  V(ArmI64x2Eq)                    \\\n  V(ArmI64x2Ne)                    \\\n  V(ArmI64x2GtS)                   \\\n  V(ArmI64x2GeS)                   \\\n  V(ArmI64x2SConvertI32x4Low)      \\\n  V(ArmI64x2SConvertI32x4High)     \\\n  V(ArmI64x2UConvertI32x4Low)      \\\n  V(ArmI64x2UConvertI32x4High)     \\\n  V(ArmI32x4Splat)                 \\\n  V(ArmI32x4ExtractLane)           \\\n  V(ArmI32x4ReplaceLane)           \\\n  V(ArmI32x4SConvertF32x4)         \\\n  V(ArmI32x4SConvertI16x8Low)      \\\n  V(ArmI32x4SConvertI16x8High)     \\\n  V(ArmI32x4Neg)                   \\\n  V(ArmI32x4Shl)                   \\\n  V(ArmI32x4ShrS)                  \\\n  V(ArmI32x4Add)                   \\\n  V(ArmI32x4Sub)                   \\\n  V(ArmI32x4Mul)                   \\\n  V(ArmI32x4MinS)                  \\\n  V(ArmI32x4MaxS)                  \\\n  V(ArmI32x4Eq)                    \\\n  V(ArmI32x4Ne)                    \\\n  V(ArmI32x4GtS)                   \\\n  V(ArmI32x4GeS)                   \\\n  V(ArmI32x4UConvertF32x4)         \\\n  V(ArmI32x4UConvertI16x8Low)      \\\n  V(ArmI32x4UConvertI16x8High)     \\\n  V(ArmI32x4ShrU)                  \\\n  V(ArmI32x4MinU)                  \\\n  V(ArmI32x4MaxU)                  \\\n  V(ArmI32x4GtU)                   \\\n  V(ArmI32x4GeU)                   \\\n  V(ArmI32x4Abs)                   \\\n  V(ArmI32x4BitMask)               \\\n  V(ArmI32x4DotI16x8S)             \\\n  V(ArmI16x8DotI8x16S)             \\\n  V(ArmI32x4DotI8x16AddS)          \\\n  V(ArmI32x4TruncSatF64x2SZero)    \\\n  V(ArmI32x4TruncSatF64x2UZero)    \\\n  V(ArmI16x8Splat)                 \\\n  V(ArmI16x8ExtractLaneS)          \\\n  V(ArmI16x8ReplaceLane)           \\\n  V(ArmI16x8SConvertI8x16Low)      \\\n  V(ArmI16x8SConvertI8x16High)     \\\n  V(ArmI16x8Neg)                   \\\n  V(ArmI16x8Shl)                   \\\n  V(ArmI16x8ShrS)                  \\\n  V(ArmI16x8SConvertI32x4)         \\\n  V(ArmI16x8Add)                   \\\n  V(ArmI16x8AddSatS)               \\\n  V(ArmI16x8Sub)                   \\\n  V(ArmI16x8SubSatS)               \\\n  V(ArmI16x8Mul)                   \\\n  V(ArmI16x8MinS)                  \\\n  V(ArmI16x8MaxS)                  \\\n  V(ArmI16x8Eq)                    \\\n  V(ArmI16x8Ne)                    \\\n  V(ArmI16x8GtS)                   \\\n  V(ArmI16x8GeS)                   \\\n  V(ArmI16x8ExtractLaneU)          \\\n  V(ArmI16x8UConvertI8x16Low)      \\\n  V(ArmI16x8UConvertI8x16High)     \\\n  V(ArmI16x8ShrU)                  \\\n  V(ArmI16x8UConvertI32x4)         \\\n  V(ArmI16x8AddSatU)               \\\n  V(ArmI16x8SubSatU)               \\\n  V(ArmI16x8MinU)                  \\\n  V(ArmI16x8MaxU)                  \\\n  V(ArmI16x8GtU)                   \\\n  V(ArmI16x8GeU)                   \\\n  V(ArmI16x8RoundingAverageU)      \\\n  V(ArmI16x8Abs)                   \\\n  V(ArmI16x8BitMask)               \\\n  V(ArmI16x8Q15MulRSatS)           \\\n  V(ArmI8x16Splat)                 \\\n  V(ArmI8x16ExtractLaneS)          \\\n  V(ArmI8x16ReplaceLane)           \\\n  V(ArmI8x16Neg)                   \\\n  V(ArmI8x16Shl)                   \\\n  V(ArmI8x16ShrS)                  \\\n  V(ArmI8x16SConvertI16x8)         \\\n  V(ArmI8x16Add)                   \\\n  V(ArmI8x16AddSatS)               \\\n  V(ArmI8x16Sub)                   \\\n  V(ArmI8x16SubSatS)               \\\n  V(ArmI8x16MinS)                  \\\n  V(ArmI8x16MaxS)                  \\\n  V(ArmI8x16Eq)                    \\\n  V(ArmI8x16Ne)                    \\\n  V(ArmI8x16GtS)                   \\\n  V(ArmI8x16GeS)                   \\\n  V(ArmI8x16ExtractLaneU)          \\\n  V(ArmI8x16ShrU)                  \\\n  V(ArmI8x16UConvertI16x8)         \\\n  V(ArmI8x16AddSatU)               \\\n  V(ArmI8x16SubSatU)               \\\n  V(ArmI8x16MinU)                  \\\n  V(ArmI8x16MaxU)                  \\\n  V(ArmI8x16GtU)                   \\\n  V(ArmI8x16GeU)                   \\\n  V(ArmI8x16RoundingAverageU)      \\\n  V(ArmI8x16Abs)                   \\\n  V(ArmI8x16BitMask)               \\\n  V(ArmS128Const)                  \\\n  V(ArmS128Zero)                   \\\n  V(ArmS128AllOnes)                \\\n  V(ArmS128Dup)                    \\\n  V(ArmS128And)                    \\\n  V(ArmS128Or)                     \\\n  V(ArmS128Xor)                    \\\n  V(ArmS128Not)                    \\\n  V(ArmS128Select)                 \\\n  V(ArmS128AndNot)                 \\\n  V(ArmS32x4ZipLeft)               \\\n  V(ArmS32x4ZipRight)              \\\n  V(ArmS32x4UnzipLeft)             \\\n  V(ArmS32x4UnzipRight)            \\\n  V(ArmS32x4TransposeLeft)         \\\n  V(ArmS32x4TransposeRight)        \\\n  V(ArmS32x4Shuffle)               \\\n  V(ArmS16x8ZipLeft)               \\\n  V(ArmS16x8ZipRight)              \\\n  V(ArmS16x8UnzipLeft)             \\\n  V(ArmS16x8UnzipRight)            \\\n  V(ArmS16x8TransposeLeft)         \\\n  V(ArmS16x8TransposeRight)        \\\n  V(ArmS8x16ZipLeft)               \\\n  V(ArmS8x16ZipRight)              \\\n  V(ArmS8x16UnzipLeft)             \\\n  V(ArmS8x16UnzipRight)            \\\n  V(ArmS8x16TransposeLeft)         \\\n  V(ArmS8x16TransposeRight)        \\\n  V(ArmS8x16Concat)                \\\n  V(ArmI8x16Swizzle)               \\\n  V(ArmI8x16Shuffle)               \\\n  V(ArmS32x2Reverse)               \\\n  V(ArmS16x4Reverse)               \\\n  V(ArmS16x2Reverse)               \\\n  V(ArmS8x8Reverse)                \\\n  V(ArmS8x4Reverse)                \\\n  V(ArmS8x2Reverse)                \\\n  V(ArmI64x2AllTrue)               \\\n  V(ArmI32x4AllTrue)               \\\n  V(ArmI16x8AllTrue)               \\\n  V(ArmV128AnyTrue)               \\\n  V(ArmI8x16AllTrue)               \\\n  V(ArmS128Load8Splat)             \\\n  V(ArmS128Load16Splat)            \\\n  V(ArmS128Load32Splat)            \\\n  V(ArmS128Load64Splat)            \\\n  V(ArmS128Load8x8S)               \\\n  V(ArmS128Load8x8U)               \\\n  V(ArmS128Load16x4S)              \\\n  V(ArmS128Load16x4U)              \\\n  V(ArmS128Load32x2S)              \\\n  V(ArmS128Load32x2U)              \\\n  V(ArmS128Load32Zero)             \\\n  V(ArmS128Load64Zero)             \\\n  V(ArmS128LoadLaneLow)            \\\n  V(ArmS128LoadLaneHigh)           \\\n  V(ArmS128StoreLaneLow)           \\\n  V(ArmS128StoreLaneHigh)          \\\n  V(ArmWord32AtomicPairLoad)       \\\n  V(ArmWord32AtomicPairStore)      \\\n  V(ArmWord32AtomicPairAdd)        \\\n  V(ArmWord32AtomicPairSub)        \\\n  V(ArmWord32AtomicPairAnd)        \\\n  V(ArmWord32AtomicPairOr)         \\\n  V(ArmWord32AtomicPairXor)        \\\n  V(ArmWord32AtomicPairExchange)   \\\n  V(ArmWord32AtomicPairCompareExchange)"
    },
    {
      "metadata": {
        "language": "cpp",
        "type": "macro",
        "name": "TARGET_ADDRESSING_MODE_LIST",
        "about": "Defines a list of ARM-specific addressing modes using a macro.",
        "attributes": [],
        "dependencies": []
      },
      "code": "#define TARGET_ADDRESSING_MODE_LIST(V)  \\\n  V(Offset_RI)        /* [%r0 + K] */   \\\n  V(Offset_RR)        /* [%r0 + %r1] */ \\\n  V(Operand2_I)       /* K */           \\\n  V(Operand2_R)       /* %r0 */         \\\n  V(Operand2_R_ASR_I) /* %r0 ASR K */   \\\n  V(Operand2_R_LSL_I) /* %r0 LSL K */   \\\n  V(Operand2_R_LSR_I) /* %r0 LSR K */   \\\n  V(Operand2_R_ROR_I) /* %r0 ROR K */   \\\n  V(Operand2_R_ASR_R) /* %r0 ASR %r1 */ \\\n  V(Operand2_R_LSL_R) /* %r0 LSL %r1 */ \\\n  V(Operand2_R_LSR_R) /* %r0 LSR %r1 */ \\\n  V(Operand2_R_ROR_R) /* %r0 ROR %r1 */ \\\n  V(Root)             /* [%rr + K] */"
    }
  ],
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/arm/instruction-codes-arm.h"
}