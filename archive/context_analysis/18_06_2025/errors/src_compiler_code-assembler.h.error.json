{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/code-assembler.h",
  "error": "Response not JSON and not XML-like after cleanup",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "raw_response": "```xml\n<file>\n    <metadata>\n    {\n        \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/code-assembler.h\",\n        \"file_name\": \"code-assembler.h\",\n        \"language\": \"cpp\",\n        \"purpose\": \"Defines the CodeAssembler class, a public interface for generating code objects with TurboFan's backend.  It provides an abstraction layer over RawMachineAssembler and offers features like variable management and enhanced label functionality.\"\n    }\n    </metadata>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Includes standard library headers for various functionalities like initializer lists, maps, memory management, optional values, string streams, and type traits.\"\n        }\n        </metadata>\n        <code><![CDATA[\n            #include <initializer_list>\n            #include <map>\n            #include <memory>\n            #include <optional>\n            #include <sstream>\n            #include <type_traits>\n        ]]></code>\n    </imports>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Includes V8 headers that are safe to include outside the compiler directory.  These provide essential types and functionalities related to builtins, code generation, heap objects, runtime functions, and zone management.\"\n        }\n        </metadata>\n        <code><![CDATA[\n            #include \"include/cppgc/source-location.h\"\n            #include \"src/base/macros.h\"\n            #include \"src/builtins/builtins.h\"\n            #include \"src/codegen/atomic-memory-order.h\"\n            #include \"src/codegen/callable.h\"\n            #include \"src/codegen/handler-table.h\"\n            #include \"src/codegen/machine-type.h\"\n            #include \"src/codegen/source-position.h\"\n            #include \"src/codegen/tnode.h\"\n            #include \"src/heap/heap.h\"\n            #include \"src/objects/object-type.h\"\n            #include \"src/objects/objects.h\"\n            #include \"src/runtime/runtime.h\"\n            #include \"src/zone/zone-containers.h\"\n        ]]></code>\n    </imports>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Conditionally includes the wasm-builtin-list.h header when WebAssembly is enabled.\"\n        }\n        </metadata>\n        <code><![CDATA[\n            #if V8_ENABLE_WEBASSEMBLY\n            #include \"src/wasm/wasm-builtin-list.h\"\n            #endif\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"BuiltinCompilationScheduler\",\n            \"about\": \"A scheduler to ensure deterministic builtin compilation regardless of v8_flags.concurrent_builtin_generation.\",\n            \"attributes\": [\n                {\n                    \"name\": \"builtins_installed_count_\",\n                    \"type\": \"int\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Counts the number of builtins installed.\"\n                },\n                {\n                    \"name\": \"current_batch_zone_size_\",\n                    \"type\": \"size_t\",\n                    \"access\": \"private\",\n                    \"purpose\": \"The sum of the size of Zones of all queued jobs.\"\n                },\n                {\n                    \"name\": \"main_thread_output_queue_\",\n                    \"type\": \"std::deque<std::unique_ptr<TurbofanCompilationJob>>\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Queue to keep the allocation order identical between generating builtins concurrently and non-concurrently for reproducible builds.\"\n                }\n            ],\n            \"dependencies\": [\n                \"TurbofanCompilationJob\",\n                \"Isolate\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n            class BuiltinCompilationScheduler {\n           public:\n            ~BuiltinCompilationScheduler();\n\n            int builtins_installed_count() const { return builtins_installed_count_; }\n\n            void CompileCode(Isolate* isolate,\n                             std::unique_ptr<TurbofanCompilationJob> job);\n\n            void AwaitAndFinalizeCurrentBatch(Isolate* isolate);\n\n           private:\n            void QueueJob(Isolate* isolate,\n                          std::unique_ptr<TurbofanCompilationJob> job);\n\n            void FinalizeJobOnMainThread(Isolate* isolate, TurbofanCompilationJob* job);\n\n            int builtins_installed_count_ = 0;\n\n            // The sum of the size of Zones of all queued jobs.\n            size_t current_batch_zone_size_ = 0;\n\n            // Only used when !v8_flags.concurrent_builtin_generation. Used to keep the\n            // allocation order identical between generating builtins concurrently and\n            // non-concurrently for reproducible builds.\n            std::deque<std::unique_ptr<TurbofanCompilationJob>>\n                main_thread_output_queue_;\n          };\n        ]]></code>\n    </class>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"CodeAssembler\",\n            \"about\": \"A public interface used by components outside of the compiler directory to create code objects with TurboFan's backend.\",\n            \"attributes\": [\n                {\n                    \"name\": \"state_\",\n                    \"type\": \"CodeAssemblerState*\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Pointer to the CodeAssemblerState object, which encapsulates the state of the CodeAssembler.\"\n                }\n            ],\n            \"dependencies\": [\n                \"CodeAssemblerState\",\n                \"CodeAssemblerLabel\",\n                \"TypedCodeAssemblerVariable\",\n                \"CodeAssemblerVariableList\",\n                \"Label\",\n                \"TVariable\",\n                \"VariableList\",\n                \"Builtin\",\n                \"Isolate\",\n                \"TurbofanCompilationJob\",\n                \"CallInterfaceDescriptor\",\n                \"Code\",\n                \"Callable\",\n                \"ExternalReference\",\n                \"ObjectTypeOf\",\n                \"Node\",\n                \"JSGraph\",\n                \"RawMachineAssembler\",\n                \"RawMachineLabel\",\n                \"Signature\",\n                \"Zone\",\n                \"Factory\",\n                \"Context\",\n                \"JSFunction\",\n                \"HeapObject\",\n                \"Map\",\n                \"AtomicMemoryOrder\",\n                \"MachineRepresentation\",\n                \"PairT\",\n                \"RootIndex\",\n                \"Smi\",\n                \"CodeAssemblerParameterizedLabel\",\n                \"Object\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n            class V8_EXPORT_PRIVATE CodeAssembler {\n         public:\n          explicit CodeAssembler(CodeAssemblerState* state) : state_(state) {}\n          ~CodeAssembler();\n\n          CodeAssembler(const CodeAssembler&) = delete;\n          CodeAssembler& operator=(const CodeAssembler&) = delete;\n\n          bool Is64() const;\n          bool Is32() const;\n          bool IsFloat64RoundUpSupported() const;\n          bool IsFloat64RoundDownSupported() const;\n          bool IsFloat64RoundTiesEvenSupported() const;\n          bool IsFloat64RoundTruncateSupported() const;\n          bool IsTruncateFloat64ToFloat16RawBitsSupported() const;\n          bool IsInt32AbsWithOverflowSupported() const;\n          bool IsInt64AbsWithOverflowSupported() const;\n          bool IsIntPtrAbsWithOverflowSupported() const;\n          bool IsWord32PopcntSupported() const;\n          bool IsWord64PopcntSupported() const;\n          bool IsWord32CtzSupported() const;\n          bool IsWord64CtzSupported() const;\n\n          // A scheduler to ensure deterministic builtin compilation regardless of\n          // v8_flags.concurrent_builtin_generation.\n          //\n          // Builtin jobs are compiled in three (3) stages: PrepareJob, ExecuteJob, and\n          // FinalizeJob.\n          //\n          // PrepareJob and FinalizeJob may allocate on the heap and must run on the\n          // main thread. ExecuteJob only allocates in the job's Zone and may run on a\n          // helper thread. To ensure deterministic builds, there must be a total order\n          // of all heap allocations across all spaces. In other words, there must be a\n          // single total order of PrepareJob and FinalizeJob calls.\n          //\n          // This order is enforced by batching according to zone size. For each batch,\n          //\n          //   1. In ascending order of job->FinalizeOrder(), call PrepareJob for each\n          //      job.\n          //   2. Call ExecuteJob for each job in the batch in any order, possibly in\n          //      parallel.\n          //   3. In ascending order of job->FinalizeOrder(), call FinalizeJob for each\n          //      job.\n          //\n          // Example use:\n          //\n          // BuiltinCompilationScheduler scheduler;\n          // scheduler.CompileCode(job1);\n          // scheduler.CompileCode(job2);\n          // scheduler.AwaitAndFinalizeCurrentBatch();\n          class BuiltinCompilationScheduler {\n           public:\n            ~BuiltinCompilationScheduler();\n\n            int builtins_installed_count() const { return builtins_installed_count_; }\n\n            void CompileCode(Isolate* isolate,\n                             std::unique_ptr<TurbofanCompilationJob> job);\n\n            void AwaitAndFinalizeCurrentBatch(Isolate* isolate);\n\n           private:\n            void QueueJob(Isolate* isolate,\n                          std::unique_ptr<TurbofanCompilationJob> job);\n\n            void FinalizeJobOnMainThread(Isolate* isolate, TurbofanCompilationJob* job);\n\n            int builtins_installed_count_ = 0;\n\n            // The sum of the size of Zones of all queued jobs.\n            size_t current_batch_zone_size_ = 0;\n\n            // Only used when !v8_flags.concurrent_builtin_generation. Used to keep the\n            // allocation order identical between generating builtins concurrently and\n            // non-concurrently for reproducible builds.\n            std::deque<std::unique_ptr<TurbofanCompilationJob>>\n                main_thread_output_queue_;\n          };\n\n          // Shortened aliases for use in CodeAssembler subclasses.\n          using Label = CodeAssemblerLabel;\n          template <class T>\n          using TVariable = TypedCodeAssemblerVariable<T>;\n          using VariableList = CodeAssemblerVariableList;\n\n          // ===========================================================================\n          // Base Assembler\n          // ===========================================================================\n\n          template <class PreviousType, bool FromTyped>\n          class CheckedNode {\n           public:\n        #ifdef DEBUG\n            CheckedNode(Node* node, CodeAssembler* code_assembler, const char* location)\n                : node_(node), code_assembler_(code_assembler), location_(location) {}\n        #else\n            CheckedNode(compiler::Node* node, CodeAssembler*, const char*)\n                : node_(node) {}\n        #endif\n\n            template <class A>\n            operator TNode<A>() {\n              static_assert(!std::is_same<A, Tagged<MaybeObject>>::value,\n                            \"Can't cast to Tagged<MaybeObject>, use explicit \"\n                            \"conversion functions. \");\n\n              static_assert(types_have_common_values<A, PreviousType>::value,\n                            \"Incompatible types: this cast can never succeed.\");\n              static_assert(std::is_convertible<TNode<A>, TNode<MaybeObject>>::value ||\n                                std::is_convertible<TNode<A>, TNode<Object>>::value,\n                            \"Coercion to untagged values cannot be \"\n                            \"checked.\");\n              static_assert(\n                  !FromTyped ||\n                      !std::is_convertible<TNode<PreviousType>, TNode<A>>::value,\n                  \"Unnecessary CAST: types are convertible.\");\n        #ifdef DEBUG\n              if (v8_flags.slow_debug_code) {\n                TNode<ExternalReference> function = code_assembler_->ExternalConstant(\n                    ExternalReference::check_object_type());\n                code_assembler_->CallCFunction(\n                    function, MachineType::AnyTagged(),\n                    std::make_pair(MachineType::AnyTagged(), node_),\n                    std::make_pair(MachineType::TaggedSigned(),\n                                   code_assembler_->SmiConstant(\n                                       static_cast<int>(ObjectTypeOf<A>::value))),\n                    std::make_pair(MachineType::AnyTagged(),\n                                   code_assembler_->StringConstant(location_)));\n              }\n        #endif\n              return TNode<A>::UncheckedCast(node_);\n            }\n\n            Node* node() const { return node_; }\n\n           private:\n            Node* node_;\n        #ifdef DEBUG\n            CodeAssembler* code_assembler_;\n            const char* location_;\n        #endif\n          };\n\n          template <class T>\n          TNode<T> UncheckedCast(Node* value) {\n            return TNode<T>::UncheckedCast(value);\n          }\n          template <class T, class U>\n          TNode<T> UncheckedCast(TNode<U> value) {\n            static_assert(types_have_common_values<T, U>::value,\n                          \"Incompatible types: this cast can never succeed.\");\n            return TNode<T>::UncheckedCast(value);\n          }\n\n          // ReinterpretCast<T>(v) has the power to cast even when the type of v is\n          // unrelated to T. Use with care.\n          template <class T>\n          TNode<T> ReinterpretCast(Node* value) {\n            return TNode<T>::UncheckedCast(value);\n          }\n\n          CheckedNode<Object, false> Cast(Node* value, const char* location = \"\") {\n            return {value, this, location};\n          }\n\n          template <class T>\n          CheckedNode<T, true> Cast(TNode<T> value, const char* location = \"\") {\n            return {value, this, location};\n          }\n\n        #ifdef DEBUG\n        #define STRINGIFY(x) #x\n        #define TO_STRING_LITERAL(x) STRINGIFY(x)\n        #define CAST(x) \\\n          Cast(x, \"CAST(\" #x \") at \" __FILE__ \":\" TO_STRING_LITERAL(__LINE__))\n        #define TORQUE_CAST(...)                                      \\\n          ca_.Cast(__VA_ARGS__, \"CAST(\" #__VA_ARGS__ \") at \" __FILE__ \\\n                                \":\" TO_STRING_LITERAL(__LINE__))\n        #else\n        #define CAST(x) Cast(x)\n        #define TORQUE_CAST(...) ca_.Cast(__VA_ARGS__)\n        #endif\n\n          // Constants.\n          TNode<Int32T> UniqueInt32Constant(int32_t value);\n          TNode<Int32T> Int32Constant(int32_t value);\n          TNode<Int64T> UniqueInt64Constant(int64_t value);\n          TNode<Int64T> Int64Constant(int64_t value);\n          TNode<Uint64T> Uint64Constant(uint64_t value) {\n            return Unsigned(Int64Constant(base::bit_cast<int64_t>(value)));\n          }\n          TNode<IntPtrT> IntPtrConstant(intptr_t value);\n          TNode<IntPtrT> UniqueIntPtrConstant(intptr_t value);\n          TNode<Uint32T> UniqueUint32Constant(int32_t value) {\n            return Unsigned(UniqueInt32Constant(base::bit_cast<int32_t>(value)));\n          }\n          TNode<Uint32T> Uint32Constant(uint32_t value) {\n            return Unsigned(Int32Constant(base::bit_cast<int32_t>(value)));\n          }\n          TNode<Uint32T> Uint64HighWordConstant(uint64_t value) {\n            return Uint32Constant(value >> 32);\n          }\n          TNode<Uint32T> Uint64HighWordConstantNoLowWord(uint64_t value) {\n            DCHECK_EQ(0, value & ~uint32_t{0});\n            return Uint64HighWordConstant(value);\n          }\n          TNode<Uint32T> Uint64LowWordConstant(uint64_t value) {\n            return Uint32Constant(static_cast<uint32_t>(value));\n          }\n          TNode<UintPtrT> UintPtrConstant(uintptr_t value) {\n            return Unsigned(IntPtrConstant(base::bit_cast<intptr_t>(value)));\n          }\n          TNode<TaggedIndex> TaggedIndexConstant(intptr_t value);\n          TNode<RawPtrT> PointerConstant(void* value) {\n            return ReinterpretCast<RawPtrT>(\n                IntPtrConstant(reinterpret_cast<intptr_t>(value)));\n          }\n          TNode<Number> NumberConstant(double value);\n          TNode<Smi> SmiConstant(Tagged<Smi> value);\n          TNode<Smi> SmiConstant(int value);\n          template <typename E>\n          TNode<Smi> SmiConstant(E value)\n            requires std::is_enum<E>::value\n          {\n            static_assert(sizeof(E) <= sizeof(int));\n            return SmiConstant(static_cast<int>(value));\n          }\n\n          void CanonicalizeEmbeddedBuiltinsConstantIfNeeded(Handle<HeapObject> object);\n          TNode<HeapObject> UntypedHeapConstantNoHole(Handle<HeapObject> object);\n          TNode<HeapObject> UntypedHeapConstantMaybeHole(Handle<HeapObject> object);\n          TNode<HeapObject> UntypedHeapConstantHole(Handle<HeapObject> object);\n          template <class Type>\n          TNode<Type> HeapConstantNoHole(Handle<Type> object) {\n            return UncheckedCast<Type>(UntypedHeapConstantNoHole(object));\n          }\n          template <class Type>\n          TNode<Type> HeapConstantMaybeHole(Handle<Type> object) {\n            return UncheckedCast<Type>(UntypedHeapConstantMaybeHole(object));\n          }\n          template <class Type>\n          TNode<Type> HeapConstantHole(Handle<Type> object) {\n            return UncheckedCast<Type>(UntypedHeapConstantHole(object));\n          }\n          TNode<String> StringConstant(const char* str);\n          TNode<Boolean> BooleanConstant(bool value);\n          TNode<ExternalReference> ExternalConstant(ExternalReference address);\n          TNode<ExternalReference> IsolateField(IsolateFieldId id);\n          TNode<Float32T> Float32Constant(double value);\n          TNode<Float64T> Float64Constant(double value);\n          TNode<BoolT> Int32TrueConstant() {\n            return ReinterpretCast<BoolT>(Int32Constant(1));\n          }\n          TNode<BoolT> Int32FalseConstant() {\n            return ReinterpretCast<BoolT>(Int32Constant(0));\n          }\n          TNode<BoolT> BoolConstant(bool value) {\n            return value ? Int32TrueConstant() : Int32FalseConstant();\n          }\n          TNode<ExternalPointerHandleT> ExternalPointerHandleNullConstant() {\n            return ReinterpretCast<ExternalPointerHandleT>(Uint32Constant(0));\n          }\n\n          bool IsMapOffsetConstant(Node* node);\n\n          bool TryToInt32Constant(TNode<IntegralT> node, int32_t* out_value);\n          bool TryToInt64Constant(TNode<IntegralT> node, int64_t* out_value);\n          bool TryToIntPtrConstant(TNode<IntegralT> node, intptr_t* out_value);\n          bool TryToIntPtrConstant(TNode<Smi> tnode, intptr_t* out_value);\n          bool TryToSmiConstant(TNode<IntegralT> node, Tagged<Smi>* out_value);\n          bool TryToSmiConstant(TNode<Smi> node, Tagged<Smi>* out_value);\n\n          bool IsUndefinedConstant(TNode<Object> node);\n          bool IsNullConstant(TNode<Object> node);\n\n          TNode<Int32T> Signed(TNode<Word32T> x) { return UncheckedCast<Int32T>(x); }\n          TNode<Int64T> Signed(TNode<Word64T> x) { return UncheckedCast<Int64T>(x); }\n          TNode<IntPtrT> Signed(TNode<WordT> x) { return UncheckedCast<IntPtrT>(x); }\n          TNode<Uint32T> Unsigned(TNode<Word32T> x) {\n            return UncheckedCast<Uint32T>(x);\n          }\n          TNode<Uint64T> Unsigned(TNode<Word64T> x) {\n            return UncheckedCast<Uint64T>(x);\n          }\n          TNode<UintPtrT> Unsigned(TNode<WordT> x) {\n            return UncheckedCast<UintPtrT>(x);\n          }\n\n          // Support for code with a \"dynamic\" parameter count.\n          //\n          // Code assembled by our code assembler always has a \"static\" parameter count\n          // as defined by the call descriptor for the code. This parameter count is\n          // known at compile time. However, some builtins also have a \"dynamic\"\n          // parameter count because they can be installed on different function\n          // objects with different parameter counts. In that case, the actual\n          // parameter count is only known at runtime. Examples of such builtins\n          // include the CompileLazy builtin and the InterpreterEntryTrampoline, or the\n          // generic JSToWasm and JSToJS wrappers. These builtins then may have to\n          // obtain the \"dynamic\" parameter count, for example to correctly remove all\n          // function arguments (including padding arguments) from the stack.\n          bool HasDynamicJSParameterCount();\n          TNode<Uint16T> DynamicJSParameterCount();\n          void SetDynamicJSParameterCount(TNode<Uint16T> parameter_count);\n\n          static constexpr int kTargetParameterIndex = kJSCallClosureParameterIndex;\n          static_assert(kTargetParameterIndex == -1);\n\n          template <class T>\n          TNode<T> Parameter(int value,\n                             const SourceLocation& loc = SourceLocation::Current()) {\n            static_assert(\n                std::is_convertible<TNode<T>, TNode<Object>>::value,\n                \"Parameter is only for tagged types. Use UncheckedParameter instead.\");\n            std::stringstream message;\n            message << \"Parameter \" << value;\n            if (loc.FileName()) {\n              message << \" at \" << loc.FileName() << \":\" << loc.Line();\n            }\n            size_t buf_size = message.str().size() + 1;\n            char* message_dup = zone()->AllocateArray<char>(buf_size);\n            snprintf(message_dup, buf_size, \"%s\", message.str().c_str());\n\n            return Cast(UntypedParameter(value), message_dup);\n          }\n\n          template <class T>\n          TNode<T> UncheckedParameter(int value) {\n            return UncheckedCast<T>(UntypedParameter(value));\n          }\n\n          Node* UntypedParameter(int value);\n\n          TNode<Context> GetJSContextParameter();\n          void Return(TNode<Object> value);\n          void Return(TNode<Object> value1, TNode<Object> value2);\n          void Return(TNode<Object> value1, TNode<Object> value2, TNode<Object> value3);\n          void Return(TNode<Int32T> value);\n          void Return(TNode<Uint32T> value);\n          void Return(TNode<WordT> value);\n          void Return(TNode<Float32T> value);\n          void Return(TNode<Float64T> value);\n          void Return(TNode<WordT> value1, TNode<WordT> value2);\n          void Return(TNode<Word32T> value1, TNode<Word32T> value2);\n          void Return(TNode<WordT> value1, TNode<Object> value2);\n          void Return(TNode<Word32T> value1, TNode<Object> value2);\n          void PopAndReturn(Node* pop, Node* value);\n          void PopAndReturn(Node* pop, Node* value1, Node* value2, Node* value3,\n                            Node* value4);\n\n          void ReturnIf(TNode<BoolT> condition, TNode<Object> value);\n\n          void AbortCSADcheck(Node* message);\n          void DebugBreak();\n          void Unreachable();\n\n          // Hack for supporting SourceLocation alongside template packs.\n          struct MessageWithSourceLocation {\n            const char* message;\n            const SourceLocation& loc;\n\n            // Allow implicit construction, necessary for the hack.\n            // NOLINTNEXTLINE\n            MessageWithSourceLocation(\n                const char* message,\n                const SourceLocation& loc = SourceLocation::Current())\n                : message(message), loc(loc) {}\n          };\n          template <class... Args>\n          void Comment(MessageWithSourceLocation message, Args&&... args) {\n            if (!v8_flags.code_comments) return;\n            std::ostringstream s;\n            USE(s << message.message, (s << std::forward<Args>(args))...);\n            if (message.loc.FileName()) {\n              s << \" - \" << message.loc.ToString();\n            }\n            EmitComment(std::move(s).str());\n          }\n\n          void StaticAssert(TNode<BoolT> value,\n                            const char* source = \"unknown position\");\n\n          // The following methods refer to source positions in CSA or Torque code\n          // compiled during mksnapshot, not JS compiled at runtime.\n          void SetSourcePosition(const char* file, int line);\n          void PushSourcePosition();\n          void PopSourcePosition();\n          class V8_NODISCARD SourcePositionScope {\n           public:\n            explicit SourcePositionScope(CodeAssembler* ca) : ca_(ca) {\n              ca->PushSourcePosition();\n            }\n            ~SourcePositionScope() { ca_->PopSourcePosition(); }\n\n           private:\n            CodeAssembler* ca_;\n          };\n          const std::vector<FileAndLine>& GetMacroSourcePositionStack() const;\n\n          void Bind(Label* label);\n        #if DEBUG\n          void Bind(Label* label, AssemblerDebugInfo debug_info);\n        #endif  // DEBUG\n          void Goto(Label* label);\n\n          void GotoIf(TNode<IntegralT> condition, Label* true_label,\n                      GotoHint goto_hint = GotoHint::kNone);\n          void GotoIfNot(TNode<IntegralT> condition, Label* false_label,\n                         GotoHint goto_hint = GotoHint::kNone);\n          void Branch(TNode<IntegralT> condition, Label* true_label, Label* false_label,\n                      BranchHint branch_hint = BranchHint::kNone);\n\n          template <class T>\n          TNode<T> Uninitialized() {\n            return {};\n          }\n\n          template <class... T>\n          void Bind(CodeAssemblerParameterizedLabel<T...>* label, TNode<T>*... phis) {\n            Bind(label->plain_label());\n            label->CreatePhis(phis...);\n          }\n          template <class... T, class... Args>\n          void Branch(TNode<BoolT> condition,\n                      CodeAssemblerParameterizedLabel<T...>* if_true,\n                      CodeAssemblerParameterizedLabel<T...>* if_false, Args... args) {\n            if_true->AddInputs(args...);\n            if_false->AddInputs(args...);\n            Branch(condition, if_true->plain_label(), if_false->plain_label());\n          }\n          template <class... T, class... U>\n          void Branch(TNode<BoolT> condition,\n                      CodeAssemblerParameterizedLabel<T...>* if_true,\n                      std::vector<Node*> args_true,\n                      CodeAssemblerParameterizedLabel<U...>* if_false,\n                      std::vector<Node*> args_false) {\n            if_true->AddInputsVector(std::move(args_true));\n            if_false->AddInputsVector(std::move(args_false));\n            Branch(condition, if_true->plain_label(), if_false->plain_label());\n          }\n\n          template <class... T, class... Args>\n          void Goto(CodeAssemblerParameterizedLabel<T...>* label, Args... args) {\n            label->AddInputs(args...);\n            Goto(label->plain_label());\n          }\n\n          void Branch(TNode<BoolT> condition, const std::function<void()>& true_body,\n                      const std::function<void()>& false_body);\n          void Branch(TNode<BoolT> condition, Label* true_label,\n                      const std::function<void()>& false_body);\n          void Branch(TNode<BoolT> condition, const std::function<void()>& true_body,\n                      Label* false_label);\n\n          void Switch(Node* index, Label* default_label, const int32_t* case_values,\n                      Label** case_labels, size_t case_count);\n\n          // Access to the frame pointer.\n          TNode<RawPtrT> LoadFramePointer();\n          TNode<RawPtrT> LoadParentFramePointer();\n          TNode<RawPtrT> StackSlotPtr(int size, int alignment);\n\n        #if V8_ENABLE_WEBASSEMBLY\n          // Access to the stack pointer.\n          TNode<RawPtrT> LoadStackPointer();\n          void SetStackPointer(TNode<RawPtrT> ptr);\n        #endif  // V8_ENABLE_WEBASSEMBLY\n\n          TNode<RawPtrT> LoadPointerFromRootRegister(TNode<IntPtrT> offset);\n          TNode<Uint8T> LoadUint8FromRootRegister(TNode<IntPtrT> offset);\n\n          // Load raw memory location.\n          Node* Load(MachineType type, Node* base);\n          template <class Type>\n          TNode<Type> Load(MachineType type, TNode<RawPtr<Type>> base) {\n            DCHECK(\n                IsSubtype(type.representation(), MachineRepresentationOf<Type>::value));\n            return UncheckedCast<Type>(Load(type, static_cast<Node*>(base)));\n          }\n          Node* Load(MachineType type, Node* base, Node* offset);\n          template <class Type>\n          TNode<Type> Load(Node* base) {\n            return UncheckedCast<Type>(Load(MachineTypeOf<Type>::value, base));\n          }\n          template <class Type>\n          TNode<Type> Load(Node* base, TNode<WordT> offset) {\n            return UncheckedCast<Type>(Load(MachineTypeOf<Type>::value, base, offset));\n          }\n          template <class Type>\n          TNode<Type> AtomicLoad(AtomicMemoryOrder order, TNode<RawPtrT> base,\n                                 TNode<WordT> offset) {\n            return UncheckedCast<Type>(\n                AtomicLoad(MachineTypeOf<Type>::value, order, base, offset));\n          }\n          template <class Type>\n          TNode<Type> AtomicLoad64(AtomicMemoryOrder order, TNode<RawPtrT> base,\n                                   TNode<WordT> offset);\n          // Load uncompressed tagged value from (most likely off JS heap) memory\n          // location.\n          TNode<Object> LoadFullTagged(Node* base);\n          TNode<Object> LoadFullTagged(Node* base, TNode<IntPtrT> offset);\n\n          Node* LoadFromObject(MachineType type, TNode<Object> object,\n                               TNode<IntPtrT> offset);\n          Node* LoadProtectedPointerFromObject(TNode<Object> object,\n                                               TNode<IntPtrT> offset);\n\n        #ifdef V8_MAP_PACKING\n          Node* PackMapWord(Node* value);\n        #endif\n\n          // Load a value from the root array.\n          // If map packing is enabled, LoadRoot for a root map returns the unpacked map\n          // word (i.e., the map). Use LoadRootMapWord to obtain the packed map word\n          // instead.\n          TNode<Object> LoadRoot(RootIndex root_index);\n          TNode<AnyTaggedT> LoadRootMapWord(RootIndex root_index);\n\n          template <typename Type>\n          TNode<Type> UnalignedLoad(TNode<RawPtrT> base, TNode<IntPtrT> offset) {\n            MachineType mt = MachineTypeOf<Type>::value;\n            return UncheckedCast<Type>(UnalignedLoad(mt, base, offset));\n          }\n\n          // Store value to raw memory location.\n          void Store(Node* base, Node* value);\n          void Store(Node* base, Node* offset, Node* value);\n          void StoreEphemeronKey(Node* base, Node* offset, Node* value);\n          void StoreNoWriteBarrier(MachineRepresentation rep, Node* base, Node* value);\n          void StoreNoWriteBarrier(MachineRepresentation rep, Node* base, Node* offset,\n                                   Node* value);\n          void UnsafeStoreNoWriteBarrier(MachineRepresentation rep, Node* base,\n                                         Node* value);\n          void UnsafeStoreNoWriteBarrier(MachineRepresentation rep, Node* base,\n                                         Node* offset, Node* value);\n\n          // Stores uncompressed tagged value to (most likely off JS heap) memory\n          // location without write barrier.\n          void StoreFullTaggedNoWriteBarrier(TNode<RawPtrT> base,\n                                             TNode<Object> tagged_value);\n          void StoreFullTaggedNoWriteBarrier(TNode<RawPtrT> base, TNode<IntPtrT> offset,\n                                             TNode<Object> tagged_value);\n\n          // Optimized memory operations that map to Turbofan simplified nodes.\n          TNode<HeapObject> OptimizedAllocate(TNode<IntPtrT> size,\n                                              AllocationType allocation);\n          void StoreToObject(MachineRepresentation rep, TNode<Object> object,\n                             TNode<IntPtrT> offset, Node* value,\n                             StoreToObjectWriteBarrier write_barrier);\n          void OptimizedStoreField(MachineRepresentation rep, TNode<HeapObject> object,\n                                   int offset, Node* value);\n          void OptimizedStoreIndirectPointerField(TNode<HeapObject> object, int offset,\n                                            IndirectPointerTag"
}