{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/turboshaft/growable-stacks-reducer.h",
  "error": "JSON and XML parsing failed",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "xml_error": "mismatched tag: line 253, column 10",
  "raw_response": "```xml\n<file>\n    <metadata>\n    {\n        \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/turboshaft/growable-stacks-reducer.h\",\n        \"file_name\": \"growable-stacks-reducer.h\",\n        \"language\": \"cpp\",\n        \"purpose\": \"Defines the GrowableStacksReducer class, which optimizes stack checks and return operations for WebAssembly growable stacks in the Turboshaft compiler.\"\n    }\n    </metadata>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Include necessary V8 headers for compiler globals, Turboshaft graph manipulation, operations, phases, representations, and uniform reducer adapter.\"\n        }\n        </metadata>\n        <code><![CDATA[\n#include \"src/compiler/globals.h\"\n#include \"src/compiler/turboshaft/assembler.h\"\n#include \"src/compiler/turboshaft/graph.h\"\n#include \"src/compiler/turboshaft/index.h\"\n#include \"src/compiler/turboshaft/operations.h\"\n#include \"src/compiler/turboshaft/phase.h\"\n#include \"src/compiler/turboshaft/representations.h\"\n#include \"src/compiler/turboshaft/uniform-reducer-adapter.h\"\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"GrowableStacksReducer\",\n            \"extends\": \"Next\",\n            \"about\": \"A Turboshaft reducer that optimizes stack checks and return operations for WebAssembly growable stacks.\",\n            \"attributes\": [\n                {\n                    \"name\": \"skip_reducer_\",\n                    \"type\": \"bool\",\n                    \"access\": \"private\",\n                    \"purpose\": \"A flag to disable the reducer if growable stacks are not enabled or if not compiling a wasm function.\"\n                },\n                {\n                    \"name\": \"call_descriptor_\",\n                    \"type\": \"CallDescriptor*\",\n                    \"access\": \"private\",\n                    \"purpose\": \"The call descriptor for Wasm calls.\"\n                }\n            ],\n            \"dependencies\": [\n                \"Next\",\n                \"WasmStackCheckOp\",\n                \"compiler::GetWasmCallDescriptor\",\n                \"compiler::GetI32WasmCallDescriptor\",\n                \"compiler::Linkage::GetStubCallDescriptor\",\n                \"TSCallDescriptor::Create\",\n                \"ExternalReference\",\n                \"StackFrame\",\n                \"FrameSlotToFPOffset\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\ntemplate <class Next>\nclass GrowableStacksReducer : public Next {\n public:\n  TURBOSHAFT_REDUCER_BOILERPLATE(GrowableStacks)\n\n  GrowableStacksReducer() {\n    if (!__ data()->wasm_module_sig() ||\n        !v8_flags.experimental_wasm_growable_stacks) {\n      // We are not compiling a wasm function if there is no signature.\n      skip_reducer_ = true;\n      return;\n    }\n    call_descriptor_ = compiler::GetWasmCallDescriptor(\n        __ graph_zone(), __ data()->wasm_module_sig());\n#if V8_TARGET_ARCH_32_BIT\n    call_descriptor_ =\n        compiler::GetI32WasmCallDescriptor(__ graph_zone(), call_descriptor_);\n#endif\n  }\n\n  V<None> REDUCE(WasmStackCheck)(WasmStackCheckOp::Kind kind) {\n    CHECK_EQ(kind, WasmStackCheckOp::Kind::kFunctionEntry);\n    if (skip_reducer_) {\n      return Next::ReduceWasmStackCheck(kind);\n    }\n    // Loads of the stack limit should not be load-eliminated as it can be\n    // modified by another thread.\n    V<WordPtr> limit = __ Load(\n        __ LoadRootRegister(), LoadOp::Kind::RawAligned().NotLoadEliminable(),\n        MemoryRepresentation::UintPtr(), IsolateData::jslimit_offset());\n\n    IF_NOT (LIKELY(__ StackPointerGreaterThan(limit, StackCheckKind::kWasm))) {\n      const int stack_parameter_count = 0;\n      const CallDescriptor* stub_call_descriptor =\n          compiler::Linkage::GetStubCallDescriptor(\n              __ graph_zone(), WasmGrowableStackGuardDescriptor{},\n              stack_parameter_count, CallDescriptor::kNoFlags,\n              Operator::kNoProperties, StubCallMode::kCallWasmRuntimeStub);\n      const TSCallDescriptor* ts_stub_call_descriptor =\n          TSCallDescriptor::Create(stub_call_descriptor,\n                                   compiler::CanThrow::kNo,\n                                   LazyDeoptOnThrow::kNo, __ graph_zone());\n      V<WordPtr> builtin =\n          __ RelocatableWasmBuiltinCallTarget(Builtin::kWasmGrowableStackGuard);\n      auto param_slots_size = __ IntPtrConstant(\n          call_descriptor_->ParameterSlotCount() * kSystemPointerSize);\n      __ Call(\n          builtin, {param_slots_size}, ts_stub_call_descriptor,\n          OpEffects().CanReadMemory().RequiredWhenUnused().CanCreateIdentity());\n    }\n\n    return V<None>::Invalid();\n  }\n\n  OpIndex REDUCE(Return)(V<Word32> pop_count,\n                         base::Vector<const OpIndex> return_values,\n                         bool spill_caller_frame_slots) {\n    if (skip_reducer_ || !spill_caller_frame_slots ||\n        call_descriptor_->ReturnSlotCount() == 0) {\n      return Next::ReduceReturn(pop_count, return_values,\n                                spill_caller_frame_slots);\n    }\n    V<Word32> frame_marker = __ Load(\n        __ FramePointer(), LoadOp::Kind::RawAligned(),\n        MemoryRepresentation::Uint32(), WasmFrameConstants::kFrameTypeOffset);\n\n    Label<WordPtr> done(this);\n    IF (UNLIKELY(__ Word32Equal(\n            frame_marker,\n            StackFrame::TypeToMarker(StackFrame::WASM_SEGMENT_START)))) {\n      auto sig =\n          FixedSizeSignature<MachineType>::Returns(MachineType::Pointer())\n              .Params(MachineType::Pointer());\n      const CallDescriptor* ccall_descriptor =\n          compiler::Linkage::GetSimplifiedCDescriptor(__ graph_zone(), &sig);\n      const TSCallDescriptor* ts_ccall_descriptor = TSCallDescriptor::Create(\n          ccall_descriptor, compiler::CanThrow::kNo,\n          compiler::LazyDeoptOnThrow::kNo, __ graph_zone());\n      GOTO(done, __ template Call<WordPtr>(\n                     __ ExternalConstant(ExternalReference::wasm_load_old_fp()),\n                     OpIndex::Invalid(),\n                     base::VectorOf({__ ExternalConstant(\n                         ExternalReference::isolate_address())}),\n                     ts_ccall_descriptor));\n    } ELSE {\n      GOTO(done, __ FramePointer());\n    }\n    BIND(done, old_fp);\n\n    base::SmallVector<OpIndex, 8> register_return_values;\n    for (size_t i = 0; i < call_descriptor_->ReturnCount(); i++) {\n      LinkageLocation loc = call_descriptor_->GetReturnLocation(i);\n      if (!loc.IsCallerFrameSlot()) {\n        register_return_values.push_back(return_values[i]);\n        continue;\n      }\n      MemoryRepresentation mem_rep =\n          MemoryRepresentation::FromMachineType(loc.GetType());\n      OpIndex ret_value = return_values[i];\n      // Pointers are stored uncompressed on the stacks.\n      // Also, we don't need to mark the stack slot as a reference, because\n      // we are about to return from this frame, so it is the caller's\n      // responsibility to track the tagged return values using the signature.\n      if (mem_rep == MemoryRepresentation::AnyTagged()) {\n        mem_rep = MemoryRepresentation::UintPtr();\n        ret_value = __ BitcastTaggedToWordPtr(ret_value);\n      }\n      __ StoreOffHeap(old_fp, ret_value, mem_rep,\n                      FrameSlotToFPOffset(loc.GetLocation()));\n    }\n    return Next::ReduceReturn(pop_count, base::VectorOf(register_return_values),\n                              spill_caller_frame_slots);\n  }\n\n private:\n  bool skip_reducer_ = false;\n  CallDescriptor* call_descriptor_ = nullptr;\n};\n        ]]></code>\n    </class>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"GrowableStacksReducer\",\n            \"parent\": \"GrowableStacksReducer\",\n            \"about\": \"Constructor for the GrowableStacksReducer. Initializes the reducer and determines if it should be skipped based on whether it is compiling a wasm function with growable stacks enabled.\",\n            \"logic\": \"The constructor checks if the reducer should be skipped if not compiling a wasm function or if growable stacks are not enabled. If not skipped, it retrieves the Wasm call descriptor. On 32-bit architectures, it also retrieves the I32 Wasm call descriptor.\",\n            \"parameters\": [],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"v8_flags.experimental_wasm_growable_stacks\",\n                \"compiler::GetWasmCallDescriptor\",\n                \"compiler::GetI32WasmCallDescriptor\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n  GrowableStacksReducer() {\n    if (!__ data()->wasm_module_sig() ||\n        !v8_flags.experimental_wasm_growable_stacks) {\n      // We are not compiling a wasm function if there is no signature.\n      skip_reducer_ = true;\n      return;\n    }\n    call_descriptor_ = compiler::GetWasmCallDescriptor(\n        __ graph_zone(), __ data()->wasm_module_sig());\n#if V8_TARGET_ARCH_32_BIT\n    call_descriptor_ =\n        compiler::GetI32WasmCallDescriptor(__ graph_zone(), call_descriptor_);\n#endif\n  }\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"REDUCE(WasmStackCheck)\",\n            \"parent\": \"GrowableStacksReducer\",\n            \"about\": \"Reduces Wasm stack checks.  Replaces the stack check with a load of the stack limit and a comparison.\",\n            \"logic\": \"If the reducer is not skipped, this method replaces the standard Wasm stack check with code that loads the stack limit and checks if the stack pointer is greater than the limit. If not, it calls the `kWasmGrowableStackGuard` builtin.\",\n            \"parameters\": [\n                {\n                    \"name\": \"kind\",\n                    \"type\": \"WasmStackCheckOp::Kind\",\n                    \"purpose\": \"The kind of Wasm stack check.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"V<None>\",\n                \"description\": \"An invalid V<None> if reduction occurs; otherwise, the result of the next reducer.\"\n            },\n            \"dependencies\": [\n                \"Next::ReduceWasmStackCheck\",\n                \"__ Load\",\n                \"IsolateData::jslimit_offset\",\n                \"__ StackPointerGreaterThan\",\n                \"compiler::Linkage::GetStubCallDescriptor\",\n                \"TSCallDescriptor::Create\",\n                \"__ RelocatableWasmBuiltinCallTarget\",\n                \"__ Call\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n  V<None> REDUCE(WasmStackCheck)(WasmStackCheckOp::Kind kind) {\n    CHECK_EQ(kind, WasmStackCheckOp::Kind::kFunctionEntry);\n    if (skip_reducer_) {\n      return Next::ReduceWasmStackCheck(kind);\n    }\n    // Loads of the stack limit should not be load-eliminated as it can be\n    // modified by another thread.\n    V<WordPtr> limit = __ Load(\n        __ LoadRootRegister(), LoadOp::Kind::RawAligned().NotLoadEliminable(),\n        MemoryRepresentation::UintPtr(), IsolateData::jslimit_offset());\n\n    IF_NOT (LIKELY(__ StackPointerGreaterThan(limit, StackCheckKind::kWasm))) {\n      const int stack_parameter_count = 0;\n      const CallDescriptor* stub_call_descriptor =\n          compiler::Linkage::GetStubCallDescriptor(\n              __ graph_zone(), WasmGrowableStackGuardDescriptor{},\n              stack_parameter_count, CallDescriptor::kNoFlags,\n              Operator::kNoProperties, StubCallMode::kCallWasmRuntimeStub);\n      const TSCallDescriptor* ts_stub_call_descriptor =\n          TSCallDescriptor::Create(stub_call_descriptor,\n                                   compiler::CanThrow::kNo,\n                                   LazyDeoptOnThrow::kNo, __ graph_zone());\n      V<WordPtr> builtin =\n          __ RelocatableWasmBuiltinCallTarget(Builtin::kWasmGrowableStackGuard);\n      auto param_slots_size = __ IntPtrConstant(\n          call_descriptor_->ParameterSlotCount() * kSystemPointerSize);\n      __ Call(\n          builtin, {param_slots_size}, ts_stub_call_descriptor,\n          OpEffects().CanReadMemory().RequiredWhenUnused().CanCreateIdentity());\n    }\n\n    return V<None>::Invalid();\n  }\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"REDUCE(Return)\",\n            \"parent\": \"GrowableStacksReducer\",\n            \"about\": \"Reduces return operations for WebAssembly with growable stacks.\",\n            \"logic\": \"If the reducer is not skipped and the caller frame slots need to be spilled, this method checks if the current frame is a WASM segment start frame. If it is, it loads the old frame pointer using `wasm_load_old_fp`. Then, it stores any return values that are located in caller frame slots onto the stack at the correct offset.  After handling any values in frame slots, the method calls the next reducer in the chain.\",\n            \"parameters\": [\n                {\n                    \"name\": \"pop_count\",\n                    \"type\": \"V<Word32>\",\n                    \"purpose\": \"The number of values to pop from the stack.\"\n                },\n                {\n                    \"name\": \"return_values\",\n                    \"type\": \"base::Vector<const OpIndex>\",\n                    \"purpose\": \"A vector of the return value operation indices.\"\n                },\n                {\n                    \"name\": \"spill_caller_frame_slots\",\n                    \"type\": \"bool\",\n                    \"purpose\": \"Indicates whether caller frame slots need to be spilled.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"OpIndex\",\n                \"description\": \"The operation index of the reduced return.\"\n            },\n            \"dependencies\": [\n                \"Next::ReduceReturn\",\n                \"__ Load\",\n                \"StackFrame::TypeToMarker\",\n                \"__ Word32Equal\",\n                \"compiler::Linkage::GetSimplifiedCDescriptor\",\n                \"TSCallDescriptor::Create\",\n                \"__ ExternalConstant\",\n                \"__ template Call\",\n                \"__ FramePointer\",\n                \"__ BitcastTaggedToWordPtr\",\n                \"__ StoreOffHeap\",\n                \"FrameSlotToFPOffset\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n  OpIndex REDUCE(Return)(V<Word32> pop_count,\n                         base::Vector<const OpIndex> return_values,\n                         bool spill_caller_frame_slots) {\n    if (skip_reducer_ || !spill_caller_frame_slots ||\n        call_descriptor_->ReturnSlotCount() == 0) {\n      return Next::ReduceReturn(pop_count, return_values,\n                                spill_caller_frame_slots);\n    }\n    V<Word32> frame_marker = __ Load(\n        __ FramePointer(), LoadOp::Kind::RawAligned(),\n        MemoryRepresentation::Uint32(), WasmFrameConstants::kFrameTypeOffset);\n\n    Label<WordPtr> done(this);\n    IF (UNLIKELY(__ Word32Equal(\n            frame_marker,\n            StackFrame::TypeToMarker(StackFrame::WASM_SEGMENT_START)))) {\n      auto sig =\n          FixedSizeSignature<MachineType>::Returns(MachineType::Pointer())\n              .Params(MachineType::Pointer());\n      const CallDescriptor* ccall_descriptor =\n          compiler::Linkage::GetSimplifiedCDescriptor(__ graph_zone(), &sig);\n      const TSCallDescriptor* ts_ccall_descriptor = TSCallDescriptor::Create(\n          ccall_descriptor, compiler::CanThrow::kNo,\n          compiler::LazyDeoptOnThrow::kNo, __ graph_zone());\n      GOTO(done, __ template Call<WordPtr>(\n                     __ ExternalConstant(ExternalReference::wasm_load_old_fp()),\n                     OpIndex::Invalid(),\n                     base::VectorOf({__ ExternalConstant(\n                         ExternalReference::isolate_address())}),\n                     ts_ccall_descriptor));\n    } ELSE {\n      GOTO(done, __ FramePointer());\n    }\n    BIND(done, old_fp);\n\n    base::SmallVector<OpIndex, 8> register_return_values;\n    for (size_t i = 0; i < call_descriptor_->ReturnCount(); i++) {\n      LinkageLocation loc = call_descriptor_->GetReturnLocation(i);\n      if (!loc.IsCallerFrameSlot()) {\n        register_return_values.push_back(return_values[i]);\n        continue;\n      }\n      MemoryRepresentation mem_rep =\n          MemoryRepresentation::FromMachineType(loc.GetType());\n      OpIndex ret_value = return_values[i];\n      // Pointers are stored uncompressed on the stacks.\n      // Also, we don't need to mark the stack slot as a reference, because\n      // we are about to return from this frame, so it is the caller's\n      // responsibility to track the tagged return values using the signature.\n      if (mem_rep == MemoryRepresentation::AnyTagged()) {\n        mem_rep = MemoryRepresentation::UintPtr();\n        ret_value = __ BitcastTaggedToWordPtr(ret_value);\n      }\n      __ StoreOffHeap(old_fp, ret_value, mem_rep,\n                      FrameSlotToFPOffset(loc.GetLocation()));\n    }\n    return Next::ReduceReturn(pop_count, base::VectorOf(register_return_values),\n                              spill_caller_frame_slots);\n  }\n        ]]></code>\n    </func>\n    <dependencies>\n        <class>\n            <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"class\",\n                \"name\": \"Next\",\n                \"about\": \"A template parameter representing the next reducer in the chain.\",\n                \"dependencies\": []\n            }\n            </metadata>\n            <code><![CDATA[\n            class Next {};\n            ]]></code>\n        </class>\n        <class>\n            <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"class\",\n                \"name\": \"TSCallDescriptor\",\n                \"about\": \"The Turboshaft call descriptor.\",\n                \"dependencies\": []\n            }\n            </metadata>\n            <code><![CDATA[\n            class TSCallDescriptor {};\n            ]]></code>\n        </class>\n        <class>\n            <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"class\",\n                \"name\": \"WasmGrowableStackGuardDescriptor\",\n                \"about\": \"Descriptor for the WasmGrowableStackGuard stub call.\",\n                \"dependencies\": []\n            }\n            </metadata>\n            <code><![CDATA[\n            class WasmGrowableStackGuardDescriptor {};\n            ]]></code>\n        </class>\n        <class>\n            <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"class\",\n                \"name\": \"StackFrame\",\n                \"about\": \"Represents a stack frame.\",\n                \"dependencies\": []\n            }\n            </metadata>\n            <code><![CDATA[\n            class StackFrame {\n            public:\n              enum Type {\n                WASM_SEGMENT_START\n              };\n              static int TypeToMarker(Type type) { return 0; }\n            };\n            ]]></code>\n        </class>\n    </dependencies>\n</file>\n```"
}