{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/move-optimizer.cc",
  "error": "Response not JSON and not XML-like after cleanup",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "raw_response": "```xml\n<file>\n    <metadata>\n    {\n        \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/move-optimizer.cc\",\n        \"file_name\": \"move-optimizer.cc\",\n        \"language\": \"cpp\",\n        \"purpose\": \"Implements the move optimizer for the V8 compiler backend, which eliminates redundant moves and optimizes parallel moves in the instruction sequence.\"\n    }\n    </metadata>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Includes necessary header files for move optimization, code generation, and register configuration.\"\n        }\n        </metadata>\n        <code><![CDATA[\n#include \"src/compiler/backend/move-optimizer.h\"\n\n#include \"src/codegen/register-configuration.h\"\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"struct\",\n            \"name\": \"MoveKey\",\n            \"about\": \"Represents a key for move operations, used for comparing and hashing moves based on their source and destination operands.\",\n            \"attributes\": [\n                {\n                    \"name\": \"source\",\n                    \"type\": \"InstructionOperand\",\n                    \"access\": \"public\",\n                    \"purpose\": \"The source operand of the move operation.\"\n                },\n                {\n                    \"name\": \"destination\",\n                    \"type\": \"InstructionOperand\",\n                    \"access\": \"public\",\n                    \"purpose\": \"The destination operand of the move operation.\"\n                }\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nstruct MoveKey {\n  InstructionOperand source;\n  InstructionOperand destination;\n  bool operator<(const MoveKey& other) const {\n    if (this->source != other.source) {\n      return this->source.Compare(other.source);\n    }\n    return this->destination.Compare(other.destination);\n  }\n  bool operator==(const MoveKey& other) const {\n    return std::tie(this->source, this->destination) ==\n           std::tie(other.source, other.destination);\n  }\n};\n        ]]></code>\n    </class>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"OperandSet\",\n            \"about\": \"Manages a set of InstructionOperands, providing methods to insert operands and check for their presence, including handling of FP register aliasing.\",\n            \"attributes\": [\n                {\n                    \"name\": \"set_\",\n                    \"type\": \"ZoneVector<InstructionOperand>*\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Pointer to the underlying ZoneVector storing the operands.\"\n                },\n                {\n                    \"name\": \"fp_reps_\",\n                    \"type\": \"int\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Bitmask representing the FP representations encountered, used for aliasing checks.\"\n                }\n            ],\n            \"dependencies\": [\n                \"AliasingKind\",\n                \"LocationOperand\",\n                \"MachineRepresentation\",\n                \"RegisterConfiguration\",\n                \"AllocatedOperand\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nclass OperandSet {\n public:\n  explicit OperandSet(ZoneVector<InstructionOperand>* buffer)\n      : set_(buffer), fp_reps_(0) {\n    buffer->clear();\n  }\n\n  void InsertOp(const InstructionOperand& op) {\n    set_->push_back(op);\n\n    if (kFPAliasing == AliasingKind::kCombine && op.IsFPRegister())\n      fp_reps_ |= RepresentationBit(LocationOperand::cast(op).representation());\n  }\n\n  bool Contains(const InstructionOperand& op) const {\n    for (const InstructionOperand& elem : *set_) {\n      if (elem.EqualsCanonicalized(op)) return true;\n    }\n    return false;\n  }\n\n  bool ContainsOpOrAlias(const InstructionOperand& op) const {\n    if (Contains(op)) return true;\n\n    if (kFPAliasing == AliasingKind::kCombine && op.IsFPRegister()) {\n      // Platforms where FP registers have complex aliasing need extra checks.\n      const LocationOperand& loc = LocationOperand::cast(op);\n      MachineRepresentation rep = loc.representation();\n      // If haven't encountered mixed rep FP registers, skip the extra checks.\n      if (!HasMixedFPReps(fp_reps_ | RepresentationBit(rep))) return false;\n\n      // Check register against aliasing registers of other FP representations.\n      MachineRepresentation other_rep1, other_rep2;\n      switch (rep) {\n        case MachineRepresentation::kFloat32:\n          other_rep1 = MachineRepresentation::kFloat64;\n          other_rep2 = MachineRepresentation::kSimd128;\n          break;\n        case MachineRepresentation::kFloat64:\n          other_rep1 = MachineRepresentation::kFloat32;\n          other_rep2 = MachineRepresentation::kSimd128;\n          break;\n        case MachineRepresentation::kSimd128:\n          other_rep1 = MachineRepresentation::kFloat32;\n          other_rep2 = MachineRepresentation::kFloat64;\n          break;\n        default:\n          UNREACHABLE();\n      }\n      const RegisterConfiguration* config = RegisterConfiguration::Default();\n      int base = -1;\n      int aliases =\n          config->GetAliases(rep, loc.register_code(), other_rep1, &base);\n      DCHECK(aliases > 0 || (aliases == 0 && base == -1));\n      while (aliases--) {\n        if (Contains(AllocatedOperand(LocationOperand::REGISTER, other_rep1,\n                                      base + aliases))) {\n          return true;\n        }\n      }\n      aliases = config->GetAliases(rep, loc.register_code(), other_rep2, &base);\n      DCHECK(aliases > 0 || (aliases == 0 && base == -1));\n      while (aliases--) {\n        if (Contains(AllocatedOperand(LocationOperand::REGISTER, other_rep2,\n                                      base + aliases))) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }\n\n private:\n  static bool HasMixedFPReps(int reps) {\n    return reps && !base::bits::IsPowerOfTwo(reps);\n  }\n\n  ZoneVector<InstructionOperand>* set_;\n  int fp_reps_;\n};\n        ]]></code>\n    </class>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"function\",\n            \"name\": \"FindFirstNonEmptySlot\",\n            \"about\": \"Finds the first non-empty parallel move slot in an instruction, eliminating redundant moves and clearing the slot if only redundant moves are present.\",\n            \"logic\": \"Iterates through the parallel move slots of the instruction, checking for non-redundant moves.  If a non-redundant move is found, the index of the slot is returned.  If only redundant moves are present in a slot, they are eliminated and the slot is cleared.\",\n            \"parameters\": [\n                {\n                    \"name\": \"instr\",\n                    \"type\": \"const Instruction*\",\n                    \"purpose\": \"The instruction to check for non-empty parallel move slots.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"int\",\n                \"description\": \"The index of the first non-empty slot, or a value greater than Instruction::LAST_GAP_POSITION if all slots are empty or contain only redundant moves.\"\n            },\n            \"dependencies\": [\n                \"ParallelMove\",\n                \"MoveOperands\",\n                \"Instruction\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nint FindFirstNonEmptySlot(const Instruction* instr) {\n  int i = Instruction::FIRST_GAP_POSITION;\n  for (; i <= Instruction::LAST_GAP_POSITION; i++) {\n    ParallelMove* moves = instr->parallel_moves()[i];\n    if (moves == nullptr) continue;\n    for (MoveOperands* move : *moves) {\n      if (!move->IsRedundant()) return i;\n      move->Eliminate();\n    }\n    moves->clear();  // Clear this redundant move.\n  }\n  return i;\n}\n        ]]></code>\n    </func>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"MoveOptimizer\",\n            \"about\": \"The main class responsible for optimizing move operations within an instruction sequence.\",\n            \"attributes\": [\n                {\n                    \"name\": \"local_zone_\",\n                    \"type\": \"Zone*\",\n                    \"access\": \"private\",\n                    \"purpose\": \"The zone used for local memory allocation.\"\n                },\n                {\n                    \"name\": \"code_\",\n                    \"type\": \"InstructionSequence*\",\n                    \"access\": \"private\",\n                    \"purpose\": \"The instruction sequence being optimized.\"\n                },\n                {\n                    \"name\": \"local_vector_\",\n                    \"type\": \"ZoneVector<MoveOperands*>\",\n                    \"access\": \"private\",\n                    \"purpose\": \"A local vector used for temporary storage of MoveOperands.\"\n                },\n                {\n                    \"name\": \"operand_buffer1\",\n                    \"type\": \"ZoneVector<InstructionOperand>\",\n                    \"access\": \"private\",\n                    \"purpose\": \"A buffer for storing InstructionOperands, used by OperandSet.\"\n                },\n                {\n                    \"name\": \"operand_buffer2\",\n                    \"type\": \"ZoneVector<InstructionOperand>\",\n                    \"access\": \"private\",\n                    \"purpose\": \"Another buffer for storing InstructionOperands, used by OperandSet.\"\n                }\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nMoveOptimizer::MoveOptimizer(Zone* local_zone, InstructionSequence* code)\n    : local_zone_(local_zone),\n      code_(code),\n      local_vector_(local_zone),\n      operand_buffer1(local_zone),\n      operand_buffer2(local_zone) {}\n        ]]></code>\n    </class>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"Run\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Executes the move optimization process on the instruction sequence.\",\n            \"logic\": \"Iterates through the instructions and instruction blocks, compressing gaps, blocks, and optimizing merges.  Finally, it finalizes the moves.\",\n            \"parameters\": [],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"CompressGaps\",\n                \"CompressBlock\",\n                \"OptimizeMerge\",\n                \"FinalizeMoves\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::Run() {\n  for (Instruction* instruction : code()->instructions()) {\n    CompressGaps(instruction);\n  }\n  for (InstructionBlock* block : code()->instruction_blocks()) {\n    CompressBlock(block);\n  }\n  for (InstructionBlock* block : code()->instruction_blocks()) {\n    if (block->PredecessorCount() <= 1) continue;\n    if (!block->IsDeferred()) {\n      bool has_only_deferred = true;\n      for (RpoNumber& pred_id : block->predecessors()) {\n        if (!code()->InstructionBlockAt(pred_id)->IsDeferred()) {\n          has_only_deferred = false;\n          break;\n        }\n      }\n      // This would pull down common moves. If the moves occur in deferred\n      // blocks, and the closest common successor is not deferred, we lose the\n      // optimization of just spilling/filling in deferred blocks, when the\n      // current block is not deferred.\n      if (has_only_deferred) continue;\n    }\n    OptimizeMerge(block);\n  }\n  for (Instruction* gap : code()->instructions()) {\n    FinalizeMoves(gap);\n  }\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"RemoveClobberedDestinations\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Removes move operations whose destinations are clobbered by the outputs or temps of the given instruction.\",\n            \"logic\": \"Creates an OperandSet of outputs and temps, then iterates through the parallel moves, eliminating those that write to operands in the set and are not used as inputs.\",\n            \"parameters\": [\n                {\n                    \"name\": \"instruction\",\n                    \"type\": \"Instruction*\",\n                    \"purpose\": \"The instruction whose outputs and temps might clobber move destinations.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"OperandSet\",\n                \"Instruction\",\n                \"ParallelMove\",\n                \"MoveOperands\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::RemoveClobberedDestinations(Instruction* instruction) {\n  if (instruction->IsCall()) return;\n  ParallelMove* moves = instruction->parallel_moves()[0];\n  if (moves == nullptr) return;\n\n  DCHECK(instruction->parallel_moves()[1] == nullptr ||\n         instruction->parallel_moves()[1]->empty());\n\n  OperandSet outputs(&operand_buffer1);\n  OperandSet inputs(&operand_buffer2);\n\n  // Outputs and temps are treated together as potentially clobbering a\n  // destination operand.\n  for (size_t i = 0; i < instruction->OutputCount(); ++i) {\n    outputs.InsertOp(*instruction->OutputAt(i));\n  }\n  for (size_t i = 0; i < instruction->TempCount(); ++i) {\n    outputs.InsertOp(*instruction->TempAt(i));\n  }\n\n  // Input operands block elisions.\n  for (size_t i = 0; i < instruction->InputCount(); ++i) {\n    inputs.InsertOp(*instruction->InputAt(i));\n  }\n\n  // Elide moves made redundant by the instruction.\n  for (MoveOperands* move : *moves) {\n    if (outputs.ContainsOpOrAlias(move->destination()) &&\n        !inputs.ContainsOpOrAlias(move->destination())) {\n      move->Eliminate();\n    }\n  }\n\n  // The ret instruction makes any assignment before it unnecessary, except for\n  // the one for its input.\n  if (instruction->IsRet() || instruction->IsTailCall()) {\n    for (MoveOperands* move : *moves) {\n      if (!inputs.ContainsOpOrAlias(move->destination())) {\n        move->Eliminate();\n      }\n    }\n  }\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"MigrateMoves\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Migrates eligible move operations from one instruction's gap to another.\",\n            \"logic\": \"Determines which move operations can be safely moved from the 'from' instruction's gap to the 'to' instruction's gap without interfering with the 'from' instruction's inputs, outputs, or temps.\",\n            \"parameters\": [\n                {\n                    \"name\": \"to\",\n                    \"type\": \"Instruction*\",\n                    \"purpose\": \"The instruction to which moves will be migrated.\"\n                },\n                {\n                    \"name\": \"from\",\n                    \"type\": \"Instruction*\",\n                    \"purpose\": \"The instruction from which moves will be migrated.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"OperandSet\",\n                \"Instruction\",\n                \"ParallelMove\",\n                \"MoveOperands\",\n                \"MoveKey\",\n                \"CompressMoves\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::MigrateMoves(Instruction* to, Instruction* from) {\n  if (from->IsCall()) return;\n\n  ParallelMove* from_moves = from->parallel_moves()[0];\n  if (from_moves == nullptr || from_moves->empty()) return;\n\n  OperandSet dst_cant_be(&operand_buffer1);\n  OperandSet src_cant_be(&operand_buffer2);\n\n  // If an operand is an input to the instruction, we cannot move assignments\n  // where it appears on the LHS.\n  for (size_t i = 0; i < from->InputCount(); ++i) {\n    dst_cant_be.InsertOp(*from->InputAt(i));\n  }\n  // If an operand is output to the instruction, we cannot move assignments\n  // where it appears on the RHS, because we would lose its value before the\n  // instruction.\n  // Same for temp operands.\n  // The output can't appear on the LHS because we performed\n  // RemoveClobberedDestinations for the \"from\" instruction.\n  for (size_t i = 0; i < from->OutputCount(); ++i) {\n    src_cant_be.InsertOp(*from->OutputAt(i));\n  }\n  for (size_t i = 0; i < from->TempCount(); ++i) {\n    src_cant_be.InsertOp(*from->TempAt(i));\n  }\n  for (MoveOperands* move : *from_moves) {\n    if (move->IsRedundant()) continue;\n    // Assume dest has a value \"V\". If we have a \"dest = y\" move, then we can't\n    // move \"z = dest\", because z would become y rather than \"V\".\n    // We assume CompressMoves has happened before this, which means we don't\n    // have more than one assignment to dest.\n    src_cant_be.InsertOp(move->destination());\n  }\n\n  // This set is usually small, e.g., for JetStream2 it has 16 elements or less\n  // in 99.99% of the cases, hence use inline storage and fast linear search.\n  // It is encoded as a `SmallMap` to `Dummy` values, since we don't have an\n  // equivalent `SmallSet` type.\n  struct Dummy {};\n  SmallZoneMap<MoveKey, Dummy, 16> move_candidates(local_zone());\n  // We start with all the moves that don't have conflicting source or\n  // destination operands are eligible for being moved down.\n  for (MoveOperands* move : *from_moves) {\n    if (move->IsRedundant()) continue;\n    if (!dst_cant_be.ContainsOpOrAlias(move->destination())) {\n      MoveKey key = {move->source(), move->destination()};\n      move_candidates.emplace(key, Dummy{});\n    }\n  }\n  if (move_candidates.empty()) return;\n\n  // Stabilize the candidate set.\n  bool changed = false;\n  do {\n    changed = false;\n    for (auto iter = move_candidates.begin(); iter != move_candidates.end();) {\n      auto [move, _] = *iter;\n      if (src_cant_be.ContainsOpOrAlias(move.source)) {\n        src_cant_be.InsertOp(move.destination);\n        iter = move_candidates.erase(iter);\n        changed = true;\n      } else {\n        ++iter;\n      }\n    }\n  } while (changed);\n\n  ParallelMove to_move(local_zone());\n  for (MoveOperands* move : *from_moves) {\n    if (move->IsRedundant()) continue;\n    MoveKey key = {move->source(), move->destination()};\n    if (move_candidates.find(key) != move_candidates.end()) {\n      to_move.AddMove(move->source(), move->destination(), code_zone());\n      move->Eliminate();\n    }\n  }\n  if (to_move.empty()) return;\n\n  ParallelMove* dest =\n      to->GetOrCreateParallelMove(Instruction::GapPosition::START, code_zone());\n\n  CompressMoves(&to_move, dest);\n  DCHECK(dest->empty());\n  for (MoveOperands* m : to_move) {\n    dest->push_back(m);\n  }\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"CompressMoves\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Compresses two sets of parallel moves by merging them into a single set and eliminating redundant moves.\",\n            \"logic\": \"Merges the moves from the 'right' MoveOpVector into the 'left' ParallelMove, eliminating any moves that are made redundant by the merge.  The 'right' MoveOpVector is then cleared.\",\n            \"parameters\": [\n                {\n                    \"name\": \"left\",\n                    \"type\": \"ParallelMove*\",\n                    \"purpose\": \"The primary ParallelMove to which other moves will be added.\"\n                },\n                {\n                    \"name\": \"right\",\n                    \"type\": \"MoveOpVector*\",\n                    \"purpose\": \"The MoveOpVector whose moves will be merged into the 'left' ParallelMove.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"ParallelMove\",\n                \"MoveOperands\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::CompressMoves(ParallelMove* left, MoveOpVector* right) {\n  if (right == nullptr) return;\n\n  MoveOpVector& eliminated = local_vector();\n  DCHECK(eliminated.empty());\n\n  if (!left->empty()) {\n    // Modify the right moves in place and collect moves that will be killed by\n    // merging the two gaps.\n    for (MoveOperands* move : *right) {\n      if (move->IsRedundant()) continue;\n      left->PrepareInsertAfter(move, &eliminated);\n    }\n    // Eliminate dead moves.\n    for (MoveOperands* to_eliminate : eliminated) {\n      to_eliminate->Eliminate();\n    }\n    eliminated.clear();\n  }\n  // Add all possibly modified moves from right side.\n  for (MoveOperands* move : *right) {\n    if (move->IsRedundant()) continue;\n    left->push_back(move);\n  }\n  // Nuke right.\n  right->clear();\n  DCHECK(eliminated.empty());\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"CompressGaps\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Compresses the parallel move gaps within an instruction.\",\n            \"logic\": \"Identifies the first non-empty parallel move slot in an instruction and consolidates all moves into that slot, potentially swapping or merging the slots.\",\n            \"parameters\": [\n                {\n                    \"name\": \"instruction\",\n                    \"type\": \"Instruction*\",\n                    \"purpose\": \"The instruction whose parallel move gaps are to be compressed.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"FindFirstNonEmptySlot\",\n                \"CompressMoves\",\n                \"Instruction\",\n                \"ParallelMove\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::CompressGaps(Instruction* instruction) {\n  int i = FindFirstNonEmptySlot(instruction);\n  bool has_moves = i <= Instruction::LAST_GAP_POSITION;\n  USE(has_moves);\n\n  if (i == Instruction::LAST_GAP_POSITION) {\n    std::swap(instruction->parallel_moves()[Instruction::FIRST_GAP_POSITION],\n              instruction->parallel_moves()[Instruction::LAST_GAP_POSITION]);\n  } else if (i == Instruction::FIRST_GAP_POSITION) {\n    CompressMoves(\n        instruction->parallel_moves()[Instruction::FIRST_GAP_POSITION],\n        instruction->parallel_moves()[Instruction::LAST_GAP_POSITION]);\n  }\n  // We either have no moves, or, after swapping or compressing, we have\n  // all the moves in the first gap position, and none in the second/end gap\n  // position.\n  ParallelMove* first =\n      instruction->parallel_moves()[Instruction::FIRST_GAP_POSITION];\n  ParallelMove* last =\n      instruction->parallel_moves()[Instruction::LAST_GAP_POSITION];\n  USE(first);\n  USE(last);\n\n  DCHECK(!has_moves ||\n         (first != nullptr && (last == nullptr || last->empty())));\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"CompressBlock\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Compresses move operations within an instruction block by migrating and removing clobbered destinations.\",\n            \"logic\": \"Iterates through the instructions in the block, migrating eligible moves from the previous instruction and removing move operations that are clobbered by the current instruction's outputs.\",\n            \"parameters\": [\n                {\n                    \"name\": \"block\",\n                    \"type\": \"InstructionBlock*\",\n                    \"purpose\": \"The instruction block to be compressed.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"RemoveClobberedDestinations\",\n                \"MigrateMoves\",\n                \"InstructionBlock\",\n                \"Instruction\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::CompressBlock(InstructionBlock* block) {\n  int first_instr_index = block->first_instruction_index();\n  int last_instr_index = block->last_instruction_index();\n\n  // Start by removing gap assignments where the output of the subsequent\n  // instruction appears on LHS, as long as they are not needed by its input.\n  Instruction* prev_instr = code()->instructions()[first_instr_index];\n  RemoveClobberedDestinations(prev_instr);\n\n  for (int index = first_instr_index + 1; index <= last_instr_index; ++index) {\n    Instruction* instr = code()->instructions()[index];\n    // Migrate to the gap of prev_instr eligible moves from instr.\n    MigrateMoves(instr, prev_instr);\n    // Remove gap assignments clobbered by instr's output.\n    RemoveClobberedDestinations(instr);\n    prev_instr = instr;\n  }\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"LastInstruction\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Returns the last instruction of a given instruction block.\",\n            \"logic\": \"Retrieves the last instruction index from the block and uses it to access the instruction within the code's instruction sequence.\",\n            \"parameters\": [\n                {\n                    \"name\": \"block\",\n                    \"type\": \"const InstructionBlock*\",\n                    \"purpose\": \"The instruction block whose last instruction is to be retrieved.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"const Instruction*\",\n                \"description\": \"The last instruction in the block.\"\n            },\n            \"dependencies\": [\n                \"InstructionBlock\",\n                \"Instruction\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nconst Instruction* MoveOptimizer::LastInstruction(\n    const InstructionBlock* block) const {\n  return code()->instructions()[block->last_instruction_index()];\n}\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"OptimizeMerge\",\n            \"parent\": \"MoveOptimizer\",\n            \"about\": \"Optimizes move operations across multiple predecessor blocks merging into a single block.\",\n            \"logic\": \"Identifies common move operations at the end of predecessor blocks and moves them to the beginning of the current block, eliminating redundant moves in the predecessors.\",\n            \"parameters\": [\n                {\n                    \"name\": \"block\",\n                    \"type\": \"InstructionBlock*\",\n                    \"purpose\": \"The block where the predecessors are merging into.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"void\",\n                \"description\": \"No return value.\"\n            },\n            \"dependencies\": [\n                \"InstructionBlock\",\n                \"Instruction\",\n                \"LastInstruction\",\n                \"ParallelMove\",\n                \"MoveOperands\",\n                \"MoveKey\",\n                \"CompressMoves\",\n                \"CompressBlock\",\n                \"OperandSet\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nvoid MoveOptimizer::OptimizeMerge(InstructionBlock* block) {\n  DCHECK_LT(1, block->PredecessorCount());\n  // Ensure that the last instruction in all incoming blocks don't contain\n  // things that would prevent moving gap moves across them.\n  for (RpoNumber& pred_index : block->predecessors()) {\n    const InstructionBlock* pred = code()->InstructionBlockAt(pred_index);\n\n    // If the predecessor has more than one successor, we shouldn't attempt to\n    // move down to this block (one of the successors) any of the gap moves,\n    // because their effect may be necessary to the other successors.\n    if (pred->SuccessorCount() > 1) return;\n\n    const Instruction* last_instr =\n        code()->instructions()[pred->last_instruction_index()];\n    if (last_instr->IsCall()) return;\n    if (last_instr->TempCount() != 0) return;\n    if (last_instr->OutputCount() != 0) return;\n    for (size_t i = 0; i < last_instr->InputCount(); ++i) {\n      const InstructionOperand* op = last_instr->InputAt(i);\n      if (!op->IsConstant() && !op->IsImmediate()) return;\n    }\n  }\n\n  // This map is usually small, e.g., for JetStream2 in 99.5% of the cases it\n  // has 16 elements or less. Hence use a `SmallMap` with inline storage and\n  // fast linear search in the common case.\n  SmallZoneMap<MoveKey, /* count */ size_t, 16> move_map(local_zone());\n  size_t correct_counts = 0;\n  // Accumulate set of shared moves.\n  for (RpoNumber& pred_index : block->predecessors()) {\n    const InstructionBlock* pred = code()->InstructionBlockAt(pred_index);\n    const Instruction* instr = LastInstruction(pred);\n    if (instr->parallel_moves()[0] == nullptr ||\n        instr->parallel_moves()[0]->empty()) {\n      return;\n    }\n    for (const MoveOperands* move : *instr->parallel_moves()[0]) {\n      if (move->IsRedundant()) continue;\n      InstructionOperand src = move->source();\n      InstructionOperand dst = move->destination();\n      MoveKey key = {src, dst};\n      auto [it, inserted] = move_map.emplace(key, 1);\n      if (!inserted) {\n        it->second++;\n        if (it->second == block->PredecessorCount()) {\n          correct_counts++;\n        }\n      }\n    }\n  }\n  if (move_map.empty() || correct_counts == 0) return;\n\n  // Find insertion point.\n  Instruction* instr = code()->instructions()[block->first_instruction_index()];\n\n  if (correct_counts != move_map.size()) {\n    // Moves that are unique to each predecessor won't be pushed to the common\n    // successor.\n    OperandSet conflicting_srcs(&operand_buffer1);\n    for (auto iter = move_map.begin(); iter != move_map.end();) {\n      auto [move, count] = *iter;\n      if (count != block->PredecessorCount()) {\n        // Not all the moves in all the gaps are the same. Maybe some are. If\n        // there are such moves, we could move them, but the destination of the\n        // moves staying behind can't appear as a source of a common move,\n        // because the move staying behind will clobber this destination.\n        conflicting_srcs.InsertOp(move.destination);\n        iter = move_map.erase(iter);\n      } else {\n        ++iter;\n      }\n    }\n\n    bool changed = false;\n    do {\n      // If a common move can't be pushed to the common successor, then its\n      // destination also can't appear as source to any move being pushed.\n      changed = false;\n      for (auto iter = move_map.begin(); iter != move_map.end();) {\n        auto [move, count] = *iter;\n        DCHECK_EQ(block->PredecessorCount(), count);\n        USE(count);\n        if (conflicting_srcs.ContainsOpOrAlias(move.source)) {\n          conflicting_srcs.InsertOp(move.destination);\n          iter = move_map.erase(iter);\n          changed = true;\n        } else {\n          ++iter;\n        }\n      }\n    } while (changed);\n  }\n\n  if (move_map.empty()) return;\n\n  DCHECK_NOT_NULL(instr);\n  bool gap_initialized = true;\n  if (instr->parallel_moves()[0] != nullptr &&\n      !instr->parallel_moves()[0]->empty()) {\n    // Will compress after insertion.\n    gap_initialized = false;\n    std::swap(instr->parallel_moves()[0], instr->parallel_moves()[1]);\n  }\n  ParallelMove* moves = instr->GetOrCreateParallelMove(\n      static_cast<Instruction::GapPosition>(0), code_zone());\n  // Delete relevant entries in predecessors and move everything to block.\n  bool first_iteration = true;\n  for (RpoNumber& pred_index : block->predecessors()) {\n    const InstructionBlock* pred = code()->InstructionBlockAt(pred_index);\n    for (MoveOperands* move : *LastInstruction(pred)->parallel_moves()[0]) {\n      if (move->IsRedundant()) continue;\n      MoveKey key = {move->source(), move->destination()};\n      auto"
}