{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/graph-assembler.h",
  "error": "Response not JSON and not XML-like after cleanup",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "raw_response": "```xml\n<file>\n    <metadata>\n    {\n        \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/graph-assembler.h\",\n        \"file_name\": \"graph-assembler.h\",\n        \"language\": \"cpp\",\n        \"purpose\": \"Declares the GraphAssembler and JSGraphAssembler classes, which provide a high-level interface for constructing graphs in the V8 compiler.\"\n    }\n    </metadata>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Includes standard library headers and V8-specific headers for data structures, code generation, compiler components, objects, and more.\"\n        }\n        </metadata>\n        <code><![CDATA[\n            #include <optional>\n            #include <type_traits>\n\n            #include \"src/base/small-vector.h\"\n            #include \"src/codegen/tnode.h\"\n            #include \"src/common/globals.h\"\n            #include \"src/compiler/feedback-source.h\"\n            #include \"src/compiler/js-graph.h\"\n            #include \"src/compiler/node.h\"\n            #include \"src/compiler/simplified-operator.h\"\n            #include \"src/objects/hole.h\"\n            #include \"src/objects/oddball.h\"\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"GraphAssembler\",\n            \"about\": \"Provides a high-level interface for constructing graphs in the V8 compiler's Sea of Nodes intermediate representation.\",\n            \"attributes\": [],\n            \"dependencies\": [\n                \"MachineGraph\",\n                \"Zone\",\n                \"Node\",\n                \"CommonOperatorBuilder\",\n                \"MachineOperatorBuilder\",\n                \"Reducer\",\n                \"GraphAssemblerLabel\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n            class GraphAssembler {\n            public:\n              // Constructs a GraphAssembler. If {schedule} is not null, the graph assembler\n              // will maintain the schedule as it updates blocks.\n              GraphAssembler(\n                  MachineGraph* jsgraph, Zone* zone,\n                  BranchSemantics default_branch_semantics,\n                  std::optional<NodeChangedCallback> node_changed_callback = std::nullopt,\n                  bool mark_loop_exits = false);\n              virtual ~GraphAssembler();\n              virtual SimplifiedOperatorBuilder* simplified() { UNREACHABLE(); }\n\n              void Reset();\n              void InitializeEffectControl(Node* effect, Node* control);\n\n              // Create label.\n              template <typename... Reps>\n              detail::GraphAssemblerLabelForReps<Reps...> MakeLabelFor(\n                  GraphAssemblerLabelType type, Reps... reps);\n              GraphAssemblerDynamicLabel MakeLabelFor(\n                  GraphAssemblerLabelType type,\n                  base::SmallVector<MachineRepresentation, 4> reps);\n\n              // Convenience wrapper for creating non-deferred labels.\n              template <typename... Reps>\n              detail::GraphAssemblerLabelForReps<Reps...> MakeLabel(Reps... reps);\n\n              // Convenience wrapper for creating loop labels.\n              template <typename... Reps>\n              detail::GraphAssemblerLabelForReps<Reps...> MakeLoopLabel(Reps... reps);\n\n              // Convenience wrapper for creating deferred labels.\n              template <typename... Reps>\n              detail::GraphAssemblerLabelForReps<Reps...> MakeDeferredLabel(Reps... reps);\n\n              // Value creation.\n              Node* IntPtrConstant(intptr_t value);\n              TNode<UintPtrT> UintPtrConstant(uintptr_t value);\n              Node* Int32Constant(int32_t value);\n              TNode<Uint32T> Uint32Constant(uint32_t value);\n              Node* Int64Constant(int64_t value);\n              Node* Uint64Constant(uint64_t value);\n              Node* UniqueIntPtrConstant(intptr_t value);\n              Node* Float64Constant(double value);\n              Node* ExternalConstant(ExternalReference ref);\n              Node* IsolateField(IsolateFieldId id);\n\n              Node* Projection(int index, Node* value, Node* ctrl = nullptr);\n\n              Node* Parameter(int index);\n\n              Node* LoadFramePointer();\n\n              Node* LoadRootRegister();\n\n            #if V8_ENABLE_WEBASSEMBLY\n              Node* LoadStackPointer();\n              Node* SetStackPointer(Node* sp);\n            #endif\n\n              Node* LoadHeapNumberValue(Node* heap_number);\n\n            #define PURE_UNOP_DECL(Name) Node* Name(Node* input);\n              PURE_ASSEMBLER_MACH_UNOP_LIST(PURE_UNOP_DECL)\n            #undef PURE_UNOP_DECL\n\n            #define BINOP_DECL(Name) Node* Name(Node* left, Node* right);\n            #define BINOP_DECL_TNODE(Name, Result, Left, Right) \\\n              TNode<Result> Name(SloppyTNode<Left> left, SloppyTNode<Right> right);\n              PURE_ASSEMBLER_MACH_BINOP_LIST(BINOP_DECL, BINOP_DECL_TNODE)\n              CHECKED_ASSEMBLER_MACH_BINOP_LIST(BINOP_DECL)\n            #undef BINOP_DECL\n            #undef BINOP_DECL_TNODE\n              TNode<BoolT> UintPtrLessThan(TNode<UintPtrT> left, TNode<UintPtrT> right);\n              TNode<BoolT> UintPtrLessThanOrEqual(TNode<UintPtrT> left,\n                                                  TNode<UintPtrT> right);\n              TNode<UintPtrT> UintPtrAdd(TNode<UintPtrT> left, TNode<UintPtrT> right);\n              TNode<UintPtrT> UintPtrSub(TNode<UintPtrT> left, TNode<UintPtrT> right);\n              TNode<UintPtrT> UintPtrDiv(TNode<UintPtrT> left, TNode<UintPtrT> right);\n              TNode<UintPtrT> ChangeUint32ToUintPtr(SloppyTNode<Uint32T> value);\n\n            #ifdef V8_MAP_PACKING\n              Node* PackMapWord(TNode<Map> map);\n              TNode<Map> UnpackMapWord(Node* map_word);\n            #endif\n              TNode<Map> LoadMap(Node* object);\n\n              Node* DebugBreak();\n\n              Node* Unreachable();\n              // This special variant doesn't connect the Unreachable node to end, and does\n              // not reset current effect/control. Intended only for special use-cases like\n              // lowering DeadValue.\n              Node* UnreachableWithoutConnectToEnd();\n\n              Node* IntPtrEqual(Node* left, Node* right);\n              Node* TaggedEqual(Node* left, Node* right);\n\n              Node* SmiSub(Node* left, Node* right);\n              Node* SmiLessThan(Node* left, Node* right);\n\n              Node* Float64RoundDown(Node* value);\n              Node* Float64RoundTruncate(Node* value);\n              Node* TruncateFloat64ToInt64(Node* value, TruncateKind kind);\n\n              Node* BitcastWordToTagged(Node* value);\n              Node* BitcastWordToTaggedSigned(Node* value);\n              Node* BitcastTaggedToWord(Node* value);\n              Node* BitcastTaggedToWordForTagAndSmiBits(Node* value);\n              Node* BitcastMaybeObjectToWord(Node* value);\n\n              Node* TypeGuard(Type type, Node* value);\n              template <typename T>\n              TNode<T> TypeGuard(Type type, TNode<T> value) {\n                return TNode<T>::UncheckedCast(TypeGuard(type, static_cast<Node*>(value)));\n              }\n              Node* Checkpoint(FrameState frame_state);\n\n              TNode<RawPtrT> StackSlot(int size, int alignment, bool is_tagged = false);\n\n              Node* AdaptLocalArgument(Node* argument);\n\n              Node* Store(StoreRepresentation rep, Node* object, Node* offset, Node* value);\n              Node* Store(StoreRepresentation rep, Node* object, int offset, Node* value);\n              Node* Load(MachineType type, Node* object, Node* offset);\n              Node* Load(MachineType type, Node* object, int offset);\n\n              Node* StoreUnaligned(MachineRepresentation rep, Node* object, Node* offset,\n                                   Node* value);\n              Node* LoadUnaligned(MachineType type, Node* object, Node* offset);\n\n              Node* ProtectedStore(MachineRepresentation rep, Node* object, Node* offset,\n                                   Node* value);\n              Node* ProtectedLoad(MachineType type, Node* object, Node* offset);\n              Node* LoadTrapOnNull(MachineType type, Node* object, Node* offset);\n              Node* StoreTrapOnNull(StoreRepresentation rep, Node* object, Node* offset,\n                                    Node* value);\n\n              Node* Retain(Node* buffer);\n              Node* IntPtrAdd(Node* a, Node* b);\n              Node* IntPtrSub(Node* a, Node* b);\n\n              Node* DeoptimizeIf(DeoptimizeReason reason, FeedbackSource const& feedback,\n                                 Node* condition, Node* frame_state);\n              Node* DeoptimizeIfNot(DeoptimizeReason reason, FeedbackSource const& feedback,\n                                    Node* condition, Node* frame_state);\n              TNode<Object> Call(const CallDescriptor* call_descriptor, int inputs_size,\n                                 Node** inputs);\n              TNode<Object> Call(const Operator* op, int inputs_size, Node** inputs);\n              template <typename... Args>\n              TNode<Object> Call(const CallDescriptor* call_descriptor, Node* first_arg,\n                                 Args... args);\n              template <typename... Args>\n              TNode<Object> Call(const Operator* op, Node* first_arg, Args... args);\n              void TailCall(const CallDescriptor* call_descriptor, int inputs_size,\n                            Node** inputs);\n\n              // Basic control operations.\n              template <size_t VarCount>\n              void Bind(GraphAssemblerLabel<VarCount>* label);\n\n              template <typename... Vars>\n              void Goto(detail::GraphAssemblerLabelForVars<Vars...>* label, Vars...);\n\n              // Branch hints are inferred from if_true/if_false deferred states.\n              void BranchWithCriticalSafetyCheck(Node* condition,\n                                                 GraphAssemblerLabel<0u>* if_true,\n                                                 GraphAssemblerLabel<0u>* if_false);\n\n              // Branch hints are inferred from if_true/if_false deferred states.\n              template <typename... Vars>\n              void Branch(Node* condition,\n                          detail::GraphAssemblerLabelForVars<Vars...>* if_true,\n                          detail::GraphAssemblerLabelForVars<Vars...>* if_false, Vars...);\n\n              template <typename... Vars>\n              void BranchWithHint(Node* condition,\n                                  detail::GraphAssemblerLabelForVars<Vars...>* if_true,\n                                  detail::GraphAssemblerLabelForVars<Vars...>* if_false,\n                                  BranchHint hint, Vars...);\n              template <typename... Vars>\n              void MachineBranch(TNode<Word32T> condition,\n                                 GraphAssemblerLabel<sizeof...(Vars)>* if_true,\n                                 GraphAssemblerLabel<sizeof...(Vars)>* if_false,\n                                 BranchHint hint, Vars...);\n              template <typename... Vars>\n              void JSBranch(TNode<Boolean> condition,\n                            GraphAssemblerLabel<sizeof...(Vars)>* if_true,\n                            GraphAssemblerLabel<sizeof...(Vars)>* if_false, BranchHint hint,\n                            Vars...);\n\n              // Control helpers.\n\n              // {GotoIf(c, l, h)} is equivalent to {BranchWithHint(c, l, templ, h);\n              // Bind(templ)}.\n              template <typename... Vars>\n              void GotoIf(Node* condition,\n                          detail::GraphAssemblerLabelForVars<Vars...>* label,\n                          BranchHint hint, Vars...);\n\n              // {GotoIfNot(c, l, h)} is equivalent to {BranchWithHint(c, templ, l, h);\n              // Bind(templ)}.\n              // The branch hint refers to the expected outcome of the provided condition,\n              // so {GotoIfNot(..., BranchHint::kTrue)} means \"optimize for the case where\n              // the branch is *not* taken\".\n              template <typename... Vars>\n              void GotoIfNot(Node* condition,\n                           detail::GraphAssemblerLabelForVars<Vars...>* label,\n                           BranchHint hint, Vars...);\n\n              // {GotoIf(c, l)} is equivalent to {Branch(c, l, templ);Bind(templ)}.\n              template <typename... Vars>\n              void GotoIf(Node* condition,\n                          detail::GraphAssemblerLabelForVars<Vars...>* label, Vars...);\n\n              // {GotoIfNot(c, l)} is equivalent to {Branch(c, templ, l);Bind(templ)}.\n              template <typename... Vars>\n              void GotoIfNot(Node* condition,\n                           detail::GraphAssemblerLabelForVars<Vars...>* label, Vars...);\n\n              void RuntimeAbort(AbortReason reason);\n\n              bool HasActiveBlock() const {\n                // This is false if the current block has been terminated (e.g. by a Goto or\n                // Unreachable). In that case, a new label must be bound before we can\n                // continue emitting nodes.\n                return control() != nullptr;\n              }\n\n              // Updates current effect and control based on outputs of {node}.\n              V8_INLINE void UpdateEffectControlWith(Node* node);\n\n              // Adds {node} to the current position and updates assembler's current effect\n              // and control.\n              Node* AddNode(Node* node);\n\n              template <typename T>\n              TNode<T> AddNode(Node* node);\n\n              void ConnectUnreachableToEnd();\n\n              // Add an inline reducers such that nodes added to the graph will be run\n              // through the reducers and possibly further lowered. Each reducer should\n              // operate on independent node types since once a reducer changes a node we\n              // no longer run any other reducers on that node. The reducers should also\n              // only generate new nodes that wouldn't be further reduced, as new nodes\n              // generated by a reducer won't be passed through the reducers again.\n              void AddInlineReducer(Reducer* reducer);\n\n              Control control() const { return Control(control_); }\n              Effect effect() const { return Effect(effect_); }\n\n              Node* start() const { return graph()->start(); }\n\n            protected:\n              constexpr bool Is64() const { return kSystemPointerSize == 8; }\n\n              template <typename... Vars>\n              void MergeState(detail::GraphAssemblerLabelForVars<Vars...>* label,\n                              Vars... vars);\n\n              V8_INLINE Node* AddClonedNode(Node* node);\n\n              MachineGraph* mcgraph() const { return mcgraph_; }\n              TFGraph* graph() const { return mcgraph_->graph(); }\n              Zone* temp_zone() const { return temp_zone_; }\n              CommonOperatorBuilder* common() const { return mcgraph()->common(); }\n              MachineOperatorBuilder* machine() const { return mcgraph()->machine(); }\n\n              // Updates machinery for creating {LoopExit,LoopExitEffect,LoopExitValue}\n              // nodes on loop exits (which are necessary for loop peeling).\n              //\n              // All labels created while a LoopScope is live are considered to be inside\n              // the loop.\n              template <MachineRepresentation... Reps>\n              class V8_NODISCARD LoopScope final {\n               private:\n                // The internal scope is only here to increment the graph assembler's\n                // nesting level prior to `loop_header_label` creation below.\n                class V8_NODISCARD LoopScopeInternal {\n                 public:\n                  explicit LoopScopeInternal(GraphAssembler* gasm)\n                      : previous_loop_nesting_level_(gasm->loop_nesting_level_),\n                        gasm_(gasm) {\n                    gasm->loop_nesting_level_++;\n                  }\n\n                  ~LoopScopeInternal() {\n                    gasm_->loop_nesting_level_--;\n                    DCHECK_EQ(gasm_->loop_nesting_level_, previous_loop_nesting_level_);\n                  }\n\n                 private:\n                  const int previous_loop_nesting_level_;\n                  GraphAssembler* const gasm_;\n                };\n\n               public:\n                explicit LoopScope(GraphAssembler* gasm)\n                    : internal_scope_(gasm),\n                      gasm_(gasm),\n                      loop_header_label_(gasm->MakeLoopLabel(Reps...)) {\n                  // This feature may only be used if it has been enabled.\n                  DCHECK(gasm_->mark_loop_exits_);\n                  gasm->loop_headers_.push_back(&loop_header_label_.control_);\n                  DCHECK_EQ(static_cast<int>(gasm_->loop_headers_.size()),\n                            gasm_->loop_nesting_level_);\n                }\n\n                ~LoopScope() {\n                  DCHECK_EQ(static_cast<int>(gasm_->loop_headers_.size()),\n                            gasm_->loop_nesting_level_);\n                  gasm_->loop_headers_.pop_back();\n                }\n\n                GraphAssemblerLabel<sizeof...(Reps)>* loop_header_label() {\n                  return &loop_header_label_;\n                }\n\n               private:\n                const LoopScopeInternal internal_scope_;\n                GraphAssembler* const gasm_;\n                GraphAssemblerLabel<sizeof...(Reps)> loop_header_label_;\n              };\n\n              // Upon destruction, restores effect and control to the state at construction.\n              class V8_NODISCARD RestoreEffectControlScope {\n               public:\n                explicit RestoreEffectControlScope(GraphAssembler* gasm)\n                    : gasm_(gasm), effect_(gasm->effect()), control_(gasm->control()) {}\n\n                ~RestoreEffectControlScope() {\n                  gasm_->effect_ = effect_;\n                  gasm_->control_ = control_;\n                }\n\n               private:\n                GraphAssembler* const gasm_;\n                const Effect effect_;\n                const Control control_;\n              };\n\n            private:\n              class BlockInlineReduction;\n\n              template <typename... Vars>\n              void BranchImpl(BranchSemantics semantics, Node* condition,\n                              GraphAssemblerLabel<sizeof...(Vars)>* if_true,\n                              GraphAssemblerLabel<sizeof...(Vars)>* if_false,\n                              BranchHint hint, Vars... vars);\n\n              Zone* temp_zone_;\n              MachineGraph* mcgraph_;\n              BranchSemantics default_branch_semantics_;\n              Node* effect_;\n              Node* control_;\n              // {node_changed_callback_} should be called when a node outside the\n              // subgraph created by the graph assembler changes.\n              std::optional<NodeChangedCallback> node_changed_callback_;\n\n              // Inline reducers enable reductions to be performed to nodes as they are\n              // added to the graph with the graph assembler.\n              ZoneVector<Reducer*> inline_reducers_;\n              bool inline_reductions_blocked_;\n\n              // Track loop information in order to properly mark loop exits with\n              // {LoopExit,LoopExitEffect,LoopExitValue} nodes. The outermost level has\n              // a nesting level of 0. See also GraphAssembler::LoopScope.\n              int loop_nesting_level_ = 0;\n              ZoneVector<Node**> loop_headers_;\n\n              // Feature configuration. As more features are added, this should be turned\n              // into a bitfield.\n              const bool mark_loop_exits_;\n            };\n        ]]></code>\n    </class>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"JSGraphAssembler\",\n            \"extends\": \"GraphAssembler\",\n            \"about\": \"Extends GraphAssembler to provide a high-level interface specifically for constructing JavaScript graphs, integrating with JS-specific components like JSHeapBroker and JSOperatorBuilder.\",\n            \"attributes\": [],\n            \"dependencies\": [\n                \"JSHeapBroker\",\n                \"JSGraph\",\n                \"JSOperatorBuilder\",\n                \"SimplifiedOperatorBuilder\",\n                \"Handle\",\n                \"HeapObject\",\n                \"ObjectRef\",\n                \"MapRef\",\n                \"FieldAccess\",\n                \"ElementAccess\",\n                \"CatchScope\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\n            class V8_EXPORT_PRIVATE JSGraphAssembler : public GraphAssembler {\n            public:\n              // Constructs a JSGraphAssembler. If {schedule} is not null, the graph\n              // assembler will maintain the schedule as it updates blocks.\n              JSGraphAssembler(\n                  JSHeapBroker* broker, JSGraph* jsgraph, Zone* zone,\n                  BranchSemantics branch_semantics,\n                  std::optional<NodeChangedCallback> node_changed_callback = std::nullopt,\n                  bool mark_loop_exits = false)\n                  : GraphAssembler(jsgraph, zone, branch_semantics, node_changed_callback,\n                                   mark_loop_exits),\n                    broker_(broker),\n                    jsgraph_(jsgraph),\n                    outermost_catch_scope_(CatchScope::Outermost(zone)),\n                    catch_scope_(&outermost_catch_scope_) {\n                outermost_catch_scope_.set_gasm(this);\n              }\n\n              TNode<Smi> SmiConstant(int32_t value);\n              TNode<HeapObject> HeapConstant(Handle<HeapObject> object);\n              TNode<Object> Constant(ObjectRef ref);\n              TNode<Number> NumberConstant(double value);\n              Node* CEntryStubConstant(int result_size);\n\n            #define SINGLETON_CONST_DECL(Name, Type) TNode<Type> Name##Constant();\n              JSGRAPH_SINGLETON_CONSTANT_LIST(SINGLETON_CONST_DECL)\n            #undef SINGLETON_CONST_DECL\n\n            #define SINGLETON_CONST_TEST_DECL(Name, ...) \\\n              TNode<Boolean> Is##Name(TNode<Object> value);\n              JSGRAPH_SINGLETON_CONSTANT_LIST(SINGLETON_CONST_TEST_DECL)\n            #undef SINGLETON_CONST_TEST_DECL\n\n              Node* Allocate(AllocationType allocation, Node* size);\n              TNode<Map> LoadMap(TNode<HeapObject> object);\n              Node* LoadField(FieldAccess const&, Node* object);\n              template <typename T>\n              TNode<T> LoadField(FieldAccess const& access, TNode<HeapObject> object) {\n                // TODO(jgruber): Investigate issues on ptr compression bots and enable.\n                // DCHECK(IsMachineRepresentationOf<T>(\n                //     access.machine_type.representation()));\n                return TNode<T>::UncheckedCast(LoadField(access, object));\n              }\n              TNode<Uint32T> LoadElementsKind(TNode<Map> map);\n              Node* LoadElement(ElementAccess const&, Node* object, Node* index);\n              template <typename T>\n              TNode<T> LoadElement(ElementAccess const& access, TNode<HeapObject> object,\n                                   TNode<Number> index) {\n                // TODO(jgruber): Investigate issues on ptr compression bots and enable.\n                // DCHECK(IsMachineRepresentationOf<T>(\n                //     access.machine_type.representation()));\n                return TNode<T>::UncheckedCast(LoadElement(access, object, index));\n              }\n              Node* StoreField(FieldAccess const&, Node* object, Node* value);\n              Node* StoreElement(ElementAccess const&, Node* object, Node* index,\n                                 Node* value);\n              Node* ClearPendingMessage();\n\n              void TransitionAndStoreElement(MapRef double_map, MapRef fast_map,\n                                             TNode<HeapObject> object, TNode<Number> index,\n                                             TNode<Object> value);\n              TNode<Number> StringLength(TNode<String> string);\n              TNode<Boolean> ReferenceEqual(TNode<Object> lhs, TNode<Object> rhs);\n              TNode<Number> PlainPrimitiveToNumber(TNode<Object> value);\n              TNode<Number> NumberMin(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberMax(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Boolean> NumberEqual(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Boolean> NumberLessThan(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Boolean> NumberLessThanOrEqual(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberAdd(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberSubtract(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberShiftRightLogical(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberBitwiseAnd(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberBitwiseOr(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberDivide(TNode<Number> lhs, TNode<Number> rhs);\n              TNode<Number> NumberFloor(TNode<Number> value);\n              TNode<String> StringSubstring(TNode<String> string, TNode<Number> from,\n                                           TNode<Number> to);\n              TNode<Boolean> ObjectIsCallable(TNode<Object> value);\n              TNode<Boolean> ObjectIsSmi(TNode<Object> value);\n              TNode<Boolean> ObjectIsUndetectable(TNode<Object> value);\n              Node* BooleanNot(Node* cond);\n              Node* CheckSmi(Node* value, const FeedbackSource& feedback = {});\n              Node* CheckNumber(Node* value, const FeedbackSource& feedback = {});\n              Node* CheckNumberFitsInt32(Node* value, const FeedbackSource& feedback = {});\n              Node* CheckIf(Node* cond, DeoptimizeReason reason,\n                            const FeedbackSource& feedback = {});\n              Node* Assert(Node* cond, const char* condition_string = \"\",\n                           const char* file = \"\", int line = -1);\n              void Assert(TNode<Word32T> cond, const char* condition_string = \"\",\n                         const char* file = \"\", int line = -1);\n              TNode<Boolean> NumberIsFloat64Hole(TNode<Number> value);\n              TNode<Boolean> ToBoolean(TNode<Object> value);\n              TNode<Object> ConvertTaggedHoleToUndefined(TNode<Object> value);\n              TNode<FixedArrayBase> MaybeGrowFastElements(ElementsKind kind,\n                                                        const FeedbackSource& feedback,\n                                                        TNode<JSArray> array,\n                                                        TNode<FixedArrayBase> elements,\n                                                        TNode<Number> new_length,\n                                                        TNode<Number> old_length);\n              Node* StringCharCodeAt(TNode<String> string, TNode<Number> position);\n              TNode<String> StringFromSingleCharCode(TNode<Number> code);\n              TNode<Object> DoubleArrayMax(TNode<JSArray> array);\n              TNode<Object> DoubleArrayMin(TNode<JSArray> array);\n              // Computes the byte length for a given {array_buffer_view}. If the set of\n              // possible ElementsKinds is known statically pass as\n              // {elements_kinds_candidates} to allow the assembler to generate more\n              // efficient code. Pass an empty {elements_kinds_candidates} to generate code\n              // that is generic enough to handle all ElementsKinds.\n              TNode<Number> ArrayBufferViewByteLength(\n                  TNode<JSArrayBufferView> array_buffer_view, InstanceType instance_type,\n                  std::set<ElementsKind> elements_kinds_candidates, TNode<Context> context);\n              // Load just the detached bit on a TypedArray or DataView. For the full\n              // detached and out-of-bounds check on TypedArrays, please use\n              // CheckIfTypedArrayWasDetachedOrOutOfBounds.\n              TNode<Word32T> ArrayBufferDetachedBit(TNode<HeapObject> buffer);\n              TNode<Word32T> ArrayBufferViewDetachedBit(\n                  TNode<JSArrayBufferView> array_buffer_view);\n              // Computes the length for a given {typed_array}. If the set of possible\n              // ElementsKinds is known statically pass as {elements_kinds_candidates} to\n              // allow the assembler to generate more efficient code. Pass an empty\n              // {elements_kinds_candidates} to generate code that is generic enough to\n              // handle all ElementsKinds.\n              TNode<Number> TypedArrayLength(\n                  TNode<JSTypedArray> typed_array,\n                  std::set<ElementsKind> elements_kinds_candidates, TNode<Context> context);\n              // Performs the full detached check. This includes fixed-length RABs whos\n              // underlying buffer has been shrunk OOB.\n              void CheckIfTypedArrayWasDetachedOrOutOfBounds(\n                  TNode<JSTypedArray> typed_array,\n                  std::set<ElementsKind> elements_kinds_candidates,\n                  const FeedbackSource& feedback);\n              TNode<Uint32T> LookupByteShiftForElementsKind(TNode<Uint32T> elements_kind);\n              TNode<Uint32T> LookupByteSizeForElementsKind(TNode<Uint32T> elements_kind);\n\n              TNode<Object> JSCallRuntime1(\n                  Runtime::FunctionId function_id, TNode<Object> arg0,\n                  TNode<Context> context, std::optional<FrameState> frame_state,\n                  Operator::Properties properties = Operator::kNoProperties);\n              TNode<Object> JSCallRuntime2(Runtime::FunctionId function_id,\n                                           TNode<Object> arg0, TNode<Object> arg1,\n                                           TNode<Context> context, FrameState frame_state);\n              Node* Chained(const Operator* op, Node* input);\n\n              JSHeapBroker* broker() const { return broker_; }\n              JSGraph* jsgraph() const { return jsgraph_; }\n              Isolate* isolate() const { return jsgraph()->isolate(); }\n              SimplifiedOperatorBuilder* simplified() override {\n                return jsgraph()->simplified();\n              }\n              JSOperatorBuilder* javascript() const { return jsgraph()->javascript(); }\n\n              template <typename T, typename U>\n              TNode<T> EnterMachineGraph(TNode<U> input, UseInfo use_info) {\n                DCHECK_EQ(use_info.type_check(), TypeCheckKind::kNone);\n                return AddNode<T>(\n                    graph()->NewNode(common()->EnterMachineGraph(use_info), input));\n              }\n\n              template <typename T, typename U>\n              TNode<T> ExitMachineGraph(TNode<U> input,\n                                        MachineRepresentation output_representation,\n                                        Type output_type) {\n                return AddNode<T>(graph()->NewNode(\n                    common()->ExitMachineGraph(output_representation, output_type), input));\n              }\n\n              // A catch scope represents a single catch handler. The handler can be\n              // custom catch logic within the reduction itself; or a catch handler in the\n              // outside graph into which the reduction will be integrated (in this case\n              // the scope is called 'outermost').\n              class V8_NODISCARD CatchScope {\n               private:\n                // Only used to partially construct the outermost scope.\n                explicit CatchScope(Zone* zone) : if_exception_nodes_(zone) {}\n\n                // For all inner scopes.\n                CatchScope(Zone* zone, JSGraphAssembler* gasm)\n                    : gasm_(gasm),\n                      parent_(gasm->catch_scope_),\n                      has_handler_(true),\n                      if_exception_nodes_(zone) {\n                  DCHECK_NOT_NULL(gasm_);\n                  gasm_->catch_scope_ = this;\n                }\n\n               public:\n                ~CatchScope() { gasm_->catch_scope_ = parent_; }\n\n                static CatchScope Outermost(Zone* zone) { return CatchScope{zone}; }\n                static CatchScope Inner(Zone* zone, JSGraphAssembler* gasm) {\n                  return {zone, gasm};\n                }\n\n                bool has_handler() const { return has_handler_; }\n                bool is_outermost() const { return parent_ == nullptr; }\n                CatchScope* parent() const { return parent_; }\n\n                // Should only be used to initialize the outermost scope (inner scopes\n                // always have a handler and are passed the gasm pointer at construction).\n                void set_has_handler(bool v) {\n                  DCHECK(is_outermost());\n                  has_handler_ = v;\n                }\n                void set_gasm(JSGraphAssembler* v) {\n                  DCHECK(is_outermost());\n                  DCHECK_NOT_NULL(v);\n                  gasm_ = v;\n                }\n\n                bool has_exceptional_control_flow() const {\n                  return !if_exception_nodes_.empty();\n                }\n\n                void RegisterIfExceptionNode(Node* if_exception) {\n                  DCHECK(has_handler());\n                  if_exception_nodes_.push_back(if_exception);\n                }\n\n                void MergeExceptionalPaths(TNode<Object>* exception_out, Effect* effect_out,\n                                            Control* control_out) {\n                  DCHECK(has_handler());\n                  DCHECK(has_exceptional_control_flow());\n\n                  const int size = static_cast<int>(if_exception_nodes_.size());\n\n                  if (size == 1) {\n                    // No merge needed.\n                    Node* e = if_exception_nodes_.at(0);\n                    *exception_out = TNode<Object>::UncheckedCast(e);\n                    *effect_out = Effect(e);\n                    *control_out = Control(e);\n                  } else {\n                    DCHECK_GT(size, 1);\n\n                    Node* merge = gasm_->graph()->NewNode(gasm_->common()->Merge(size),\n                                                  size, if_exception_nodes_.data());\n\n                    // These phis additionally take {merge} as an input. Temporarily add\n                    // it to the list.\n                    if_exception_nodes_.push_back(merge);\n                    const int size_with_merge =\n                        static_cast<int>(if_exception_nodes_.size());\n\n                    Node* ephi = gasm_->graph()->NewNode(gasm_->common()->EffectPhi(size),\n                                                 size_with_merge,\n                                                 if_exception_nodes_.data());\n                    Node*"
}