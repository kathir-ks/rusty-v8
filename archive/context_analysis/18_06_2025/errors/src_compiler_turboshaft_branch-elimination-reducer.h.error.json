{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/turboshaft/branch-elimination-reducer.h",
  "error": "Response not JSON and not XML-like after cleanup",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "raw_response": "```xml\n<file>\n    <metadata>\n        {\n            \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/turboshaft/branch-elimination-reducer.h\",\n            \"file_name\": \"branch-elimination-reducer.h\",\n            \"language\": \"cpp\",\n            \"purpose\": \"Defines the BranchEliminationReducer class for optimizing branches in the Turboshaft compiler.\"\n        }\n    </metadata>\n    <imports>\n        <metadata>\n            {\n                \"language\": \"cpp\",\n                \"purpose\": \"Includes standard library headers and V8 specific headers for compiler, base utilities and data structures.\"\n            }\n        </metadata>\n        <code><![CDATA[\n#include <optional>\n\n#include \"src/base/bits.h\"\n#include \"src/base/logging.h\"\n#include \"src/compiler/turboshaft/assembler.h\"\n#include \"src/compiler/turboshaft/index.h\"\n#include \"src/compiler/turboshaft/layered-hash-map.h\"\n#include \"src/compiler/turboshaft/operations.h\"\n#include \"src/utils/utils.h\"\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"class\",\n                \"name\": \"BranchEliminationReducer\",\n                \"extends\": \"Next\",\n                \"about\": \"Reducer that performs branch elimination optimizations on the Turboshaft graph.\",\n                \"attributes\": [],\n                \"dependencies\": [\n                    \"Next\",\n                    \"VariableReducer\",\n                    \"Assembler\",\n                    \"Block\",\n                    \"V\",\n                    \"Word32\",\n                    \"BranchHint\",\n                    \"Operation\",\n                    \"BranchOp\",\n                    \"GotoOp\",\n                    \"Any\",\n                    \"RegisterRepresentation\",\n                    \"SelectOp\",\n                    \"PhiOp\",\n                    \"OpIndex\",\n                    \"ReturnOp\",\n                    \"SwitchOp\",\n                    \"FrameState\",\n                    \"DeoptimizeParameters\",\n                    \"DeoptimizeIf\",\n                    \"TrapId\",\n                    \"ConstantOp\",\n                    \"OptionalV\",\n                    \"ZoneVector\",\n                    \"LayeredHashMap\"\n                ]\n            }\n        </metadata>\n        <code><![CDATA[\ntemplate <class Next>\nclass BranchEliminationReducer : public Next {\n  // # General overview\n  //\n  // BranchEliminationAssembler optimizes branches in a few ways:\n  //\n  //   1- When a branch is nested in another branch and uses the same condition,\n  //     then we can get rid of this branch and keep only the correct target.\n  //     For instance:\n  //\n  //         if (cond) {\n  //              if (cond) print(\"B1\");\n  //              else print(\"B2\");\n  //         } else {\n  //              if (cond) print(\"B3\");\n  //              else print(\"B4\");\n  //         }\n  //\n  //     Will be simplified to:\n  //\n  //         if (cond) {\n  //              print(\"B1\");\n  //         } else {\n  //              print(\"B4\");\n  //         }\n  //\n  //     Because the 1st nested \"if (cond)\" is always true, and the 2nd is\n  //     always false.\n  //\n  //     Or, if you prefer a more graph-oriented visual representation:\n  //\n  //           condition                             condition\n  //           |   |   |                                 |\n  //       -----   |   ------                            |\n  //       |       |        |                            |\n  //       |       v        |                            v\n  //       |     branch     |                         branch\n  //       |     /     \\    |                          /   \\\n  //       |    /       \\   |                         /     \\\n  //       v   /         \\  v         becomes        v       v\n  //       branch      branch         ======>       B1       B4\n  //        /  \\        /  \\\n  //       /    \\      /    \\\n  //      B1     B2   B3     B4\n  //\n  //\n  //   2- When 2 consecutive branches (where the 2nd one is after the merging of\n  //     the 1st one) have the same condition, we can pull up the 2nd branch to\n  //     get rid of the merge of the 1st branch and the branch of the 2nd\n  //     branch. For instance:\n  //\n  //         if (cond) {\n  //             B1;\n  //         } else {\n  //             B2;\n  //         }\n  //         B3;\n  //         if (cond) {\n  //             B4;\n  //         } else {\n  //             B5;\n  //         }\n  //\n  //     Will be simplified to:\n  //\n  //         if (cond) {\n  //             B1;\n  //             B3;\n  //             B4;\n  //         } else {\n  //             B2;\n  //             B3;\n  //             B5;\n  //         }\n  //\n  //     Or, if you prefer a more graph-oriented visual representation:\n  //\n  //           condition                           condition\n  //           |     |                                 |\n  //     -------     |                                 |\n  //     |           v                                 v\n  //     |        branch                            branch\n  //     |         /  \\                              /  \\\n  //     |        /    \\                            /    \\\n  //     |       B1    B2                          B1    B2\n  //     |        \\    /                           |     |\n  //     |         \\  /         becomes            |     |\n  //     |        merge1        ======>            B3    B3\n  //     |          B3                             |     |\n  //     -------> branch                           |     |\n  //               /  \\                            B4    B5\n  //              /    \\                            \\    /\n  //             B4    B5                            \\  /\n  //              \\    /                             merge\n  //               \\  /\n  //              merge2\n  //\n  //   2bis- In the 2nd optimization, if `cond` is a Phi of 2 values that come\n  //   from B1 and B2, then the same optimization can be applied for a similar\n  //   result. For instance:\n  //\n  //     if (cond) {                                if (cond) {\n  //       x = 1                                        x = 1;\n  //     } else {                becomes                B1\n  //       x = 0                 ======>            } else {\n  //     }                                              x = 0;\n  //     if (x) B1 else B2                              B2;\n  //                                                }\n  //\n  //   If `x` is more complex than a simple boolean, then the 2nd branch will\n  //   remain, except that it will be on `x`'s value directly rather than on a\n  //   Phi (so, it avoids creating a Phi, and it will probably be better for\n  //   branch prediction).\n  //\n  //\n  //   3- Optimizing {Return} nodes through merges. It checks that\n  //    the return value is actually a {Phi} and the Return is dominated\n  //    only by the Phi.\n  //\n  //    if (c) {                         if (c) {\n  //       v = 42;            ====>         v = 42;\n  //    } else {                            return v;\n  //       v = 5;                        } else {\n  //    }                                   v = 5;\n  //    return v;                           return v;\n  //                                     }\n  //\n  //    And here's the graph representation:\n  //\n  //    +----B1----+    <Some other           +----B1'----+     +----B2'----+\n  //    | p1 = ... |      block(s):           | p1 = ...  |     | p2 = ...  |\n  //    | <...>    |      B2,...>             | <...>     |     | <...>     |\n  //    +----------+        /                 | return p1 |     | return p2 |\n  //         \\             /                  +-----------+     +-----------+\n  //          \\           /          =====>\n  //           \\         /\n  //            \\       |\n  //        +--------B3-------+\n  //        | p = Phi(p1,...) |\n  //        | <...>           |\n  //        | return p        |\n  //        +-----------------+\n  //\n  //\n  //    4- Eliminating merges: if the 2 merged branches are empty,\n  //    and the merge block doesn't have a Phi (which is either the first\n  //    operation or is only preceded by FrameState operations),\n  //    we can remove the merge and instead Goto the block from the new graph.\n  //\n  //    5- Eliminating unneeded control flow edges: if a block has only one\n  //    successor and the successor only has one predecessor, we can merge these\n  //    blocks.\n  //\n  // # Technical overview of the implementation\n  //\n  // We iterate the graph in dominator order, and maintain a hash map of\n  // conditions with a resolved value along the current path. For instance, if\n  // we have:\n  //     if (c) { B1 } else { B2 }\n  // when iterating B1, we'll know that |c| is true, while when iterating\n  // over B2, we'll know that |c| is false.\n  // When reaching a Branch, we'll insert the condition in the hash map, while\n  // when reaching a Merge, we'll remove it.\n  //\n  // Then, the 1st optimization (nested branches with the same condition) is\n  // trivial: we just look in the hashmap if the condition is known, and only\n  // generate the right branch target without generating the branch itself.\n  //\n  // For the 2nd optimization, when generating a Goto, we check if the\n  // destination block ends with a branch whose condition is already known. If\n  // that's the case, then we copy the destination block, and the 1st\n  // optimization will replace its final Branch by a Goto when reaching it.\n public:\n  TURBOSHAFT_REDUCER_BOILERPLATE(BranchElimination)\n  // TODO(dmercadier): Add static_assert that this is ran as part of a\n  // CopyingPhase.\n\n  void Bind(Block* new_block) {\n    Next::Bind(new_block);\n\n    if (ShouldSkipOptimizationStep()) {\n      // It's important to have a ShouldSkipOptimizationStep here, because\n      // {known_conditions_} assumes that we perform all branch elimination\n      // possible (which implies that we don't ever insert twice the same thing\n      // in {known_conditions_}). If we stop doing ReduceBranch because of\n      // ShouldSkipOptimizationStep, then this assumption doesn't hold anymore,\n      // and we should thus stop updating {known_conditions_} to not trigger\n      // some DCHECKs.\n      return;\n    }\n\n    // Update {known_conditions_} based on where {new_block} is in the dominator\n    // tree.\n    ResetToBlock(new_block);\n    ReplayMissingPredecessors(new_block);\n    StartLayer(new_block);\n\n    if (new_block->IsBranchTarget()) {\n      // The current block is a branch target, so we add the branch condition\n      // along with its value in {known_conditions_}.\n      DCHECK_EQ(new_block->PredecessorCount(), 1);\n      const Operation& op =\n          new_block->LastPredecessor()->LastOperation(__ output_graph());\n      if (const BranchOp* branch = op.TryCast<BranchOp>()) {\n        DCHECK_EQ(new_block, any_of(branch->if_true, branch->if_false));\n        bool condition_value = branch->if_true == new_block;\n        if (!known_conditions_.Contains(branch->condition())) {\n          known_conditions_.InsertNewKey(branch->condition(), condition_value);\n        }\n      }\n    }\n  }\n\n  V<None> REDUCE(Branch)(V<Word32> cond, Block* if_true, Block* if_false,\n                         BranchHint hint) {\n    LABEL_BLOCK(no_change) {\n      return Next::ReduceBranch(cond, if_true, if_false, hint);\n    }\n    if (ShouldSkipOptimizationStep()) goto no_change;\n\n    if (const Block* if_true_origin = __ OriginForBlockStart(if_true)) {\n      if (const Block* if_false_origin = __ OriginForBlockStart(if_false)) {\n        const Operation& first_op_true =\n            if_true_origin->FirstOperation(__ input_graph());\n        const Operation& first_op_false =\n            if_false_origin->FirstOperation(__ input_graph());\n        const GotoOp* true_goto = first_op_true.template TryCast<GotoOp>();\n        const GotoOp* false_goto = first_op_false.template TryCast<GotoOp>();\n        // We apply the fourth optimization, replacing empty braches with a\n        // Goto to their destination (if it's the same block).\n        if (true_goto && false_goto &&\n            true_goto->destination == false_goto->destination) {\n          Block* merge_block = true_goto->destination;\n          if (!merge_block->HasPhis(__ input_graph())) {\n            // Using `ReduceInputGraphGoto()` here enables more optimizations.\n            __ Goto(__ MapToNewGraph(merge_block));\n            return V<None>::Invalid();\n          }\n        }\n      }\n    }\n\n    if (auto cond_value = known_conditions_.Get(cond)) {\n      // We already know the value of {cond}. We thus remove the branch (this is\n      // the \"first\" optimization in the documentation at the top of this\n      // module).\n      __ Goto(*cond_value ? if_true : if_false);\n      return V<None>::Invalid();\n    }\n    // We can't optimize this branch.\n    goto no_change;\n  }\n\n  V<Any> REDUCE(Select)(V<Word32> cond, V<Any> vtrue, V<Any> vfalse,\n                        RegisterRepresentation rep, BranchHint hint,\n                        SelectOp::Implementation implem) {\n    LABEL_BLOCK(no_change) {\n      return Next::ReduceSelect(cond, vtrue, vfalse, rep, hint, implem);\n    }\n    if (ShouldSkipOptimizationStep()) goto no_change;\n\n    if (auto cond_value = known_conditions_.Get(cond)) {\n      if (*cond_value) {\n        return vtrue;\n      } else {\n        return vfalse;\n      }\n    }\n    goto no_change;\n  }\n\n  V<None> REDUCE(Goto)(Block* destination, bool is_backedge) {\n    LABEL_BLOCK(no_change) {\n      return Next::ReduceGoto(destination, is_backedge);\n    }\n    if (ShouldSkipOptimizationStep()) goto no_change;\n\n    const Block* destination_origin = __ OriginForBlockStart(destination);\n    if (!destination_origin || !destination_origin->IsMerge()) {\n      goto no_change;\n    }\n\n    // Maximum size up to which we allow cloning a block. Cloning too large\n    // blocks will lead to increasing the size of the graph too much, which will\n    // lead to slower compile time, and larger generated code.\n    // TODO(dmercadier): we might want to exclude Phis from this, since they are\n    // typically removed when we clone a block. However, computing the number of\n    // operations in a block excluding Phis is more costly (because we'd have to\n    // iterate all of the operations one by one).\n    // TODO(dmercadier): this \"13\" was selected fairly arbitrarily (= it sounded\n    // reasonable). It could be useful to run a few benchmarks to see if we can\n    // find a more optimal number.\n    static constexpr int kMaxOpCountForCloning = 13;\n\n    const Operation& last_op =\n        destination_origin->LastOperation(__ input_graph());\n\n    if (destination_origin->OpCountUpperBound() > kMaxOpCountForCloning) {\n      goto no_change;\n    }\n\n    if (const BranchOp* branch = last_op.template TryCast<BranchOp>()) {\n      V<Word32> condition =\n          __ template MapToNewGraph<true>(branch->condition());\n      if (condition.valid()) {\n        std::optional<bool> condition_value = known_conditions_.Get(condition);\n        if (!condition_value.has_value()) {\n          // We've already visited the subsequent block's Branch condition, but\n          // we don't know its value right now.\n          goto no_change;\n        }\n\n        // The next block {new_dst} is a Merge, and ends with a Branch whose\n        // condition is already known. As per the 2nd optimization, we'll\n        // process {new_dst} right away, and we'll end it with a Goto instead of\n        // its current Branch.\n        __ CloneBlockAndGoto(destination_origin);\n        return {};\n      } else {\n        // Optimization 2bis:\n        // {condition} hasn't been visited yet, and thus it doesn't have a\n        // mapping to the new graph. However, if it's the result of a Phi whose\n        // input is coming from the current block, then it still makes sense to\n        // inline {destination_origin}: the condition will then be known.\n        if (destination_origin->Contains(branch->condition())) {\n          if (__ input_graph().Get(branch->condition()).template Is<PhiOp>()) {\n            __ CloneBlockAndGoto(destination_origin);\n            return {};\n          } else if (CanBeConstantFolded(branch->condition(),\n                                         destination_origin)) {\n            // If the {cond} only uses constant Phis that come from the current\n            // block, it's probably worth it to clone the block in order to\n            // constant-fold away the Branch.\n            __ CloneBlockAndGoto(destination_origin);\n            return {};\n          } else {\n            goto no_change;\n          }\n        }\n      }\n    } else if (last_op.template Is<ReturnOp>()) {\n      // In case of the following pattern, the `Goto` is most likely going to be\n      // folded into a jump table, so duplicating Block 5 will only increase the\n      // amount of different targets within the jump table.\n      //\n      // Block 1:\n      // [...]\n      // SwitchOp()[2, 3, 4]\n      //\n      // Block 2:    Block 3:    Block 4:\n      // Goto  5     Goto  5     Goto  6\n      //\n      // Block 5:                Block 6:\n      // [...]                   [...]\n      // ReturnOp\n      if (Asm().current_block()->PredecessorCount() == 1 &&\n          Asm().current_block()->begin() ==\n              __ output_graph().next_operation_index()) {\n        const Block* prev_block = Asm().current_block()->LastPredecessor();\n        if (prev_block->LastOperation(__ output_graph())\n                .template Is<SwitchOp>()) {\n          goto no_change;\n        }\n      }\n      // The destination block in the old graph ends with a Return\n      // and the old destination is a merge block, so we can directly\n      // inline the destination block in place of the Goto.\n      Asm().CloneAndInlineBlock(destination_origin);\n      return {};\n    }\n\n    goto no_change;\n  }\n\n  V<None> REDUCE(DeoptimizeIf)(V<Word32> condition, V<FrameState> frame_state,\n                               bool negated,\n                               const DeoptimizeParameters* parameters) {\n    LABEL_BLOCK(no_change) {\n      return Next::ReduceDeoptimizeIf(condition, frame_state, negated,\n                                      parameters);\n    }\n    if (ShouldSkipOptimizationStep()) goto no_change;\n\n    std::optional<bool> condition_value = known_conditions_.Get(condition);\n    if (!condition_value.has_value()) {\n      known_conditions_.InsertNewKey(condition, negated);\n      goto no_change;\n    }\n\n    if ((*condition_value && !negated) || (!*condition_value && negated)) {\n      // The condition is true, so we always deoptimize.\n      return Next::ReduceDeoptimize(frame_state, parameters);\n    } else {\n      // The condition is false, so we never deoptimize.\n      return V<None>::Invalid();\n    }\n  }\n\n#if V8_ENABLE_WEBASSEMBLY\n  V<None> REDUCE(TrapIf)(V<Word32> condition, OptionalV<FrameState> frame_state,\n                         bool negated, const TrapId trap_id) {\n    LABEL_BLOCK(no_change) {\n      return Next::ReduceTrapIf(condition, frame_state, negated, trap_id);\n    }\n    if (ShouldSkipOptimizationStep()) goto no_change;\n\n    std::optional<bool> condition_value = known_conditions_.Get(condition);\n    if (!condition_value.has_value()) {\n      known_conditions_.InsertNewKey(condition, negated);\n      goto no_change;\n    }\n\n    if (__ matcher().template Is<ConstantOp>(condition)) {\n      goto no_change;\n    }\n\n    V<Word32> static_condition = __ Word32Constant(*condition_value);\n    if (negated) {\n      __ TrapIfNot(static_condition, frame_state, trap_id);\n    } else {\n      __ TrapIf(static_condition, frame_state, trap_id);\n    }\n    return V<None>::Invalid();\n  }\n#endif  // V8_ENABLE_WEBASSEMBLY\n\n private:\n  // Resets {known_conditions_} and {dominator_path_} up to the 1st dominator of\n  // {block} that they contain.\n  void ResetToBlock(Block* block) {\n    Block* target = block->GetDominator();\n    while (!dominator_path_.empty() && target != nullptr &&\n           dominator_path_.back() != target) {\n      if (dominator_path_.back()->Depth() > target->Depth()) {\n        ClearCurrentEntries();\n      } else if (dominator_path_.back()->Depth() < target->Depth()) {\n        target = target->GetDominator();\n      } else {\n        // {target} and {dominator_path.back} have the same depth but are not\n        // equal, so we go one level up for both.\n        ClearCurrentEntries();\n        target = target->GetDominator();\n      }\n    }\n  }\n\n  // Removes the latest entry in {known_conditions_} and {dominator_path_}.\n  void ClearCurrentEntries() {\n    known_conditions_.DropLastLayer();\n    dominator_path_.pop_back();\n  }\n\n  void StartLayer(Block* block) {\n    known_conditions_.StartLayer();\n    dominator_path_.push_back(block);\n  }\n\n  // ReplayMissingPredecessors adds to {known_conditions_} and {dominator_path_}\n  // the conditions/blocks that related to the dominators of {block} that are\n  // not already present. This can happen when control-flow changes during the\n  // CopyingPhase, which results in a block being visited not right after\n  // its dominator. For instance, when optimizing a double-diamond like:\n  //\n  //                  B0\n  //                 /  \\\n  //                /    \\\n  //               B1    B2\n  //                \\    /\n  //                 \\  /\n  //                  B3\n  //                 /  \\\n  //                /    \\\n  //               B4    B5\n  //                \\    /\n  //                 \\  /\n  //                  B6\n  //                 /  \\\n  //                /    \\\n  //               B7    B8\n  //                \\    /\n  //                 \\  /\n  //                  B9\n  //\n  // In this example, where B0, B3 and B6 branch on the same condition, the\n  // blocks are actually visited in the following order: B0 - B1 - B3/1 - B2 -\n  // B3/2 - B4 - B5 - ... (note how B3 is duplicated and visited twice because\n  // from B1/B2 its branch condition is already known; I've noted the duplicated\n  // blocks as B3/1 and B3/2). In the new graph, the dominator of B4 is B3/1 and\n  // the dominator of B5 is B3/2. Except that upon visiting B4, the last visited\n  // block is not B3/1 but rather B3/2, so, we have to reset {known_conditions_}\n  // to B0, and thus miss that we actually know branch condition of B0/B3/B6 and\n  // we thus won't optimize the 3rd diamond.\n  //\n  // To overcome this issue, ReplayMissingPredecessors will add the information\n  // of the missing predecessors of the current block to {known_conditions_}. In\n  // the example above, this means that when visiting B4,\n  // ReplayMissingPredecessors will add the information of B3/1 to\n  // {known_conditions_}.\n  void ReplayMissingPredecessors(Block* new_block) {\n    // Collect blocks that need to be replayed.\n    base::SmallVector<Block*, 32> missing_blocks;\n    for (Block* dom = new_block->GetDominator();\n         dom != nullptr && dom != dominator_path_.back();\n         dom = dom->GetDominator()) {\n      missing_blocks.push_back(dom);\n    }\n    // Actually does the replaying, starting from the oldest block and finishing\n    // with the newest one (so that they will later be removed in the correct\n    // order).\n    for (auto it = missing_blocks.rbegin(); it != missing_blocks.rend(); ++it) {\n      Block* block = *it;\n      StartLayer(block);\n\n      if (block->IsBranchTarget()) {\n        const Operation& op =\n            block->LastPredecessor()->LastOperation(__ output_graph());\n        if (const BranchOp* branch = op.TryCast<BranchOp>()) {\n          DCHECK(branch->if_true->index() == block->index() ||\n                 branch->if_false->index() == block->index());\n          bool condition_value =\n              branch->if_true->index().valid()\n                  ? branch->if_true->index() == block->index()\n                  : branch->if_false->index() != block->index();\n          known_conditions_.InsertNewKey(branch->condition(), condition_value);\n        }\n      }\n    }\n  }\n\n  // Checks that {idx} only depends on only on Constants or on Phi whose input\n  // from the current block is a Constant, and on a least one Phi (whose input\n  // from the current block is a Constant). If it is the case and {idx} is used\n  // in a Branch, then the Branch's block could be cloned in the current block,\n  // and {idx} could then be constant-folded away such that the Branch becomes a\n  // Goto.\n  bool CanBeConstantFolded(OpIndex idx, const Block* cond_input_block,\n                           bool has_phi = false, int depth = 0) {\n    // We limit the depth of the search to {kMaxDepth} in order to avoid\n    // potentially visiting a lot of nodes.\n    static constexpr int kMaxDepth = 4;\n    if (depth > kMaxDepth) return false;\n    const Operation& op = __ input_graph().Get(idx);\n    if (!cond_input_block->Contains(idx)) {\n      // If we reach a ConstantOp without having gone through a Phi, then the\n      // condition can be constant-folded without performing block cloning.\n      return has_phi && op.Is<ConstantOp>();\n    }\n    if (op.Is<PhiOp>()) {\n      int curr_block_pred_idx = cond_input_block->GetPredecessorIndex(\n          __ current_block()->OriginForBlockEnd());\n      // There is no need to increment {depth} on this recursive call, because\n      // it will anyways exit early because {idx} won't be in\n      // {cond_input_block}.\n      return CanBeConstantFolded(op.input(curr_block_pred_idx),\n                                 cond_input_block, /*has_phi*/ true, depth);\n    } else if (op.Is<ConstantOp>()) {\n      return true;\n    } else if (op.input_count == 0) {\n      // Any operation that has no input but is not a ConstantOp probably won't\n      // be able to be constant-folded away (eg, LoadRootRegister).\n      return false;\n    } else if (!op.Effects().can_be_constant_folded()) {\n      // Operations with side-effects won't be able to be constant-folded.\n      return false;\n    }\n\n    for (int i = 0; i < op.input_count; i++) {\n      if (!CanBeConstantFolded(op.input(i), cond_input_block, has_phi,\n                               depth + 1)) {\n        return false;\n      }\n    }\n\n    return has_phi;\n  }\n\n  // TODO(dmercadier): use the SnapshotTable to replace {dominator_path_} and\n  // {known_conditions_}, and to reuse the existing merging/replay logic of the\n  // SnapshotTable.\n  ZoneVector<Block*> dominator_path_{__ phase_zone()};\n  LayeredHashMap<V<Word32>, bool> known_conditions_{\n      __ phase_zone(), __ input_graph().DominatorTreeDepth() * 2};\n};\n        ]]></code>\n    </class>\n    <func>\n        <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"method\",\n                \"name\": \"Bind\",\n                \"parent\": \"BranchEliminationReducer\",\n                \"about\": \"Binds a new block to the reducer, updating known conditions based on the block's position in the dominator tree.\",\n                \"logic\": \"Updates the known conditions hash map based on the block's position in the dominator tree. It adds branch conditions to the hash map when a block is a branch target.\",\n                \"parameters\": [\n                    {\n                        \"name\": \"new_block\",\n                        \"type\": \"Block*\",\n                        \"purpose\": \"The new block to bind to the reducer.\"\n                    }\n                ],\n                \"return\": {\n                    \"type\": \"void\",\n                    \"description\": \"No return value\"\n                },\n                \"dependencies\": [\n                    \"Next::Bind\",\n                    \"ShouldSkipOptimizationStep\",\n                    \"ResetToBlock\",\n                    \"ReplayMissingPredecessors\",\n                    \"StartLayer\",\n                    \"new_block->IsBranchTarget\",\n                    \"new_block->PredecessorCount\",\n                    \"new_block->LastPredecessor\",\n                    \"BranchOp\",\n                    \"known_conditions_\"\n                ]\n            }\n        </metadata>\n        <code><![CDATA[\n  void Bind(Block* new_block) {\n    Next::Bind(new_block);\n\n    if (ShouldSkipOptimizationStep()) {\n      // It's important to have a ShouldSkipOptimizationStep here, because\n      // {known_conditions_} assumes that we perform all branch elimination\n      // possible (which implies that we don't ever insert twice the same thing\n      // in {known_conditions_}). If we stop doing ReduceBranch because of\n      // ShouldSkipOptimizationStep, then this assumption doesn't hold anymore,\n      // and we should thus stop updating {known_conditions_} to not trigger\n      // some DCHECKs.\n      return;\n    }\n\n    // Update {known_conditions_} based on where {new_block} is in the dominator\n    // tree.\n    ResetToBlock(new_block);\n    ReplayMissingPredecessors(new_block);\n    StartLayer(new_block);\n\n    if (new_block->IsBranchTarget()) {\n      // The current block is a branch target, so we add the branch condition\n      // along with its value in {known_conditions_}.\n      DCHECK_EQ(new_block->PredecessorCount(), 1);\n      const Operation& op =\n          new_block->LastPredecessor()->LastOperation(__ output_graph());\n      if (const BranchOp* branch = op.TryCast<BranchOp>()) {\n        DCHECK_EQ(new_block, any_of(branch->if_true, branch->if_false));\n        bool condition_value = branch->if_true == new_block;\n        if (!known_conditions_.Contains(branch->condition())) {\n          known_conditions_.InsertNewKey(branch->condition(), condition_value);\n        }\n      }\n    }\n  }\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n            {\n                \"language\": \"cpp\",\n                \"type\": \"method\",\n                \"name\": \"REDUCE(Branch)\",\n                \"parent\": \"BranchEliminationReducer\",\n                \"about\": \"Reduces a Branch operation by eliminating it if the condition is known or by replacing it with a Goto if the target blocks can be simplified.\",\n                \"logic\": \"Checks if the branch condition is already known. If it is, the branch is replaced with a Goto to the appropriate target block.  Also checks if target blocks can be replaced with gotos.\",\n                \"parameters\": [\n                    {\n                        \"name\": \"cond\",\n                        \"type\": \"V<Word32>\",\n                        \"purpose\": \"The condition of the branch.\"\n                    },\n                    {\n                        \"name\": \"if_true\",\n                        \"type\": \"Block*\",\n                        \"purpose\": \"The block to jump to if the condition is true.\"\n                    },\n                    {\n                        \"name\": \"if_false\",\n                        \"type\": \"Block*\",\n                        \"purpose\": \"The block to jump to if the condition is false.\"\n                    },\n                    {\n                        \"name\": \"hint\",\n                        \"type\": \"BranchHint\",\n                        \"purpose\": \"Branch prediction hint.\"\n                    }\n                ],\n                \"return\": {\n                    \"type\": \"V"
}