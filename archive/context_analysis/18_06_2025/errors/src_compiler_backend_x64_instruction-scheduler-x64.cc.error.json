{
  "file_path": "/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/x64/instruction-scheduler-x64.cc",
  "error": "Response not JSON and not XML-like after cleanup",
  "json_error_if_any": "Skipped JSON parsing for whole response due to presence of XML tags; XML is primary.",
  "raw_response": "```xml\n<file>\n    <metadata>\n    {\n        \"path\": \"/home/kathirks_gc/v8_go/archive/codebase/src/compiler/backend/x64/instruction-scheduler-x64.cc\",\n        \"file_name\": \"instruction-scheduler-x64.cc\",\n        \"language\": \"cpp\",\n        \"purpose\": \"Implements the instruction scheduler for the x64 architecture in the V8 compiler backend.  It defines methods to determine if scheduling is supported, to get target-specific instruction flags, and to retrieve instruction latencies for the x64 architecture.\"\n    }\n    </metadata>\n    <imports>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"purpose\": \"Includes the InstructionScheduler class definition.\"\n        }\n        </metadata>\n        <code><![CDATA[\n#include \"src/compiler/backend/instruction-scheduler.h\"\n        ]]></code>\n    </imports>\n    <class>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"class\",\n            \"name\": \"InstructionScheduler\",\n            \"about\": \"Provides instruction scheduling functionality.\",\n            \"dependencies\": []\n        }\n        </metadata>\n        <code><![CDATA[\nnamespace v8 {\nnamespace internal {\nnamespace compiler {\n\n        ]]></code>\n    </class>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"SchedulerSupported\",\n            \"parent\": \"InstructionScheduler\",\n            \"about\": \"Determines if instruction scheduling is supported for the x64 architecture.\",\n            \"logic\": \"Always returns true, indicating that scheduling is supported.\",\n            \"parameters\": [],\n            \"return\": {\n                \"type\": \"bool\",\n                \"description\": \"True if scheduling is supported, false otherwise.\"\n            },\n            \"dependencies\": []\n        }\n        </metadata>\n        <code><![CDATA[\nbool InstructionScheduler::SchedulerSupported() { return true; }\n        ]]></code>\n    </func>\n    <func>\n        <metadata>\n        {\n            \"language\": \"cpp\",\n            \"type\": \"method\",\n            \"name\": \"GetTargetInstructionFlags\",\n            \"parent\": \"InstructionScheduler\",\n            \"about\": \"Gets target-specific instruction flags for a given instruction on the x64 architecture.\",\n            \"logic\": \"Uses a switch statement to determine instruction flags based on the instruction's architecture-specific opcode.  Flags indicate side effects, load operations, or potential deoptimization/trap checks.\",\n            \"parameters\": [\n                {\n                    \"name\": \"instr\",\n                    \"type\": \"const Instruction*\",\n                    \"purpose\": \"The instruction to get flags for.\"\n                }\n            ],\n            \"return\": {\n                \"type\": \"int\",\n                \"description\": \"The target-specific instruction flags.\"\n            },\n            \"dependencies\": [\n                \"Instruction\",\n                \"kX64TraceInstruction\",\n                \"kHasSideEffect\",\n                \"kX64Add\",\n                \"kX64Add32\",\n                \"kX64And\",\n                \"kX64And32\",\n                \"kX64Cmp\",\n                \"kX64Cmp32\",\n                \"kX64Cmp16\",\n                \"kX64Cmp8\",\n                \"kX64Test\",\n                \"kX64Test32\",\n                \"kX64Test16\",\n                \"kX64Test8\",\n                \"kX64Or\",\n                \"kX64Or32\",\n                \"kX64Xor\",\n                \"kX64Xor32\",\n                \"kX64Sub\",\n                \"kX64Sub32\",\n                \"kX64Imul\",\n                \"kX64Imul32\",\n                \"kX64ImulHigh32\",\n                \"kX64UmulHigh32\",\n                \"kX64ImulHigh64\",\n                \"kX64UmulHigh64\",\n                \"kX64Not\",\n                \"kX64Not32\",\n                \"kX64Neg\",\n                \"kX64Neg32\",\n                \"kX64Shl\",\n                \"kX64Shl32\",\n                \"kX64Shr\",\n                \"kX64Shr32\",\n                \"kX64Sar\",\n                \"kX64Sar32\",\n                \"kX64Rol\",\n                \"kX64Rol32\",\n                \"kX64Ror\",\n                \"kX64Ror32\",\n                \"kX64Lzcnt\",\n                \"kX64Lzcnt32\",\n                \"kX64Tzcnt\",\n                \"kX64Tzcnt32\",\n                \"kX64Popcnt\",\n                \"kX64Popcnt32\",\n                \"kX64Bswap\",\n                \"kX64Bswap32\",\n                \"kSSEFloat32Cmp\",\n                \"kSSEFloat32Add\",\n                \"kSSEFloat32Sub\",\n                \"kSSEFloat32Mul\",\n                \"kSSEFloat32Div\",\n                \"kSSEFloat32Sqrt\",\n                \"kSSEFloat32Round\",\n                \"kSSEFloat32ToFloat64\",\n                \"kSSEFloat64Cmp\",\n                \"kSSEFloat64Add\",\n                \"kSSEFloat64Sub\",\n                \"kSSEFloat64Mul\",\n                \"kSSEFloat64Div\",\n                \"kSSEFloat64Mod\",\n                \"kSSEFloat64Sqrt\",\n                \"kSSEFloat64Round\",\n                \"kSSEFloat32Max\",\n                \"kSSEFloat64Max\",\n                \"kSSEFloat32Min\",\n                \"kSSEFloat64Min\",\n                \"kSSEFloat64ToFloat32\",\n                \"kSSEFloat64ToFloat16RawBits\",\n                \"kSSEFloat16RawBitsToFloat64\",\n                \"kSSEFloat32ToInt32\",\n                \"kSSEFloat32ToUint32\",\n                \"kSSEFloat64ToInt32\",\n                \"kSSEFloat64ToUint32\",\n                \"kSSEFloat64ToInt64\",\n                \"kSSEFloat32ToInt64\",\n                \"kSSEFloat64ToUint64\",\n                \"kSSEFloat32ToUint64\",\n                \"kSSEInt32ToFloat64\",\n                \"kSSEInt32ToFloat32\",\n                \"kSSEInt64ToFloat32\",\n                \"kSSEInt64ToFloat64\",\n                \"kSSEUint64ToFloat32\",\n                \"kSSEUint64ToFloat64\",\n                \"kSSEUint32ToFloat64\",\n                \"kSSEUint32ToFloat32\",\n                \"kSSEFloat64ExtractLowWord32\",\n                \"kSSEFloat64ExtractHighWord32\",\n                \"kSSEFloat64InsertLowWord32\",\n                \"kSSEFloat64InsertHighWord32\",\n                \"kSSEFloat64LoadLowWord32\",\n                \"kSSEFloat64SilenceNaN\",\n                \"kAVXFloat32Cmp\",\n                \"kAVXFloat32Add\",\n                \"kAVXFloat32Sub\",\n                \"kAVXFloat32Mul\",\n                \"kAVXFloat32Div\",\n                \"kAVXFloat64Cmp\",\n                \"kAVXFloat64Add\",\n                \"kAVXFloat64Sub\",\n                \"kAVXFloat64Mul\",\n                \"kAVXFloat64Div\",\n                \"kX64Float64Abs\",\n                \"kX64Float64Neg\",\n                \"kX64Float32Abs\",\n                \"kX64Float32Neg\",\n                \"kX64BitcastFI\",\n                \"kX64BitcastDL\",\n                \"kX64BitcastIF\",\n                \"kX64BitcastLD\",\n                \"kX64Lea32\",\n                \"kX64Lea\",\n                \"kX64Dec32\",\n                \"kX64Inc32\",\n                \"kX64Pinsrb\",\n                \"kX64Pinsrw\",\n                \"kX64Pinsrd\",\n                \"kX64Pinsrq\",\n                \"kX64Cvttps2dq\",\n                \"kX64Cvttpd2dq\",\n                \"kX64I32x4TruncF64x2UZero\",\n                \"kX64I32x4TruncF32x4U\",\n                \"kX64I32x8TruncF32x8U\",\n                \"kX64FSplat\",\n                \"kX64FExtractLane\",\n                \"kX64FReplaceLane\",\n                \"kX64FAbs\",\n                \"kX64FNeg\",\n                \"kX64FSqrt\",\n                \"kX64FAdd\",\n                \"kX64FSub\",\n                \"kX64FMul\",\n                \"kX64FDiv\",\n                \"kX64FMin\",\n                \"kX64FMax\",\n                \"kX64FEq\",\n                \"kX64FNe\",\n                \"kX64FLt\",\n                \"kX64FLe\",\n                \"kX64F64x2Qfma\",\n                \"kX64F64x2Qfms\",\n                \"kX64F64x4Qfma\",\n                \"kX64F64x4Qfms\",\n                \"kX64Minpd\",\n                \"kX64Maxpd\",\n                \"kX64F32x8Pmin\",\n                \"kX64F32x8Pmax\",\n                \"kX64F64x4Pmin\",\n                \"kX64F64x4Pmax\",\n                \"kX64F64x2Round\",\n                \"kX64F64x2ConvertLowI32x4S\",\n                \"kX64F64x4ConvertI32x4S\",\n                \"kX64F64x2ConvertLowI32x4U\",\n                \"kX64F64x2PromoteLowF32x4\",\n                \"kX64F32x4SConvertI32x4\",\n                \"kX64F32x8SConvertI32x8\",\n                \"kX64F32x4UConvertI32x4\",\n                \"kX64F32x8UConvertI32x8\",\n                \"kX64F32x4Qfma\",\n                \"kX64F32x4Qfms\",\n                \"kX64F32x8Qfma\",\n                \"kX64F32x8Qfms\",\n                \"kX64Minps\",\n                \"kX64Maxps\",\n                \"kX64F32x4Round\",\n                \"kX64F32x4DemoteF64x2Zero\",\n                \"kX64F32x4DemoteF64x4\",\n                \"kX64F16x8Round\",\n                \"kX64I16x8SConvertF16x8\",\n                \"kX64I16x8UConvertF16x8\",\n                \"kX64F16x8SConvertI16x8\",\n                \"kX64F16x8UConvertI16x8\",\n                \"kX64F16x8DemoteF32x4Zero\",\n                \"kX64F16x8DemoteF64x2Zero\",\n                \"kX64F32x4PromoteLowF16x8\",\n                \"kX64F16x8Qfma\",\n                \"kX64F16x8Qfms\",\n                \"kX64Minph\",\n                \"kX64Maxph\",\n                \"kX64ISplat\",\n                \"kX64IExtractLane\",\n                \"kX64IAbs\",\n                \"kX64INeg\",\n                \"kX64IBitMask\",\n                \"kX64IShl\",\n                \"kX64IShrS\",\n                \"kX64IAdd\",\n                \"kX64ISub\",\n                \"kX64IMul\",\n                \"kX64IEq\",\n                \"kX64IGtS\",\n                \"kX64IGeS\",\n                \"kX64INe\",\n                \"kX64IShrU\",\n                \"kX64I64x2ExtMulLowI32x4S\",\n                \"kX64I64x2ExtMulHighI32x4S\",\n                \"kX64I64x4ExtMulI32x4S\",\n                \"kX64I64x2ExtMulLowI32x4U\",\n                \"kX64I64x2ExtMulHighI32x4U\",\n                \"kX64I64x4ExtMulI32x4U\",\n                \"kX64I64x2SConvertI32x4Low\",\n                \"kX64I64x2SConvertI32x4High\",\n                \"kX64I64x4SConvertI32x4\",\n                \"kX64I64x2UConvertI32x4Low\",\n                \"kX64I64x2UConvertI32x4High\",\n                \"kX64I64x4UConvertI32x4\",\n                \"kX64I32x4SConvertF32x4\",\n                \"kX64I32x8SConvertF32x8\",\n                \"kX64I32x4SConvertI16x8Low\",\n                \"kX64I32x4SConvertI16x8High\",\n                \"kX64I32x8SConvertI16x8\",\n                \"kX64IMinS\",\n                \"kX64IMaxS\",\n                \"kX64I32x4UConvertF32x4\",\n                \"kX64I32x8UConvertF32x8\",\n                \"kX64I32x4UConvertI16x8Low\",\n                \"kX64I32x4UConvertI16x8High\",\n                \"kX64I32x8UConvertI16x8\",\n                \"kX64IMinU\",\n                \"kX64IMaxU\",\n                \"kX64IGtU\",\n                \"kX64IGeU\",\n                \"kX64I32x4DotI16x8S\",\n                \"kX64I32x8DotI16x16S\",\n                \"kX64I32x4DotI8x16I7x16AddS\",\n                \"kX64I32x8DotI8x32I7x32AddS\",\n                \"kX64I32x4ExtMulLowI16x8S\",\n                \"kX64I32x4ExtMulHighI16x8S\",\n                \"kX64I32x8ExtMulI16x8S\",\n                \"kX64I32x4ExtMulLowI16x8U\",\n                \"kX64I32x4ExtMulHighI16x8U\",\n                \"kX64I32x8ExtMulI16x8U\",\n                \"kX64I32x4ExtAddPairwiseI16x8S\",\n                \"kX64I32x8ExtAddPairwiseI16x16S\",\n                \"kX64I32x4ExtAddPairwiseI16x8U\",\n                \"kX64I32x8ExtAddPairwiseI16x16U\",\n                \"kX64I32x4TruncSatF64x2SZero\",\n                \"kX64I32x4TruncSatF64x2UZero\",\n                \"kX64I32X4ShiftZeroExtendI8x16\",\n                \"kX64IExtractLaneS\",\n                \"kX64I16x8SConvertI8x16Low\",\n                \"kX64I16x8SConvertI8x16High\",\n                \"kX64I16x16SConvertI8x16\",\n                \"kX64I16x8SConvertI32x4\",\n                \"kX64I16x16SConvertI32x8\",\n                \"kX64IAddSatS\",\n                \"kX64ISubSatS\",\n                \"kX64I16x8UConvertI8x16Low\",\n                \"kX64I16x8UConvertI8x16High\",\n                \"kX64I16x16UConvertI8x16\",\n                \"kX64I16x8UConvertI32x4\",\n                \"kX64I16x16UConvertI32x8\",\n                \"kX64IAddSatU\",\n                \"kX64ISubSatU\",\n                \"kX64IRoundingAverageU\",\n                \"kX64I16x8ExtMulLowI8x16S\",\n                \"kX64I16x8ExtMulHighI8x16S\",\n                \"kX64I16x16ExtMulI8x16S\",\n                \"kX64I16x8ExtMulLowI8x16U\",\n                \"kX64I16x8ExtMulHighI8x16U\",\n                \"kX64I16x16ExtMulI8x16U\",\n                \"kX64I16x8ExtAddPairwiseI8x16S\",\n                \"kX64I16x16ExtAddPairwiseI8x32S\",\n                \"kX64I16x8ExtAddPairwiseI8x16U\",\n                \"kX64I16x16ExtAddPairwiseI8x32U\",\n                \"kX64I16x8Q15MulRSatS\",\n                \"kX64I16x8RelaxedQ15MulRS\",\n                \"kX64I16x8DotI8x16I7x16S\",\n                \"kX64I16x16DotI8x32I7x32S\",\n                \"kX64I8x16SConvertI16x8\",\n                \"kX64I8x32SConvertI16x16\",\n                \"kX64I8x16UConvertI16x8\",\n                \"kX64I8x32UConvertI16x16\",\n                \"kX64SAnd\",\n                \"kX64SOr\",\n                \"kX64SXor\",\n                \"kX64SNot\",\n                \"kX64SSelect\",\n                \"kX64S128Const\",\n                \"kX64S256Const\",\n                \"kX64SZero\",\n                \"kX64SAllOnes\",\n                \"kX64SAndNot\",\n                \"kX64IAllTrue\",\n                \"kX64I8x16Swizzle\",\n                \"kX64Vpshufd\",\n                \"kX64I8x16Shuffle\",\n                \"kX64I8x16Popcnt\",\n                \"kX64Shufps\",\n                \"kX64S32x4Rotate\",\n                \"kX64S32x4Swizzle\",\n                \"kX64S32x4Shuffle\",\n                \"kX64S16x8Blend\",\n                \"kX64S16x8HalfShuffle1\",\n                \"kX64S16x8HalfShuffle2\",\n                \"kX64S8x16Alignr\",\n                \"kX64S16x8Dup\",\n                \"kX64S8x16Dup\",\n                \"kX64S16x8UnzipHigh\",\n                \"kX64S16x8UnzipLow\",\n                \"kX64S8x16UnzipHigh\",\n                \"kX64S8x16UnzipLow\",\n                \"kX64S64x2UnpackHigh\",\n                \"kX64S32x4UnpackHigh\",\n                \"kX64S16x8UnpackHigh\",\n                \"kX64S8x16UnpackHigh\",\n                \"kX64S32x8UnpackHigh\",\n                \"kX64S64x2UnpackLow\",\n                \"kX64S32x4UnpackLow\",\n                \"kX64S16x8UnpackLow\",\n                \"kX64S8x16UnpackLow\",\n                \"kX64S32x8UnpackLow\",\n                \"kX64S8x16TransposeLow\",\n                \"kX64S8x16TransposeHigh\",\n                \"kX64S8x8Reverse\",\n                \"kX64S8x4Reverse\",\n                \"kX64S8x2Reverse\",\n                \"kX64V128AnyTrue\",\n                \"kX64Blendvpd\",\n                \"kX64Blendvps\",\n                \"kX64Pblendvb\",\n                \"kX64ExtractF128\",\n                \"kX64InsertI128\",\n                \"kNoOpcodeFlags\",\n                \"kIsLoadOperation\",\n                \"kMayNeedDeoptOrTrapCheck\",\n                \"kX64Idiv\",\n                \"kX64Idiv32\",\n                \"kX64Udiv\",\n                \"kX64Udiv32\",\n                \"kX64Movsxbl\",\n                \"kX64Movzxbl\",\n                \"kX64Movsxbq\",\n                \"kX64Movzxbq\",\n                \"kX64Movsxwl\",\n                \"kX64Movzxwl\",\n                \"kX64Movsxwq\",\n                \"kX64Movzxwq\",\n                \"kX64Movsxlq\",\n                \"kX64Movb\",\n                \"kX64Movw\",\n                \"kX64S128Store32Lane\",\n                \"kX64S128Store64Lane\",\n                \"kX64Pextrb\",\n                \"kX64Pextrw\",\n                \"kX64Movl\",\n                \"kX64MovqDecompressTaggedSigned\",\n                \"kX64MovqDecompressTagged\",\n                \"kX64MovqDecompressProtected\",\n                \"kX64MovqCompressTagged\",\n                \"kX64MovqStoreIndirectPointer\",\n                \"kX64MovqDecodeSandboxedPointer\",\n                \"kX64MovqEncodeSandboxedPointer\",\n                \"kX64Movq\",\n                \"kX64Movsd\",\n                \"kX64Movss\",\n                \"kX64Movsh\",\n                \"kX64Movdqu\",\n                \"kX64Movdqu256\",\n                \"kX64S128Load8Splat\",\n                \"kX64S256Load8Splat\",\n                \"kX64S128Load16Splat\",\n                \"kX64S256Load16Splat\",\n                \"kX64S128Load32Splat\",\n                \"kX64S256Load32Splat\",\n                \"kX64S128Load64Splat\",\n                \"kX64S256Load64Splat\",\n                \"kX64S128Load8x8S\",\n                \"kX64S128Load8x8U\",\n                \"kX64S128Load16x4S\",\n                \"kX64S128Load16x4U\",\n                \"kX64S128Load32x2S\",\n                \"kX64S128Load32x2U\",\n                \"kX64S256Load8x16S\",\n                \"kX64S256Load8x16U\",\n                \"kX64S256Load8x8U\",\n                \"kX64S256Load16x8S\",\n                \"kX64S256Load16x8U\",\n                \"kX64S256Load32x4S\",\n                \"kX64S256Load32x4U\",\n                \"kX64Peek\",\n                \"kX64Push\",\n                \"kX64Poke\",\n                \"kX64MFence\",\n                \"kX64LFence\",\n                \"kX64Word64AtomicStoreWord64\",\n                \"kX64Word64AtomicAddUint64\",\n                \"kX64Word64AtomicSubUint64\",\n                \"kX64Word64AtomicAndUint64\",\n                \"kX64Word64AtomicOrUint64\",\n                \"kX64Word64AtomicXorUint64\",\n                \"kX64Word64AtomicExchangeUint64\",\n                \"kX64Word64AtomicCompareExchangeUint64\",\n                \"COMMON_ARCH_OPCODE_LIST\",\n                \"UNREACHABLE\",\n                \"addressing_mode\",\n                \"kMode_None\",\n                \"kInputAt\",\n                \"IsRegister\",\n                \"HasOutput\"\n            ]\n        }\n        </metadata>\n        <code><![CDATA[\nint InstructionScheduler::GetTargetInstructionFlags(\n    const Instruction* instr) const {\n  switch (instr->arch_opcode()) {\n    case kX64TraceInstruction:\n      return kHasSideEffect;\n    case kX64Add:\n    case kX64Add32:\n    case kX64And:\n    case kX64And32:\n    case kX64Cmp:\n    case kX64Cmp32:\n    case kX64Cmp16:\n    case kX64Cmp8:\n    case kX64Test:\n    case kX64Test32:\n    case kX64Test16:\n    case kX64Test8:\n    case kX64Or:\n    case kX64Or32:\n    case kX64Xor:\n    case kX64Xor32:\n    case kX64Sub:\n    case kX64Sub32:\n    case kX64Imul:\n    case kX64Imul32:\n    case kX64ImulHigh32:\n    case kX64UmulHigh32:\n    case kX64ImulHigh64:\n    case kX64UmulHigh64:\n    case kX64Not:\n    case kX64Not32:\n    case kX64Neg:\n    case kX64Neg32:\n    case kX64Shl:\n    case kX64Shl32:\n    case kX64Shr:\n    case kX64Shr32:\n    case kX64Sar:\n    case kX64Sar32:\n    case kX64Rol:\n    case kX64Rol32:\n    case kX64Ror:\n    case kX64Ror32:\n    case kX64Lzcnt:\n    case kX64Lzcnt32:\n    case kX64Tzcnt:\n    case kX64Tzcnt32:\n    case kX64Popcnt:\n    case kX64Popcnt32:\n    case kX64Bswap:\n    case kX64Bswap32:\n    case kSSEFloat32Cmp:\n    case kSSEFloat32Add:\n    case kSSEFloat32Sub:\n    case kSSEFloat32Mul:\n    case kSSEFloat32Div:\n    case kSSEFloat32Sqrt:\n    case kSSEFloat32Round:\n    case kSSEFloat32ToFloat64:\n    case kSSEFloat64Cmp:\n    case kSSEFloat64Add:\n    case kSSEFloat64Sub:\n    case kSSEFloat64Mul:\n    case kSSEFloat64Div:\n    case kSSEFloat64Mod:\n    case kSSEFloat64Sqrt:\n    case kSSEFloat64Round:\n    case kSSEFloat32Max:\n    case kSSEFloat64Max:\n    case kSSEFloat32Min:\n    case kSSEFloat64Min:\n    case kSSEFloat64ToFloat32:\n    case kSSEFloat64ToFloat16RawBits:\n    case kSSEFloat16RawBitsToFloat64:\n    case kSSEFloat32ToInt32:\n    case kSSEFloat32ToUint32:\n    case kSSEFloat64ToInt32:\n    case kSSEFloat64ToUint32:\n    case kSSEFloat64ToInt64:\n    case kSSEFloat32ToInt64:\n    case kSSEFloat64ToUint64:\n    case kSSEFloat32ToUint64:\n    case kSSEInt32ToFloat64:\n    case kSSEInt32ToFloat32:\n    case kSSEInt64ToFloat32:\n    case kSSEInt64ToFloat64:\n    case kSSEUint64ToFloat32:\n    case kSSEUint64ToFloat64:\n    case kSSEUint32ToFloat64:\n    case kSSEUint32ToFloat32:\n    case kSSEFloat64ExtractLowWord32:\n    case kSSEFloat64ExtractHighWord32:\n    case kSSEFloat64InsertLowWord32:\n    case kSSEFloat64InsertHighWord32:\n    case kSSEFloat64LoadLowWord32:\n    case kSSEFloat64SilenceNaN:\n    case kAVXFloat32Cmp:\n    case kAVXFloat32Add:\n    case kAVXFloat32Sub:\n    case kAVXFloat32Mul:\n    case kAVXFloat32Div:\n    case kAVXFloat64Cmp:\n    case kAVXFloat64Add:\n    case kAVXFloat64Sub:\n    case kAVXFloat64Mul:\n    case kAVXFloat64Div:\n    case kX64Float64Abs:\n    case kX64Float64Neg:\n    case kX64Float32Abs:\n    case kX64Float32Neg:\n    case kX64BitcastFI:\n    case kX64BitcastDL:\n    case kX64BitcastIF:\n    case kX64BitcastLD:\n    case kX64Lea32:\n    case kX64Lea:\n    case kX64Dec32:\n    case kX64Inc32:\n    case kX64Pinsrb:\n    case kX64Pinsrw:\n    case kX64Pinsrd:\n    case kX64Pinsrq:\n    case kX64Cvttps2dq:\n    case kX64Cvttpd2dq:\n    case kX64I32x4TruncF64x2UZero:\n    case kX64I32x4TruncF32x4U:\n    case kX64I32x8TruncF32x8U:\n    case kX64FSplat:\n    case kX64FExtractLane:\n    case kX64FReplaceLane:\n    case kX64FAbs:\n    case kX64FNeg:\n    case kX64FSqrt:\n    case kX64FAdd:\n    case kX64FSub:\n    case kX64FMul:\n    case kX64FDiv:\n    case kX64FMin:\n    case kX64FMax:\n    case kX64FEq:\n    case kX64FNe:\n    case kX64FLt:\n    case kX64FLe:\n    case kX64F64x2Qfma:\n    case kX64F64x2Qfms:\n    case kX64F64x4Qfma:\n    case kX64F64x4Qfms:\n    case kX64Minpd:\n    case kX64Maxpd:\n    case kX64F32x8Pmin:\n    case kX64F32x8Pmax:\n    case kX64F64x4Pmin:\n    case kX64F64x4Pmax:\n    case kX64F64x2Round:\n    case kX64F64x2ConvertLowI32x4S:\n    case kX64"
}