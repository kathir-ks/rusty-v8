// Converted from V8 C++ source files:
// Header: instruction-codes-arm64.h
// Implementation: N/A
// 
// This file combines both header and implementation into idiomatic Rust code.

pub mod arm64_instruction_codes_arm64 {
    // This file is generated from the corresponding C++ file.
    // Copyright 2014 the V8 project authors. All rights reserved.
    // Use of this source code is governed by a BSD-style license that can be
    // found in the LICENSE file.

    // ARM64-specific opcodes that specify which assembly sequence to emit.
    // Most opcodes specify a single instruction.

    // Opcodes that support a MemoryAccessMode.
    #[derive(Debug, Copy, Clone, PartialEq, Eq)]
    pub enum TargetArchOpcodeWithMemoryAccessMode {
        Arm64Ldr,
        Arm64Ldrb,
        Arm64LdrD,
        Arm64Ldrh,
        Arm64LdrQ,
        Arm64LdrS,
        Arm64LdrH,
        Arm64Ldrsb,
        Arm64LdrsbW,
        Arm64Ldrsh,
        Arm64LdrshW,
        Arm64Ldrsw,
        Arm64LdrW,
        Arm64LoadLane,
        Arm64LoadSplat,
        Arm64S128Load16x4S,
        Arm64S128Load16x4U,
        Arm64S128Load32x2S,
        Arm64S128Load32x2U,
        Arm64S128Load8x8S,
        Arm64S128Load8x8U,
        Arm64StoreLane,
        Arm64Str,
        Arm64StrPair,
        Arm64Strb,
        Arm64StrD,
        Arm64Strh,
        Arm64StrQ,
        Arm64StrS,
        Arm64StrH,
        Arm64StrW,
        Arm64StrWPair,
        Arm64LdrDecompressTaggedSigned,
        Arm64LdrDecompressTagged,
        Arm64LdrDecompressProtected,
        Arm64StrCompressTagged,
        Arm64Word64AtomicLoadUint64,
        Arm64Word64AtomicStoreWord64,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq)]
    pub enum TargetArchSimdOpcode {
        Arm64F64x2Qfma,
        Arm64F64x2Qfms,
        Arm64F64x2Pmin,
        Arm64F64x2Pmax,
        Arm64F64x2ConvertLowI32x4S,
        Arm64F64x2ConvertLowI32x4U,
        Arm64F64x2PromoteLowF32x4,
        Arm64F32x4SConvertI32x4,
        Arm64F32x4UConvertI32x4,
        Arm64F32x4Qfma,
        Arm64F32x4Qfms,
        Arm64F32x4Pmin,
        Arm64F32x4Pmax,
        Arm64F32x4DemoteF64x2Zero,
        Arm64F16x8Pmin,
        Arm64F16x8Pmax,
        Arm64F32x4PromoteLowF16x8,
        Arm64F16x8SConvertI16x8,
        Arm64F16x8UConvertI16x8,
        Arm64F16x8DemoteF32x4Zero,
        Arm64F16x8DemoteF64x2Zero,
        Arm64I16x8SConvertF16x8,
        Arm64I16x8UConvertF16x8,
        Arm64F16x8Qfma,
        Arm64F16x8Qfms,
        Arm64I64x2ShrU,
        Arm64I64x2BitMask,
        Arm64I32x4SConvertF32x4,
        Arm64I32x4Shl,
        Arm64I32x4ShrS,
        Arm64I32x4Mul,
        Arm64I16x8Q15MulRSatS,
        Arm64I16x8BitMask,
        Arm64I8x16Shl,
        Arm64I8x16ShrS,
        Arm64I8x16SConvertI16x8,
        Arm64I8x16ShrU,
        Arm64I8x16UConvertI16x8,
        Arm64I8x16BitMask,
        Arm64S128Const,
        Arm64S128Dup,
        Arm64S128And,
        Arm64S128Or,
        Arm64S128Xor,
        Arm64S128Not,
        Arm64S128Select,
        Arm64S128AndNot,
        Arm64Ssra,
        Arm64Usra,
        Arm64S64x2UnzipLeft,
        Arm64S64x2UnzipRight,
        Arm64S32x4ZipLeft,
        Arm64S32x4ZipRight,
        Arm64S32x4UnzipLeft,
        Arm64S32x4UnzipRight,
        Arm64S32x4TransposeLeft,
        Arm64S32x4TransposeRight,
        Arm64S64x2Shuffle,
        Arm64S64x1Shuffle,
        Arm64S32x4Shuffle,
        Arm64S32x2Shuffle,
        Arm64S32x1Shuffle,
        Arm64S16x2Shuffle,
        Arm64S16x1Shuffle,
        Arm64S8x2Shuffle,
        Arm64S16x8ZipLeft,
        Arm64S16x8ZipRight,
        Arm64S16x8UnzipLeft,
        Arm64S16x8UnzipRight,
        Arm64S16x8TransposeLeft,
        Arm64S16x8TransposeRight,
        Arm64S8x16ZipLeft,
        Arm64S8x16ZipRight,
        Arm64S8x16UnzipLeft,
        Arm64S8x16UnzipRight,
        Arm64S8x16TransposeLeft,
        Arm64S8x16TransposeRight,
        Arm64S8x16Concat,
        Arm64I8x16Swizzle,
        Arm64I8x16Shuffle,
        Arm64S32x4Reverse,
        Arm64S32x4OneLaneSwizzle,
        Arm64S32x2Reverse,
        Arm64S16x4Reverse,
        Arm64S16x2Reverse,
        Arm64S8x8Reverse,
        Arm64S8x4Reverse,
        Arm64S8x2Reverse,
        Arm64V128AnyTrue,
        Arm64I64x2AllTrue,
        Arm64I32x4AllTrue,
        Arm64I16x8AllTrue,
        Arm64I8x16AllTrue,
        Arm64Sxtl,
        Arm64Sxtl2,
        Arm64Uxtl,
        Arm64Uxtl2,
        Arm64FSplat,
        Arm64FAbs,
        Arm64FSqrt,
        Arm64FNeg,
        Arm64FExtractLane,
        Arm64FReplaceLane,
        Arm64ISplat,
        Arm64IAbs,
        Arm64INeg,
        Arm64IExtractLane,
        Arm64IReplaceLane,
        Arm64I64x2Shl,
        Arm64I64x2ShrS,
        Arm64I64x2Mul,
        Arm64I32x4UConvertF32x4,
        Arm64I32x4ShrU,
        Arm64I32x4BitMask,
        Arm64I32x4DotI16x8S,
        Arm64I16x8DotI8x16S,
        Arm64I32x4DotI8x16AddS,
        Arm64I8x16Addv,
        Arm64I16x8Addv,
        Arm64I32x4Addv,
        Arm64I64x2AddPair,
        Arm64F32x4AddReducePairwise,
        Arm64F64x2AddPair,
        Arm64I32x4TruncSatF64x2SZero,
        Arm64I32x4TruncSatF64x2UZero,
        Arm64IExtractLaneU,
        Arm64IExtractLaneS,
        Arm64I16x8Shl,
        Arm64I16x8ShrS,
        Arm64I16x8SConvertI32x4,
        Arm64I16x8Mul,
        Arm64I16x8ShrU,
        Arm64I16x8UConvertI32x4,
        Arm64Mla,
        Arm64Mls,
        Arm64FAdd,
        Arm64FSub,
        Arm64FMul,
        Arm64FMulElement,
        Arm64FDiv,
        Arm64FMin,
        Arm64FMax,
        Arm64FEq,
        Arm64FNe,
        Arm64FLt,
        Arm64FLe,
        Arm64FGt,
        Arm64FGe,
        Arm64IAdd,
        Arm64ISub,
        Arm64IEq,
        Arm64INe,
        Arm64IGtS,
        Arm64IGeS,
        Arm64ILtS,
        Arm64ILeS,
        Arm64IMinS,
        Arm64IMaxS,
        Arm64IMinU,
        Arm64IMaxU,
        Arm64IGtU,
        Arm64IGeU,
        Arm64IAddSatS,
        Arm64ISubSatS,
        Arm64IAddSatU,
        Arm64ISubSatU,
        Arm64RoundingAverageU,
        Arm64Smlal,
        Arm64Smlal2,
        Arm64Sadalp,
        Arm64Saddlp,
        Arm64Uadalp,
        Arm64Uaddlp,
        Arm64Umlal,
        Arm64Umlal2,
    }

    #[derive(Debug, Copy, Clone, PartialEq, Eq)]
    pub enum TargetArchOpcode {
        Arm64Add,
        Arm64Add32,
        Arm64And,
        Arm64And32,
        Arm64Bic,
        Arm64Bic32,
        Arm64Clz,
        Arm64Clz32,
        Arm64Cmp,
        Arm64Cmp32,
        Arm64Cmn,
        Arm64Cmn32,
        Arm64Cnt,
        Arm64Cnt32,
        Arm64Cnt64,
        Arm64Tst,
        Arm64Tst32,
        Arm64Or,
        Arm64Or32,
        Arm64Orn,
        Arm64Orn32,
        Arm64Eor,
        Arm64Eor32,
        Arm64Eon,
        Arm64Eon32,
        Arm64Sub,
        Arm64Sub32,
        Arm64Mul,
        Arm64Mul32,
        Arm64Smulh,
        Arm64Smull,
        Arm64Smull2,
        Arm64Umull,
        Arm64Umulh,
        Arm64Umull2,
        Arm64Madd,
        Arm64Madd32,
        Arm64Msub,
        Arm64Msub32,
        Arm64Mneg,
        Arm64Mneg32,
        Arm64Idiv,
        Arm64Idiv32,
        Arm64Udiv,
        Arm64Udiv32,
        Arm64Imod,
        Arm64Imod32,
        Arm64Umod,
        Arm64Umod32,
        Arm64Not,
        Arm64Not32,
        Arm64Lsl,
        Arm64Lsl32,
        Arm64Lsr,
        Arm64Lsr32,
        Arm64Asr,
        Arm64Asr32,
        Arm64Ror,
        Arm64Ror32,
        Arm64Mov32,
        Arm64Sxtb32,
        Arm64Sxth32,
        Arm64Sxtb,
        Arm64Sxth,
        Arm64Sxtw,
        Arm64Sbfx,
        Arm64Sbfx32,
        Arm64Ubfx,
        Arm64Ubfx32,
        Arm64Ubfiz32,
        Arm64Sbfiz,
        Arm64Bfi,
        Arm64Rbit,
        Arm64Rbit32,
        Arm64Rev,
        Arm64Rev32,
        Arm64TestAndBranch32,
        Arm64TestAndBranch,
        Arm64CompareAndBranch32,
        Arm64CompareAndBranch,
        Arm64Claim,
        Arm64Poke,
        Arm64PokePair,
        Arm64Peek,
        Arm64Float16RoundDown,
        Arm64Float16RoundUp,
        Arm64Float16RoundTruncate,
        Arm64Float16RoundTiesEven,
        Arm64Float32Cmp,
        Arm64Float32Add,
        Arm64Float32Sub,
        Arm64Float32Mul,
        Arm64Float32Div,
        Arm64Float32Abs,
        Arm64Float32Abd,
        Arm64Float32Neg,
        Arm64Float32Sqrt,
        Arm64Float32Fnmul,
        Arm64Float32RoundDown,
        Arm64Float32Max,
        Arm64Float32Min,
        Arm64Float64Cmp,
        Arm64Float64Add,
        Arm64Float64Sub,
        Arm64Float64Mul,
        Arm64Float64Div,
        Arm64Float64Mod,
        Arm64Float64Max,
        Arm64Float64Min,
        Arm64Float64Abs,
        Arm64Float64Abd,
        Arm64Float64Neg,
        Arm64Float64Sqrt,
        Arm64Float64Fnmul,
        Arm64Float64RoundDown,
        Arm64Float32RoundUp,
        Arm64Float64RoundUp,
        Arm64Float64RoundTiesAway,
        Arm64Float32RoundTruncate,
        Arm64Float64RoundTruncate,
        Arm64Float32RoundTiesEven,
        Arm64Float64RoundTiesEven,
        Arm64Float64SilenceNaN,
        Arm64Float32ToFloat64,
        Arm64Float64ToFloat32,
        Arm64Float64ToFloat16RawBits,
        Arm64Float16RawBitsToFloat64,
        Arm64Float32ToInt32,
        Arm64Float64ToInt32,
        Arm64Float32ToUint32,
        Arm64Float64ToUint32,
        Arm64Float32ToInt64,
        Arm64Float64ToInt64,
        Arm64Float32ToUint64,
        Arm64Float64ToUint64,
        Arm64Int32ToFloat32,
        Arm64Int32ToFloat64,
        Arm64Int64ToFloat32,
        Arm64Int64ToFloat64,
        Arm64Uint32ToFloat32,
        Arm64Uint32ToFloat64,
        Arm64Uint64ToFloat32,
        Arm64Uint64ToFloat64,
        Arm64Float64ExtractLowWord32,
        Arm64Float64ExtractHighWord32,
        Arm64Float64InsertLowWord32,
        Arm64Float64InsertHighWord32,
        Arm64Float64MoveU64,
        Arm64U64MoveFloat64,
        Arm64LdarDecompressTaggedSigned,
        Arm64LdarDecompressTagged,
        Arm64StlrCompressTagged,
        Arm64StrIndirectPointer,
        Arm64LdrDecodeSandboxedPointer,
        Arm64StrEncodeSandboxedPointer,
        Arm64DmbIsh,
        Arm64DsbIsb,
        Arm64Word64AtomicAddUint64,
        Arm64Word64AtomicSubUint64,
        Arm64Word64AtomicAndUint64,
        Arm64Word64AtomicOrUint64,
        Arm64Word64AtomicXorUint64,
        Arm64Word64AtomicExchangeUint64,
        Arm64Word64AtomicCompareExchangeUint64,
        // Include Memory Access Mode opcodes
        Arm64Ldr,
        Arm64Ldrb,
        Arm64LdrD,
        Arm64Ldrh,
        Arm64LdrQ,
        Arm64LdrS,
        Arm64LdrH,
        Arm64Ldrsb,
        Arm64LdrsbW,
        Arm64Ldrsh,
        Arm64LdrshW,
        Arm64Ldrsw,
        Arm64LdrW,
        Arm64LoadLane,
        Arm64LoadSplat,
        Arm64S128Load16x4S,
        Arm64S128Load16x4U,
        Arm64S128Load32x2S,
        Arm64S128Load32x2U,
        Arm64S128Load8x8S,
        Arm64S128Load8x8U,
        Arm64StoreLane,
        Arm64Str,
        Arm64StrPair,
        Arm64Strb,
        Arm64StrD,
        Arm64Strh,
        Arm64StrQ,
        Arm64StrS,
        Arm64StrH,
        Arm64StrW,
        Arm64StrWPair,
        Arm64LdrDecompressTaggedSigned,
        Arm64LdrDecompressTagged,
        Arm64LdrDecompressProtected,
        Arm64StrCompressTagged,
        Arm64Word64AtomicLoadUint64,
        Arm64Word64AtomicStoreWord64,
        // Include SIMD opcodes
        Arm64F64x2Qfma,
        Arm64F64x2Qfms,
        Arm64F64x2Pmin,
        Arm64F64x2Pmax,
        Arm64F64x2ConvertLowI32x4S,
        Arm64F64x2ConvertLowI32x4U,
        Arm64F64x2PromoteLowF32x4,
        Arm64F32x4SConvertI32x4,
        Arm64F32x4UConvertI32x4,
        Arm64F32x4Qfma,
        Arm64F32x4Qfms,
        Arm64F32x4Pmin,
        Arm64F32x4Pmax,
        Arm64F32x4DemoteF64x2Zero,
        Arm64F16x8Pmin,
        Arm64F16x8Pmax,
        Arm64F32x4PromoteLowF16x8,
        Arm64F16x8SConvertI16x8,
        Arm64F16x8UConvertI16x8,
        Arm64F16x8DemoteF32x4Zero,
        Arm64F16x8DemoteF64x2Zero,
        Arm64I16x8SConvertF16x8,
        Arm64I16x8UConvertF16x8,
        Arm64F16x8Qfma,
        Arm64F16x8Qfms,
        Arm64I64x2ShrU,
        Arm64I64x2BitMask,
        Arm64I32x4SConvertF32x4,
        Arm64I32x4Shl,
        Arm64I32x4ShrS,
        Arm64I32x4Mul,
        Arm64I16x8Q15MulRSatS,
        Arm64I16x8BitMask,
        Arm64I8x16Shl,
        Arm64I8x16ShrS,
        Arm64I8x16SConvertI16x8,
        Arm64I8x16ShrU,
        Arm64I8x16UConvertI16x8,
        Arm64I8x16BitMask,
        Arm64S128Const,
        Arm64S128Dup,
        Arm64S128And,
        Arm64S128Or,
        Arm64S128Xor,
        Arm64S128Not,
        Arm64S128Select,
        Arm64S128AndNot,
        Arm64Ssra,
        Arm64Usra,
        Arm64S64x2UnzipLeft,
        Arm64S64x2UnzipRight,
        Arm64S32x4ZipLeft,
        Arm64S32x4ZipRight,
        Arm64S32x4UnzipLeft,
        Arm64S32x4UnzipRight,
        Arm64S32x4TransposeLeft,
        Arm64S32x4TransposeRight,
        Arm64S64x2Shuffle,
        Arm64S64x1Shuffle,
        Arm64S32x4Shuffle,
        Arm64S32x2Shuffle,
        Arm64S32x1Shuffle,
        Arm64S16x2Shuffle,
        Arm64S16x1Shuffle,
        Arm64S8x2Shuffle,
        Arm64S16x8ZipLeft,
        Arm64S16x8ZipRight,
        Arm64S16x8UnzipLeft,
        Arm64S16x8UnzipRight,
        Arm64S16x8TransposeLeft,
        Arm64S16x8TransposeRight,
        Arm64S8x16ZipLeft,
        Arm64S8x16ZipRight,
        Arm64S8x16UnzipLeft,
        Arm64S8x16UnzipRight,
        Arm64S8x16TransposeLeft,
        Arm64S8x16TransposeRight,
        Arm64S8x16Concat,
        Arm64I8x16Swizzle,
        Arm64I8x16Shuffle,
        Arm64S32x4Reverse,
        Arm64S32x4OneLaneSwizzle,
        Arm64S32x2Reverse,
        Arm64S16x4Reverse,
        Arm64S16x2Reverse,
        Arm64S8x8Reverse,
        Arm64S8x4Reverse,
        Arm64S8x2Reverse,
        Arm64V128AnyTrue,
        Arm64I64x2AllTrue,
        Arm64I32x4AllTrue,
        Arm64I16x8AllTrue,
        Arm64I8x16AllTrue,
        Arm64Sxtl,
        Arm64Sxtl2,
        Arm64Uxtl,
        Arm64Uxtl2,
        Arm64FSplat,
        Arm64FAbs,
        Arm64FSqrt,
        Arm64FNeg,
        Arm64FExtractLane,
        Arm64FReplaceLane,
        Arm64ISplat,
        Arm64IAbs,
        Arm64INeg,
        Arm64IExtractLane,
        Arm64IReplaceLane,
        Arm64I64x2Shl,
        Arm64I64x2ShrS,
        Arm64I64x2Mul,
        Arm64I32x4UConvertF32x4,
        Arm64I32x4ShrU,
        Arm64I32x4BitMask,
        Arm64I32x4DotI16x8S,
        Arm64I16x8DotI8x16S,
        Arm64I32x4DotI8x16AddS,
        Arm64I8x16Addv,
        Arm64I16x8Addv,
        Arm64I32x4Addv,
        Arm64I64x2AddPair,
        Arm64F32x4AddReducePairwise,
        Arm64F64x2AddPair,
        Arm64I32x4TruncSatF64x2SZero,
        Arm64I32x4TruncSatF64x2UZero,
        Arm64IExtractLaneU,
        Arm64IExtractLaneS,
        Arm64I16x8Shl,
        Arm64I16x8ShrS,
        Arm64I16x8SConvertI32x4,
        Arm64I16x8Mul,
        Arm64I16x8ShrU,
        Arm64I16x8UConvertI32x4,
        Arm64Mla,
        Arm64Mls,
        Arm64FAdd,
        Arm64FSub,
        Arm64FMul,
        Arm64FMulElement,
        Arm64FDiv,
        Arm64FMin,
        Arm64FMax,
        Arm64FEq,
        Arm64FNe,
        Arm64FLt,
        Arm64FLe,
        Arm64FGt,
        Arm64FGe,
        Arm64IAdd,
        Arm64ISub,
        Arm64IEq,
        Arm64INe,
        Arm64IGtS,
        Arm64IGeS,
        Arm64ILtS,
        Arm64ILeS,
        Arm64IMinS,
        Arm64IMaxS,
        Arm64IMinU,
        Arm64IMaxU,
        Arm64IGtU,
        Arm64IGeU,
        Arm64IAddSatS,
        Arm64ISubSatS,
        Arm64IAddSatU,
        Arm64ISubSatU,
        Arm64RoundingAverageU,
        Arm64Smlal,
        Arm64Smlal2,
        Arm64Sadalp,
        Arm64Saddlp,
        Arm64Uadalp,
        Arm64Uaddlp,
        Arm64Umlal,
        Arm64Umlal2,
    }
    // Addressing modes represent the "shape" of inputs to an instruction.
    // Many instructions support multiple addressing modes. Addressing modes
    // are encoded into the InstructionCode of the instruction and tell the
    // code generator after register allocation which assembler method to call.
    //
    // We use the following local notation for addressing modes:
    //
    // R = register
    // O = register or stack slot
    // D = double register
    // I = immediate (handle, external, int32)
    // MRI = [register + immediate]
    // MRR = [register + register]

    #[derive(Debug, Copy, Clone, PartialEq, Eq)]
    pub enum TargetAddressingMode {
        MRI,
        MRR,
        Operand2_R_LSL_I,
        Operand2_R_LSR_I,
        Operand2_R_ASR_I,
        Operand2_R_ROR_I,
        Operand2_R_UXTB,
        Operand2_R_UXTH,
        Operand2_R_SXTB,
        Operand2_R_SXTH,
        Operand2_R_SXTW,
        Root,
    }
}
